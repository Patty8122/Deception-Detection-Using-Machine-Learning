{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07463963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "# import mglearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import itertools\n",
    "from nltk.corpus import treebank\n",
    "from nltk.tag.sequential import ClassifierBasedPOSTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e4b0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('transcripts_final_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "508bfebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "samples= list(new_df.person_id.unique())\n",
    "num_samples = len(samples)\n",
    "train_ids = random.sample(samples,round(0.9*num_samples))\n",
    "test_ids = list(set(samples)-set(train_ids))\n",
    "\n",
    "df_train=pd.DataFrame()\n",
    "for i in train_ids:\n",
    "    df_train=df_train.append(new_df[new_df['person_id']==i])\n",
    "\n",
    "df_test=pd.DataFrame()\n",
    "for i in test_ids:\n",
    "    df_test=df_test.append(new_df[new_df['person_id']==i])\n",
    "\n",
    "X_train = df_train.drop('y',axis=1)\n",
    "X_test = df_test.drop('y',axis=1)\n",
    "y_train = df_train['y']\n",
    "y_test = df_test['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65d590c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\asim.tewari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# -------------- Main code\n",
    "train = X_train.copy()\n",
    "train['y'] = y_train.values\n",
    "nltk.download('treebank')\n",
    "train_sents = treebank.tagged_sents()\n",
    "tagger = ClassifierBasedPOSTagger(train=train_sents)\n",
    "stemmer = SnowballStemmer('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e785dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(810, 11)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65853286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tag sequences\n",
    "SEQ_1 = \"SEQ_1: {<DT|PP>?<JJ>*}\"\n",
    "SEQ_2 = \"SEQ_2: {<NN><DT|PP\\$>?<JJ>}\"\n",
    "SEQ_3 = \"SEQ_3: {<NP>?<VERB>?<NP|JJ>}\"\n",
    "SEQ_4 = \"SEQ_4: {<VB.*><NP|PP|CLAUSE>+$}\"\n",
    "\n",
    "cp1 = nltk.RegexpParser(SEQ_1)\n",
    "cp2 = nltk.RegexpParser(SEQ_2)\n",
    "cp3 = nltk.RegexpParser(SEQ_3)\n",
    "cp4 = nltk.RegexpParser(SEQ_4)\n",
    "\n",
    "lst_seq = list([cp1, cp2, cp3, cp4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "451ec522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "def get_number_of_spaces(sentence):\n",
    "    return sentence.count(' ')\n",
    "\n",
    "def get_number_of_fillers(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    return sentence.count('um')+sentence.count('uh')+sentence.count('uhh')+sentence.count('umm')+sentence.count('uhm')\n",
    "\n",
    "def get_number_of_other_fillers(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    return sentence.count('so')+sentence.count('well')+sentence.count('oh')+sentence.count('in fact')+sentence.count('ok')\n",
    "\n",
    "def get_number_of_capitals(sentence):\n",
    "    n = sum(1 for c in sentence if c.isupper())\n",
    "    return n\n",
    "\n",
    "\n",
    "def get_number_of_nouns(taged_tokens):\n",
    "    n = sum(1 for word, tag in taged_tokens if tag == 'NN' or tag == 'NNS' \\\n",
    "            or tag == 'NNP' or tag == 'NNP')\n",
    "    return n\n",
    "\n",
    "\n",
    "def get_number_of_adjectives(taged_tokens):\n",
    "    n = sum(1 for word, tag in taged_tokens if tag == 'JJ' or tag == 'JJR' or tag == 'JJS')\n",
    "    return n\n",
    "\n",
    "\n",
    "def get_count_of_tagged(taged_tokens, tag_in):\n",
    "    n = sum(1 for word, tag in taged_tokens if tag == tag_in)\n",
    "    return n\n",
    "\n",
    "\n",
    "def is_past_tense(taged_tokens):\n",
    "    n = sum(1 for word, tag in taged_tokens if tag == 'VBD')\n",
    "    return (n > 0)\n",
    "\n",
    "\n",
    "def is_modal(taged_tokens):\n",
    "    n = sum(1 for word, tag in taged_tokens if tag == 'MD')\n",
    "    return (n > 0)\n",
    "\n",
    "\n",
    "def vocab_richness(sentence):\n",
    "    unique = set(sentence.split())\n",
    "    count_uniques = len(unique)\n",
    "    return count_uniques\n",
    "\n",
    "\n",
    "def get_first_words(sentence, count):\n",
    "    arr_words = sentence.split()\n",
    "    ret_words = arr_words[:count]\n",
    "    str_ret = ' '.join(ret_words)\n",
    "    return str_ret\n",
    "\n",
    "\n",
    "def get_one_word(sentence, position):\n",
    "    arr_words = sentence.split()\n",
    "    if len(arr_words) >= (position + 1):\n",
    "        ret_word = arr_words[position]\n",
    "        return ret_word\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def exists_she(sentense):\n",
    "    if 'she' in sentense.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def exists_he(sentense):\n",
    "    if 'he' in sentense.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "def first_tag(taged_tokens):\n",
    "    return str(taged_tokens[0][1])\n",
    "\n",
    "\n",
    "def second_tag(taged_tokens):\n",
    "    if len(taged_tokens) > 1:\n",
    "        return str(taged_tokens[1][1])\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def third_tag(taged_tokens):\n",
    "    if len(taged_tokens) > 2:\n",
    "        return str(taged_tokens[2][1])\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_consonant_letters(sentence):\n",
    "    consonants = 0\n",
    "    for word in sentence:\n",
    "        for letter in word:\n",
    "            if letter in 'bcdfghjklmnpqrstvwxyz':\n",
    "                consonants += 1\n",
    "\n",
    "    return consonants\n",
    "\n",
    "\n",
    "def get_sonant_letters(sentence):\n",
    "    sonants = 0\n",
    "    for word in sentence:\n",
    "        for letter in word:\n",
    "            if letter in 'aieou':\n",
    "                sonants += 1\n",
    "\n",
    "    return sonants\n",
    "\n",
    "\n",
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)\n",
    "\n",
    "\n",
    "def get_sequence_tags(taged_tokens, n_sequence):\n",
    "    countSequence = 0\n",
    "    cp = lst_seq[n_sequence-1]\n",
    "    result = cp.parse(taged_tokens)\n",
    "\n",
    "    for tre in result:\n",
    "        if isinstance(tre, nltk.tree.Tree):\n",
    "            if tre.label() ==  cp._stages[0]._chunk_label:\n",
    "                countSequence += 1\n",
    "\n",
    "    return (countSequence > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4cc37e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_features(sentens_in):\n",
    "    stemmed_words = list()\n",
    "    for w in sentens_in.split():\n",
    "        stemmed_words.append(stemmer.stem(w))\n",
    "\n",
    "    sentence = ' '.join(stemmed_words)\n",
    "    word_tokens = nltk.wordpunct_tokenize(sentence)\n",
    "\n",
    "    taged_tokens = tagger.tag(word_tokens)\n",
    "\n",
    "    X_dict = {}\n",
    "\n",
    "    X_dict['seq_01'] = get_sequence_tags(taged_tokens, 1)\n",
    "    X_dict['seq_02'] = get_sequence_tags(taged_tokens, 2)\n",
    "    X_dict['seq_03'] = get_sequence_tags(taged_tokens, 3)\n",
    "    # X_dict['seq_04'] = get_sequence_tags(taged_tokens, 4)\n",
    "\n",
    "    X_dict['lexical_diversity'] = lexical_diversity(sentence.lower())\n",
    "    X_dict['get_consonant_letters'] = get_consonant_letters(sentence.lower())\n",
    "    X_dict['get_sonant_letters'] = get_sonant_letters(sentence.lower())\n",
    "    X_dict['count_of_fillers'] = get_number_of_fillers(sentence)\n",
    "    X_dict['count_of_other_fillers'] = get_number_of_other_fillers(sentence)\n",
    "\n",
    "    X_dict['count_of_spaces'] = get_number_of_spaces(sentence)\n",
    "    X_dict['count_capitals'] = get_number_of_capitals(sentence)\n",
    "    X_dict['count_nouns'] = get_number_of_nouns(taged_tokens)\n",
    "    X_dict['count_adjectives'] = get_number_of_adjectives(taged_tokens)\n",
    "\n",
    "    X_dict['count_numbers'] = get_count_of_tagged(taged_tokens, 'CD')\n",
    "    X_dict['count_NNS'] = get_count_of_tagged(taged_tokens, 'NNS')\n",
    "    X_dict['count_NNP'] = get_count_of_tagged(taged_tokens, 'NNP')\n",
    "    X_dict['count_NNPS'] = get_count_of_tagged(taged_tokens, 'NNPS')\n",
    "    X_dict['count_RBS'] = get_count_of_tagged(taged_tokens, 'RBS')\n",
    "    X_dict['count_RBR'] = get_count_of_tagged(taged_tokens, 'RBR')\n",
    "    X_dict['count_WP'] = get_count_of_tagged(taged_tokens, 'WP')\n",
    "    X_dict['count_WP$'] = get_count_of_tagged(taged_tokens, 'WP$')\n",
    "    X_dict['count_WRB'] = get_count_of_tagged(taged_tokens, 'WRB')\n",
    "    X_dict['count_PRP'] = get_count_of_tagged(taged_tokens, 'PRP')\n",
    "    X_dict['count_POS'] = get_count_of_tagged(taged_tokens, 'POS')\n",
    "    X_dict['count_FW'] = get_count_of_tagged(taged_tokens, 'FW')\n",
    "    X_dict['count_VB'] = get_count_of_tagged(taged_tokens, 'VB')\n",
    "    X_dict['count_VBD'] = get_count_of_tagged(taged_tokens, 'VBD')\n",
    "    X_dict['count_VBG'] = get_count_of_tagged(taged_tokens, 'VBG')\n",
    "    X_dict['count_VBN'] = get_count_of_tagged(taged_tokens, 'VBN')\n",
    "    X_dict['count_CC'] = get_count_of_tagged(taged_tokens, 'CC')\n",
    "\n",
    "    X_dict['count_DT']         = get_count_of_tagged(taged_tokens, 'DT')\n",
    "    X_dict['count_UH']         = get_count_of_tagged(taged_tokens, 'UH')\n",
    "    X_dict['count_SYM']        = get_count_of_tagged(taged_tokens, 'SYM')\n",
    "    X_dict['count_PDT']        = get_count_of_tagged(taged_tokens, 'PDT')\n",
    "    X_dict['count_LS']         = get_count_of_tagged(taged_tokens, 'LS')\n",
    "\n",
    "    X_dict['count_3rd person'] = get_count_of_tagged(taged_tokens, 'VBZ')\n",
    "    X_dict['count_gerund'] = get_count_of_tagged(taged_tokens, 'VBG')\n",
    "\n",
    "    X_dict['is_past_tense'] = is_past_tense(taged_tokens)\n",
    "    X_dict['is_modal'] = is_modal(taged_tokens)\n",
    "    X_dict['vocab_richness'] = vocab_richness(sentence)\n",
    "    X_dict['first_tag'] = first_tag(taged_tokens)\n",
    "    X_dict['second_tag'] = second_tag(taged_tokens)\n",
    "    X_dict['third_tag'] = third_tag(taged_tokens)\n",
    "    \n",
    "#     X_dict['first_one_word'] = get_one_word(sentence, 0)\n",
    "#     X_dict['second_one_word'] = get_one_word(sentence, 1)\n",
    "#     X_dict['third_one_word'] = get_one_word(sentence, 2)\n",
    "#     X_dict['forth_one_word'] = get_one_word(sentence, 3)\n",
    "#     X_dict['fifth_one_word'] = get_one_word(sentence, 4)\n",
    "#     X_dict['sixth_one_word'] = get_one_word(sentence, 5)\n",
    "#     X_dict['seventh_one_word'] = get_one_word(sentence, 6)\n",
    "#     X_dict['eith_one_word'] = get_one_word(sentence, 7)\n",
    "#     X_dict['ninth_one_word'] = get_one_word(sentence, 8)\n",
    "#     X_dict['tenth_one_word'] = get_one_word(sentence, 9)\n",
    "\n",
    "#     X_dict['first_6_word'] = get_first_words(sentence, 6)\n",
    "#     X_dict['first_5_word'] = get_first_words(sentence, 5)\n",
    "#     X_dict['first_4_word'] = get_first_words(sentence, 4)\n",
    "#     X_dict['first_3_word'] = get_first_words(sentence, 3)\n",
    "#     X_dict['first_2_word'] = get_first_words(sentence, 2)\n",
    "\n",
    "    X_dict['exists_she'] = exists_she(sentence)\n",
    "    X_dict['exists_he']  = exists_he(sentence)\n",
    "\n",
    "    X_dict['first_word_is_the'] = ('the' == get_first_words(sentence.lower(), 1))\n",
    "    X_dict['first_word_is_she'] = ('she' == get_first_words(sentence.lower(), 1))\n",
    "    X_dict['first_word_is_he']  = ('he' == get_first_words(sentence.lower(), 1))\n",
    "    X_dict['first_word_is_it']  = ('it' == get_first_words(sentence.lower(), 1))\n",
    "    X_dict['first_word_is_this'] = ('this' == get_first_words(sentence.lower(), 1))\n",
    "    X_dict['first_word_is_you']  = ('you' == get_first_words(sentence.lower(), 1))\n",
    "    X_dict['first_word_is_OK']  = ('OK' == get_first_words(sentence.lower(), 1))\n",
    "\n",
    "\n",
    "    # X_dict['Raymond'] = ('raymond' in sentence.lower())\n",
    "    # X_dict['Perdita'] = ('perdita' in sentence.lower())\n",
    "    # X_dict['Idris']   = ('idris' in sentence.lower())\n",
    "    # X_dict['Adrian']  = ('adrian' in sentence.lower())\n",
    "    # X_dict['Chapter'] = ('chapter' in sentence.lower())\n",
    "    # X_dict['sinister'] = ('sinister' in sentence.lower())\n",
    "    # X_dict['weird']    = ('weird' in sentence.lower())\n",
    "    # X_dict['horrible'] = ('horrible' in sentence.lower())\n",
    "\n",
    "    return X_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "10b66ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.text import TextCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "61b1c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(train['y'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b13d2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# random.seed(0)\n",
    "# samples= list(train.id.unique())\n",
    "# num_samples = len(samples)\n",
    "# train_ids = random.sample(samples,round(0.63*num_samples))\n",
    "# val_ids = list(set(samples)-set(train_ids))\n",
    "\n",
    "# df_train=pd.DataFrame()\n",
    "# for i in train_ids:\n",
    "#     df_train=df_train.append(train[train['id']==i])\n",
    "\n",
    "# df_val=pd.DataFrame()\n",
    "# for i in val_ids:\n",
    "#     df_val=df_val.append(train[train['id']==i])\n",
    "\n",
    "# xtrain = df_train.drop('y',axis=1)\n",
    "# xval = df_val.drop('y',axis=1)\n",
    "# ytrain = df_train['y']\n",
    "# yval = df_val['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e63cdb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\asim.tewari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update( ['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26f11572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\asim.tewari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba05ff96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(810,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['display'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "febe9106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_features(IN_x):\n",
    "    Out_x= []\n",
    "    index = 0\n",
    "\n",
    "    for sentens_edna in IN_x:\n",
    "        word_tokens1 = [i for i in word_tokenize(sentens_edna) if i not in stop_words]\n",
    "        sentens_in = ' '.join(word_tokens1)\n",
    "        X_feat_dict = get_sentence_features(sentens_in)\n",
    "        Out_x.append(X_feat_dict)\n",
    "        # Out_y.append(IN_y[index])\n",
    "        index += 1\n",
    "\n",
    "    return Out_x\n",
    "\n",
    "\n",
    "# X_Train = get_train_features(train['display'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "377bf377",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = get_train_features(new_df['display'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "16fee8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_01</th>\n",
       "      <th>seq_02</th>\n",
       "      <th>seq_03</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>get_consonant_letters</th>\n",
       "      <th>get_sonant_letters</th>\n",
       "      <th>count_of_fillers</th>\n",
       "      <th>count_of_other_fillers</th>\n",
       "      <th>count_of_spaces</th>\n",
       "      <th>count_capitals</th>\n",
       "      <th>...</th>\n",
       "      <th>third_tag</th>\n",
       "      <th>exists_she</th>\n",
       "      <th>exists_he</th>\n",
       "      <th>first_word_is_the</th>\n",
       "      <th>first_word_is_she</th>\n",
       "      <th>first_word_is_he</th>\n",
       "      <th>first_word_is_it</th>\n",
       "      <th>first_word_is_this</th>\n",
       "      <th>first_word_is_you</th>\n",
       "      <th>first_word_is_OK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.078078</td>\n",
       "      <td>163</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>RB</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.049407</td>\n",
       "      <td>249</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>RB</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.180180</td>\n",
       "      <td>56</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.069164</td>\n",
       "      <td>164</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>VBP</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.204918</td>\n",
       "      <td>57</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>PRP</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   seq_01  seq_02  seq_03  lexical_diversity  get_consonant_letters  \\\n",
       "0    True    True    True           0.078078                    163   \n",
       "1    True    True    True           0.049407                    249   \n",
       "2    True    True    True           0.180180                     56   \n",
       "3    True    True    True           0.069164                    164   \n",
       "4    True    True    True           0.204918                     57   \n",
       "\n",
       "   get_sonant_letters  count_of_fillers  count_of_other_fillers  \\\n",
       "0                 109                 0                       6   \n",
       "1                 169                 0                       8   \n",
       "2                  33                 0                       2   \n",
       "3                 116                 0                       2   \n",
       "4                  36                 0                       2   \n",
       "\n",
       "   count_of_spaces  count_capitals  ...  third_tag  exists_she  exists_he  \\\n",
       "0               58               0  ...         RB       False       True   \n",
       "1               88               0  ...         RB       False       True   \n",
       "2               22               0  ...         NN       False      False   \n",
       "3               66               0  ...        VBP       False       True   \n",
       "4               27               0  ...        PRP       False      False   \n",
       "\n",
       "   first_word_is_the  first_word_is_she  first_word_is_he  first_word_is_it  \\\n",
       "0              False              False             False             False   \n",
       "1              False              False             False             False   \n",
       "2              False              False             False             False   \n",
       "3              False              False             False             False   \n",
       "4              False              False             False             False   \n",
       "\n",
       "   first_word_is_this  first_word_is_you  first_word_is_OK  \n",
       "0               False              False             False  \n",
       "1               False              False             False  \n",
       "2               False              False             False  \n",
       "3               False              False             False  \n",
       "4               False              False             False  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = pd.DataFrame(all_features)\n",
    "all_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0b53dacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['seq_01', 'seq_02', 'seq_03', 'lexical_diversity',\n",
       "       'get_consonant_letters', 'get_sonant_letters', 'count_of_fillers',\n",
       "       'count_of_other_fillers', 'count_of_spaces', 'count_capitals',\n",
       "       'count_nouns', 'count_adjectives', 'count_numbers', 'count_NNS',\n",
       "       'count_NNP', 'count_NNPS', 'count_RBS', 'count_RBR', 'count_WP',\n",
       "       'count_WP$', 'count_WRB', 'count_PRP', 'count_POS', 'count_FW',\n",
       "       'count_VB', 'count_VBD', 'count_VBG', 'count_VBN', 'count_CC',\n",
       "       'count_DT', 'count_UH', 'count_SYM', 'count_PDT', 'count_LS',\n",
       "       'count_3rd person', 'count_gerund', 'is_past_tense', 'is_modal',\n",
       "       'vocab_richness', 'first_tag', 'second_tag', 'third_tag', 'exists_she',\n",
       "       'exists_he', 'first_word_is_the', 'first_word_is_she',\n",
       "       'first_word_is_he', 'first_word_is_it', 'first_word_is_this',\n",
       "       'first_word_is_you', 'first_word_is_OK'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "61a98ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_final = pd.concat([all_features.reset_index(),new_df[['id','y']].reset_index()],axis=1)\n",
    "# X_d_test = pd.concat([X_data_test.reset_index(),X_test[['person_id']].reset_index(),y_test.reset_index()],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e552c12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_final.drop(['index','index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a13d226a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_01</th>\n",
       "      <th>seq_02</th>\n",
       "      <th>seq_03</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>get_consonant_letters</th>\n",
       "      <th>get_sonant_letters</th>\n",
       "      <th>count_of_fillers</th>\n",
       "      <th>count_of_other_fillers</th>\n",
       "      <th>count_of_spaces</th>\n",
       "      <th>count_capitals</th>\n",
       "      <th>...</th>\n",
       "      <th>exists_he</th>\n",
       "      <th>first_word_is_the</th>\n",
       "      <th>first_word_is_she</th>\n",
       "      <th>first_word_is_he</th>\n",
       "      <th>first_word_is_it</th>\n",
       "      <th>first_word_is_this</th>\n",
       "      <th>first_word_is_you</th>\n",
       "      <th>first_word_is_OK</th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.078078</td>\n",
       "      <td>163</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.049407</td>\n",
       "      <td>249</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.180180</td>\n",
       "      <td>56</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.069164</td>\n",
       "      <td>164</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.204918</td>\n",
       "      <td>57</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.187970</td>\n",
       "      <td>66</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>897 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     seq_01  seq_02  seq_03  lexical_diversity  get_consonant_letters  \\\n",
       "0      True    True    True           0.078078                    163   \n",
       "1      True    True    True           0.049407                    249   \n",
       "2      True    True    True           0.180180                     56   \n",
       "3      True    True    True           0.069164                    164   \n",
       "4      True    True    True           0.204918                     57   \n",
       "..      ...     ...     ...                ...                    ...   \n",
       "892   False   False   False           0.789474                     10   \n",
       "893   False   False   False           0.404762                     21   \n",
       "894   False   False   False           1.000000                      2   \n",
       "895   False   False   False           0.625000                      8   \n",
       "896    True   False    True           0.187970                     66   \n",
       "\n",
       "     get_sonant_letters  count_of_fillers  count_of_other_fillers  \\\n",
       "0                   109                 0                       6   \n",
       "1                   169                 0                       8   \n",
       "2                    33                 0                       2   \n",
       "3                   116                 0                       2   \n",
       "4                    36                 0                       2   \n",
       "..                  ...               ...                     ...   \n",
       "892                   6                 0                       1   \n",
       "893                  12                 0                       0   \n",
       "894                   1                 0                       0   \n",
       "895                   5                 0                       0   \n",
       "896                  39                 2                       1   \n",
       "\n",
       "     count_of_spaces  count_capitals  ...  exists_he  first_word_is_the  \\\n",
       "0                 58               0  ...       True              False   \n",
       "1                 88               0  ...       True              False   \n",
       "2                 22               0  ...      False              False   \n",
       "3                 66               0  ...       True              False   \n",
       "4                 27               0  ...      False              False   \n",
       "..               ...             ...  ...        ...                ...   \n",
       "892                3               0  ...      False              False   \n",
       "893                8               0  ...      False              False   \n",
       "894                0               0  ...      False              False   \n",
       "895                3               0  ...      False              False   \n",
       "896               25               0  ...      False              False   \n",
       "\n",
       "     first_word_is_she  first_word_is_he  first_word_is_it  \\\n",
       "0                False             False             False   \n",
       "1                False             False             False   \n",
       "2                False             False             False   \n",
       "3                False             False             False   \n",
       "4                False             False             False   \n",
       "..                 ...               ...               ...   \n",
       "892              False             False             False   \n",
       "893              False             False             False   \n",
       "894              False             False             False   \n",
       "895              False             False             False   \n",
       "896              False             False             False   \n",
       "\n",
       "     first_word_is_this  first_word_is_you  first_word_is_OK  id    y  \n",
       "0                 False              False             False   1  1.0  \n",
       "1                 False              False             False   2  1.0  \n",
       "2                 False              False             False   3  1.0  \n",
       "3                 False              False             False   4  1.0  \n",
       "4                 False              False             False   5  1.0  \n",
       "..                  ...                ...               ...  ..  ...  \n",
       "892               False              False             False  27  0.0  \n",
       "893               False              False             False  28  0.0  \n",
       "894               False              False             False  29  0.0  \n",
       "895               False              False             False  30  0.0  \n",
       "896               False              False             False  31  0.0  \n",
       "\n",
       "[897 rows x 53 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f0cf0cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_final.to_csv('POSfeatures.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c6cccfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = (xtrain.reset_index()).drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1ba49ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xval = (xval.reset_index()).drop('index',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a83ff2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_features(IN_x, IN_y):\n",
    "    Out_x, Out_y = [], []\n",
    "    index = 0\n",
    "\n",
    "    for sentens_edna in IN_x:\n",
    "        word_tokens1 = [i for i in word_tokenize(sentens_edna) if i not in stop_words]\n",
    "        sentens_in = ' '.join(word_tokens1)\n",
    "        X_feat_dict = get_sentence_features(sentens_in)\n",
    "        Out_x.append(X_feat_dict)\n",
    "        Out_y.append(IN_y[index])\n",
    "        index += 1\n",
    "\n",
    "    return Out_x, Out_y\n",
    "\n",
    "\n",
    "X_Train, Y_train = get_train_features(xtrain['display'].reset_index(), ytrain.values)\n",
    "X_valid, Y_valid = get_train_features(xval['display'], yval.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fb08d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train = pd.DataFrame(X_Train)\n",
    "X_valid = pd.DataFrame(X_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2414801e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_01</th>\n",
       "      <th>seq_02</th>\n",
       "      <th>seq_03</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>get_consonant_letters</th>\n",
       "      <th>get_sonant_letters</th>\n",
       "      <th>count_of_fillers</th>\n",
       "      <th>count_of_other_fillers</th>\n",
       "      <th>count_of_spaces</th>\n",
       "      <th>count_capitals</th>\n",
       "      <th>...</th>\n",
       "      <th>first_2_word</th>\n",
       "      <th>exists_she</th>\n",
       "      <th>exists_he</th>\n",
       "      <th>first_word_is_the</th>\n",
       "      <th>first_word_is_she</th>\n",
       "      <th>first_word_is_he</th>\n",
       "      <th>first_word_is_it</th>\n",
       "      <th>first_word_is_this</th>\n",
       "      <th>first_word_is_you</th>\n",
       "      <th>first_word_is_OK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>index</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>display</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   seq_01  seq_02  seq_03  lexical_diversity  get_consonant_letters  \\\n",
       "0   False   False   False                1.0                      3   \n",
       "1   False   False   False                1.0                      5   \n",
       "\n",
       "   get_sonant_letters  count_of_fillers  count_of_other_fillers  \\\n",
       "0                   2                 0                       0   \n",
       "1                   2                 0                       0   \n",
       "\n",
       "   count_of_spaces  count_capitals  ...  first_2_word  exists_she  exists_he  \\\n",
       "0                0               0  ...         index       False      False   \n",
       "1                0               0  ...       display       False      False   \n",
       "\n",
       "   first_word_is_the  first_word_is_she  first_word_is_he  first_word_is_it  \\\n",
       "0              False              False             False             False   \n",
       "1              False              False             False             False   \n",
       "\n",
       "   first_word_is_this  first_word_is_you  first_word_is_OK  \n",
       "0               False              False             False  \n",
       "1               False              False             False  \n",
       "\n",
       "[2 rows x 66 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1342a26d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2, 522]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-1e1b4b2285e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBernoulliNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_Train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# clf = grid.best_estimator_.named_steps['bernoullinb']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# coef = grid.best_estimator_.named_steps['bernoullinb'].coef_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[0mrefit_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m         \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    297\u001b[0m     \"\"\"\n\u001b[0;32m    298\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    263\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 522]"
     ]
    }
   ],
   "source": [
    "params = {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "         }\n",
    "\n",
    "grid = GridSearchCV(BernoulliNB(), param_grid=params, n_jobs=-1, cv=5, verbose=5)\n",
    "grid.fit(X_Train, y_train.values)\n",
    "# clf = grid.best_estimator_.named_steps['bernoullinb']\n",
    "# coef = grid.best_estimator_.named_steps['bernoullinb'].coef_\n",
    "# best_alpha = grid.best_estimator_.named_steps['bernoullinb'].alpha\n",
    "# print(\"Best cross-validation alpha: {:.2f}\".format(best_alpha))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d256474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
