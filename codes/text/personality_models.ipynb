{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63df50f7",
   "metadata": {
    "id": "63df50f7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eOrWgRwGd2X5",
   "metadata": {
    "id": "eOrWgRwGd2X5"
   },
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('personality_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "752b8dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('numbers_personality.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99f5815c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Dataframe:\n",
      "    I..The.respondent...Am.the.life.of.the.party..  \\\n",
      "0                                         3.000000   \n",
      "1                                         2.000000   \n",
      "2                                         3.000000   \n",
      "3                                         3.000000   \n",
      "4                                         1.000000   \n",
      "5                                         1.000000   \n",
      "6                                         4.000000   \n",
      "7                                         1.000000   \n",
      "8                                         5.000000   \n",
      "9                                         2.000000   \n",
      "10                                        4.000000   \n",
      "11                                        2.000000   \n",
      "12                                        1.000000   \n",
      "13                                        1.000000   \n",
      "14                                        3.000000   \n",
      "15                                        4.000000   \n",
      "16                                        3.000000   \n",
      "17                                        3.000000   \n",
      "18                                        3.000000   \n",
      "19                                        1.000000   \n",
      "20                                        1.000000   \n",
      "21                                        5.000000   \n",
      "22                                        4.000000   \n",
      "23                                        2.000000   \n",
      "24                                        2.000000   \n",
      "25                                        4.000000   \n",
      "26                                        2.633333   \n",
      "27                                        4.000000   \n",
      "28                                        3.000000   \n",
      "29                                        2.000000   \n",
      "30                                        2.000000   \n",
      "\n",
      "    I..The.respondent...Feel.little.concern.for.others..  \\\n",
      "0                                                   3      \n",
      "1                                                   5      \n",
      "2                                                   4      \n",
      "3                                                   1      \n",
      "4                                                   4      \n",
      "5                                                   5      \n",
      "6                                                   4      \n",
      "7                                                   1      \n",
      "8                                                   2      \n",
      "9                                                   5      \n",
      "10                                                  5      \n",
      "11                                                  3      \n",
      "12                                                  4      \n",
      "13                                                  5      \n",
      "14                                                  1      \n",
      "15                                                  5      \n",
      "16                                                  3      \n",
      "17                                                  3      \n",
      "18                                                  4      \n",
      "19                                                  1      \n",
      "20                                                  4      \n",
      "21                                                  2      \n",
      "22                                                  3      \n",
      "23                                                  2      \n",
      "24                                                  4      \n",
      "25                                                  2      \n",
      "26                                                  5      \n",
      "27                                                  1      \n",
      "28                                                  2      \n",
      "29                                                  2      \n",
      "30                                                  4      \n",
      "\n",
      "    I..The.respondent...Am.always.prepared..  \\\n",
      "0                                        1.0   \n",
      "1                                        1.0   \n",
      "2                                        4.0   \n",
      "3                                        3.0   \n",
      "4                                        3.0   \n",
      "5                                        4.0   \n",
      "6                                        4.0   \n",
      "7                                        3.0   \n",
      "8                                        4.0   \n",
      "9                                        4.0   \n",
      "10                                       4.0   \n",
      "11                                       3.0   \n",
      "12                                       3.0   \n",
      "13                                       1.0   \n",
      "14                                       3.2   \n",
      "15                                       3.0   \n",
      "16                                       4.0   \n",
      "17                                       2.0   \n",
      "18                                       5.0   \n",
      "19                                       1.0   \n",
      "20                                       4.0   \n",
      "21                                       4.0   \n",
      "22                                       1.0   \n",
      "23                                       4.0   \n",
      "24                                       4.0   \n",
      "25                                       3.0   \n",
      "26                                       4.0   \n",
      "27                                       5.0   \n",
      "28                                       4.0   \n",
      "29                                       5.0   \n",
      "30                                       1.0   \n",
      "\n",
      "    I..The.respondent....Get.stressed.out.easily..  \\\n",
      "0                                                4   \n",
      "1                                                4   \n",
      "2                                                4   \n",
      "3                                                1   \n",
      "4                                                1   \n",
      "5                                                4   \n",
      "6                                                4   \n",
      "7                                                5   \n",
      "8                                                4   \n",
      "9                                                3   \n",
      "10                                               3   \n",
      "11                                               2   \n",
      "12                                               1   \n",
      "13                                               5   \n",
      "14                                               3   \n",
      "15                                               4   \n",
      "16                                               4   \n",
      "17                                               3   \n",
      "18                                               1   \n",
      "19                                               3   \n",
      "20                                               5   \n",
      "21                                               4   \n",
      "22                                               3   \n",
      "23                                               5   \n",
      "24                                               5   \n",
      "25                                               3   \n",
      "26                                               4   \n",
      "27                                               2   \n",
      "28                                               4   \n",
      "29                                               1   \n",
      "30                                               4   \n",
      "\n",
      "    I..The.respondent...Have.a.rich.vocabulary..  \\\n",
      "0                                              3   \n",
      "1                                              5   \n",
      "2                                              3   \n",
      "3                                              3   \n",
      "4                                              4   \n",
      "5                                              3   \n",
      "6                                              1   \n",
      "7                                              4   \n",
      "8                                              5   \n",
      "9                                              1   \n",
      "10                                             3   \n",
      "11                                             1   \n",
      "12                                             2   \n",
      "13                                             3   \n",
      "14                                             3   \n",
      "15                                             3   \n",
      "16                                             1   \n",
      "17                                             2   \n",
      "18                                             4   \n",
      "19                                             4   \n",
      "20                                             2   \n",
      "21                                             3   \n",
      "22                                             2   \n",
      "23                                             5   \n",
      "24                                             1   \n",
      "25                                             1   \n",
      "26                                             4   \n",
      "27                                             3   \n",
      "28                                             4   \n",
      "29                                             5   \n",
      "30                                             3   \n",
      "\n",
      "    I..The.respondent...Don.t.talk.a.lot..  \\\n",
      "0                                        1   \n",
      "1                                        4   \n",
      "2                                        3   \n",
      "3                                        4   \n",
      "4                                        1   \n",
      "5                                        4   \n",
      "6                                        1   \n",
      "7                                        4   \n",
      "8                                        1   \n",
      "9                                        1   \n",
      "10                                       1   \n",
      "11                                       1   \n",
      "12                                       3   \n",
      "13                                       1   \n",
      "14                                       1   \n",
      "15                                       1   \n",
      "16                                       2   \n",
      "17                                       3   \n",
      "18                                       1   \n",
      "19                                       3   \n",
      "20                                       1   \n",
      "21                                       2   \n",
      "22                                       2   \n",
      "23                                       2   \n",
      "24                                       4   \n",
      "25                                       2   \n",
      "26                                       2   \n",
      "27                                       1   \n",
      "28                                       4   \n",
      "29                                       2   \n",
      "30                                       1   \n",
      "\n",
      "    I..The.respondent...Am.interested.in.people..  \\\n",
      "0                                               3   \n",
      "1                                               1   \n",
      "2                                               3   \n",
      "3                                               4   \n",
      "4                                               3   \n",
      "5                                               5   \n",
      "6                                               5   \n",
      "7                                               5   \n",
      "8                                               5   \n",
      "9                                               4   \n",
      "10                                              4   \n",
      "11                                              5   \n",
      "12                                              4   \n",
      "13                                              5   \n",
      "14                                              4   \n",
      "15                                              4   \n",
      "16                                              5   \n",
      "17                                              3   \n",
      "18                                              4   \n",
      "19                                              4   \n",
      "20                                              1   \n",
      "21                                              5   \n",
      "22                                              5   \n",
      "23                                              4   \n",
      "24                                              3   \n",
      "25                                              5   \n",
      "26                                              5   \n",
      "27                                              5   \n",
      "28                                              4   \n",
      "29                                              3   \n",
      "30                                              4   \n",
      "\n",
      "    I..The.respondent....Leave.my.belongings.around..  \\\n",
      "0                                                   3   \n",
      "1                                                   4   \n",
      "2                                                   1   \n",
      "3                                                   5   \n",
      "4                                                   4   \n",
      "5                                                   1   \n",
      "6                                                   2   \n",
      "7                                                   3   \n",
      "8                                                   1   \n",
      "9                                                   4   \n",
      "10                                                  3   \n",
      "11                                                  5   \n",
      "12                                                  2   \n",
      "13                                                  4   \n",
      "14                                                  4   \n",
      "15                                                  4   \n",
      "16                                                  1   \n",
      "17                                                  5   \n",
      "18                                                  4   \n",
      "19                                                  1   \n",
      "20                                                  2   \n",
      "21                                                  4   \n",
      "22                                                  4   \n",
      "23                                                  3   \n",
      "24                                                  3   \n",
      "25                                                  1   \n",
      "26                                                  5   \n",
      "27                                                  3   \n",
      "28                                                  2   \n",
      "29                                                  4   \n",
      "30                                                  4   \n",
      "\n",
      "    I..The.respondent...Am.relaxed.most.of.the.time..  \\\n",
      "0                                                   4   \n",
      "1                                                   4   \n",
      "2                                                   3   \n",
      "3                                                   4   \n",
      "4                                                   4   \n",
      "5                                                   3   \n",
      "6                                                   3   \n",
      "7                                                   2   \n",
      "8                                                   1   \n",
      "9                                                   4   \n",
      "10                                                  5   \n",
      "11                                                  5   \n",
      "12                                                  4   \n",
      "13                                                  4   \n",
      "14                                                  3   \n",
      "15                                                  4   \n",
      "16                                                  2   \n",
      "17                                                  3   \n",
      "18                                                  5   \n",
      "19                                                  4   \n",
      "20                                                  2   \n",
      "21                                                  4   \n",
      "22                                                  3   \n",
      "23                                                  2   \n",
      "24                                                  1   \n",
      "25                                                  4   \n",
      "26                                                  4   \n",
      "27                                                  4   \n",
      "28                                                  1   \n",
      "29                                                  4   \n",
      "30                                                  1   \n",
      "\n",
      "    I..The.respondent...Have.difficulty.understanding.abstract.ideas..  ...  \\\n",
      "0                                                   1                   ...   \n",
      "1                                                   1                   ...   \n",
      "2                                                   1                   ...   \n",
      "3                                                   3                   ...   \n",
      "4                                                   1                   ...   \n",
      "5                                                   2                   ...   \n",
      "6                                                   2                   ...   \n",
      "7                                                   4                   ...   \n",
      "8                                                   4                   ...   \n",
      "9                                                   1                   ...   \n",
      "10                                                  3                   ...   \n",
      "11                                                  2                   ...   \n",
      "12                                                  3                   ...   \n",
      "13                                                  1                   ...   \n",
      "14                                                  3                   ...   \n",
      "15                                                  1                   ...   \n",
      "16                                                  2                   ...   \n",
      "17                                                  1                   ...   \n",
      "18                                                  1                   ...   \n",
      "19                                                  1                   ...   \n",
      "20                                                  1                   ...   \n",
      "21                                                  1                   ...   \n",
      "22                                                  4                   ...   \n",
      "23                                                  2                   ...   \n",
      "24                                                  1                   ...   \n",
      "25                                                  4                   ...   \n",
      "26                                                  1                   ...   \n",
      "27                                                  1                   ...   \n",
      "28                                                  2                   ...   \n",
      "29                                                  2                   ...   \n",
      "30                                                  1                   ...   \n",
      "\n",
      "    I..The.respondent...Don.t.mind.being.the.center.of.attention..  \\\n",
      "0                                                   4                \n",
      "1                                                   2                \n",
      "2                                                   3                \n",
      "3                                                   3                \n",
      "4                                                   1                \n",
      "5                                                   4                \n",
      "6                                                   4                \n",
      "7                                                   1                \n",
      "8                                                   5                \n",
      "9                                                   4                \n",
      "10                                                  4                \n",
      "11                                                  4                \n",
      "12                                                  3                \n",
      "13                                                  2                \n",
      "14                                                  4                \n",
      "15                                                  3                \n",
      "16                                                  5                \n",
      "17                                                  4                \n",
      "18                                                  5                \n",
      "19                                                  4                \n",
      "20                                                  1                \n",
      "21                                                  5                \n",
      "22                                                  1                \n",
      "23                                                  4                \n",
      "24                                                  3                \n",
      "25                                                  4                \n",
      "26                                                  5                \n",
      "27                                                  4                \n",
      "28                                                  3                \n",
      "29                                                  3                \n",
      "30                                                  2                \n",
      "\n",
      "    I..The.respondent...Feel.others..emotions..  \\\n",
      "0                                             4   \n",
      "1                                             1   \n",
      "2                                             4   \n",
      "3                                             4   \n",
      "4                                             3   \n",
      "5                                             5   \n",
      "6                                             4   \n",
      "7                                             4   \n",
      "8                                             5   \n",
      "9                                             4   \n",
      "10                                            4   \n",
      "11                                            3   \n",
      "12                                            4   \n",
      "13                                            4   \n",
      "14                                            4   \n",
      "15                                            4   \n",
      "16                                            5   \n",
      "17                                            4   \n",
      "18                                            4   \n",
      "19                                            5   \n",
      "20                                            5   \n",
      "21                                            5   \n",
      "22                                            3   \n",
      "23                                            4   \n",
      "24                                            4   \n",
      "25                                            5   \n",
      "26                                            5   \n",
      "27                                            5   \n",
      "28                                            4   \n",
      "29                                            4   \n",
      "30                                            5   \n",
      "\n",
      "    I..The.respondent...Follow.a.schedule..  \\\n",
      "0                                         3   \n",
      "1                                         2   \n",
      "2                                         4   \n",
      "3                                         1   \n",
      "4                                         4   \n",
      "5                                         4   \n",
      "6                                         3   \n",
      "7                                         4   \n",
      "8                                         5   \n",
      "9                                         4   \n",
      "10                                        4   \n",
      "11                                        2   \n",
      "12                                        3   \n",
      "13                                        2   \n",
      "14                                        1   \n",
      "15                                        4   \n",
      "16                                        5   \n",
      "17                                        3   \n",
      "18                                        1   \n",
      "19                                        3   \n",
      "20                                        5   \n",
      "21                                        2   \n",
      "22                                        3   \n",
      "23                                        3   \n",
      "24                                        1   \n",
      "25                                        3   \n",
      "26                                        3   \n",
      "27                                        4   \n",
      "28                                        1   \n",
      "29                                        4   \n",
      "30                                        4   \n",
      "\n",
      "    I..The.respondent...Get.irritated.easily..  \\\n",
      "0                                            3   \n",
      "1                                            4   \n",
      "2                                            3   \n",
      "3                                            3   \n",
      "4                                            3   \n",
      "5                                            2   \n",
      "6                                            1   \n",
      "7                                            3   \n",
      "8                                            4   \n",
      "9                                            3   \n",
      "10                                           5   \n",
      "11                                           2   \n",
      "12                                           1   \n",
      "13                                           3   \n",
      "14                                           1   \n",
      "15                                           4   \n",
      "16                                           5   \n",
      "17                                           3   \n",
      "18                                           1   \n",
      "19                                           1   \n",
      "20                                           5   \n",
      "21                                           4   \n",
      "22                                           1   \n",
      "23                                           4   \n",
      "24                                           4   \n",
      "25                                           1   \n",
      "26                                           5   \n",
      "27                                           2   \n",
      "28                                           3   \n",
      "29                                           3   \n",
      "30                                           1   \n",
      "\n",
      "    I..The.respondent...Spend.time.reflecting.on.things..  \\\n",
      "0                                                   5       \n",
      "1                                                   5       \n",
      "2                                                   4       \n",
      "3                                                   3       \n",
      "4                                                   4       \n",
      "5                                                   4       \n",
      "6                                                   4       \n",
      "7                                                   4       \n",
      "8                                                   5       \n",
      "9                                                   4       \n",
      "10                                                  4       \n",
      "11                                                  5       \n",
      "12                                                  5       \n",
      "13                                                  4       \n",
      "14                                                  3       \n",
      "15                                                  4       \n",
      "16                                                  5       \n",
      "17                                                  4       \n",
      "18                                                  4       \n",
      "19                                                  5       \n",
      "20                                                  5       \n",
      "21                                                  5       \n",
      "22                                                  4       \n",
      "23                                                  4       \n",
      "24                                                  5       \n",
      "25                                                  1       \n",
      "26                                                  5       \n",
      "27                                                  5       \n",
      "28                                                  4       \n",
      "29                                                  4       \n",
      "30                                                  4       \n",
      "\n",
      "    I..The.respondent...Am.quiet.around.strangers..  \\\n",
      "0                                                 5   \n",
      "1                                                 5   \n",
      "2                                                 3   \n",
      "3                                                 4   \n",
      "4                                                 4   \n",
      "5                                                 1   \n",
      "6                                                 1   \n",
      "7                                                 4   \n",
      "8                                                 5   \n",
      "9                                                 1   \n",
      "10                                                4   \n",
      "11                                                3   \n",
      "12                                                3   \n",
      "13                                                5   \n",
      "14                                                1   \n",
      "15                                                5   \n",
      "16                                                5   \n",
      "17                                                3   \n",
      "18                                                3   \n",
      "19                                                4   \n",
      "20                                                1   \n",
      "21                                                2   \n",
      "22                                                3   \n",
      "23                                                4   \n",
      "24                                                5   \n",
      "25                                                1   \n",
      "26                                                3   \n",
      "27                                                3   \n",
      "28                                                3   \n",
      "29                                                1   \n",
      "30                                                4   \n",
      "\n",
      "    I..The.respondent...Make.people.feel.at.ease..  \\\n",
      "0                                                4   \n",
      "1                                                3   \n",
      "2                                                3   \n",
      "3                                                1   \n",
      "4                                                3   \n",
      "5                                                4   \n",
      "6                                                4   \n",
      "7                                                3   \n",
      "8                                                5   \n",
      "9                                                4   \n",
      "10                                               4   \n",
      "11                                               5   \n",
      "12                                               3   \n",
      "13                                               4   \n",
      "14                                               3   \n",
      "15                                               5   \n",
      "16                                               5   \n",
      "17                                               3   \n",
      "18                                               4   \n",
      "19                                               3   \n",
      "20                                               5   \n",
      "21                                               5   \n",
      "22                                               4   \n",
      "23                                               4   \n",
      "24                                               3   \n",
      "25                                               5   \n",
      "26                                               5   \n",
      "27                                               5   \n",
      "28                                               3   \n",
      "29                                               3   \n",
      "30                                               4   \n",
      "\n",
      "    I..The.respondent...Am.exacting.in.my.work..  \\\n",
      "0                                              3   \n",
      "1                                              2   \n",
      "2                                              3   \n",
      "3                                              3   \n",
      "4                                              4   \n",
      "5                                              4   \n",
      "6                                              4   \n",
      "7                                              3   \n",
      "8                                              3   \n",
      "9                                              3   \n",
      "10                                             4   \n",
      "11                                             3   \n",
      "12                                             4   \n",
      "13                                             3   \n",
      "14                                             1   \n",
      "15                                             3   \n",
      "16                                             5   \n",
      "17                                             3   \n",
      "18                                             4   \n",
      "19                                             3   \n",
      "20                                             5   \n",
      "21                                             4   \n",
      "22                                             3   \n",
      "23                                             4   \n",
      "24                                             3   \n",
      "25                                             3   \n",
      "26                                             4   \n",
      "27                                             4   \n",
      "28                                             3   \n",
      "29                                             4   \n",
      "30                                             4   \n",
      "\n",
      "    I..The.respondent...Often.feel.blue..  \\\n",
      "0                                       3   \n",
      "1                                       5   \n",
      "2                                       3   \n",
      "3                                       1   \n",
      "4                                       1   \n",
      "5                                       2   \n",
      "6                                       4   \n",
      "7                                       4   \n",
      "8                                       4   \n",
      "9                                       1   \n",
      "10                                      1   \n",
      "11                                      5   \n",
      "12                                      1   \n",
      "13                                      1   \n",
      "14                                      1   \n",
      "15                                      4   \n",
      "16                                      5   \n",
      "17                                      1   \n",
      "18                                      1   \n",
      "19                                      1   \n",
      "20                                      1   \n",
      "21                                      1   \n",
      "22                                      4   \n",
      "23                                      3   \n",
      "24                                      1   \n",
      "25                                      1   \n",
      "26                                      5   \n",
      "27                                      1   \n",
      "28                                      3   \n",
      "29                                      2   \n",
      "30                                      1   \n",
      "\n",
      "    I..The.respondent...Am.full.of.ideas..  \n",
      "0                                        3  \n",
      "1                                        5  \n",
      "2                                        4  \n",
      "3                                        1  \n",
      "4                                        5  \n",
      "5                                        5  \n",
      "6                                        5  \n",
      "7                                        4  \n",
      "8                                        3  \n",
      "9                                        3  \n",
      "10                                       5  \n",
      "11                                       4  \n",
      "12                                       3  \n",
      "13                                       5  \n",
      "14                                       1  \n",
      "15                                       4  \n",
      "16                                       5  \n",
      "17                                       3  \n",
      "18                                       4  \n",
      "19                                       4  \n",
      "20                                       1  \n",
      "21                                       4  \n",
      "22                                       3  \n",
      "23                                       5  \n",
      "24                                       4  \n",
      "25                                       3  \n",
      "26                                       4  \n",
      "27                                       5  \n",
      "28                                       4  \n",
      "29                                       4  \n",
      "30                                       4  \n",
      "\n",
      "[31 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# p = pd.DataFrame(GFG_dict)\n",
    "\n",
    "#Finding the mean of the column having NaN\n",
    "mean_value=p.mean()\n",
    "\n",
    "# Replace NaNs in column S2 with the\n",
    "# mean of values in the same column\n",
    "p.fillna(value=mean_value, inplace=True)\n",
    "print('Updated Dataframe:')\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf7cf0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a86d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E = 20 + (1) ___ - (6) ___ + (11) ___ - (16) ___ + (21) ___ - (26) ___ + (31) ___ - (36) ___ + (41) ___ - (46) ___ = _____\n",
    "# A = 14 - (2) ___ + (7) ___ - (12) ___ + (17) ___ - (22) ___ + (27) ___ - (32) ___ + (37) ___ + (42) ___ + (47) ___ = _____\n",
    "# C = 14 + (3) ___ - (8) ___ + (13) ___ - (18) ___ + (23) ___ - (28) ___ + (33) ___ - (38) ___ + (43) ___ + (48) ___ = _____\n",
    "# N = 38 - (4) ___ + (9) ___ - (14) ___ + (19) ___ - (24) ___ - (29) ___ - (34) ___ - (39) ___ - (44) ___ - (49) ___ = _____\n",
    "# O = 8 + (5) ___ - (10) ___ + (15) ___ - (20) ___ + (25) ___ - (30) ___ + (35) ___ + (40) ___ + (45) ___ + (50) ___ = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12535d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "E =20+p.iloc[:,0]-p.iloc[:,5]+p.iloc[:,10]-p.iloc[:,15]+p.iloc[:,20]-p.iloc[:,25]+p.iloc[:,30]-p.iloc[:,35]+p.iloc[:,40]-p.iloc[:,45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce89640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "A =14-p.iloc[:,1]+p.iloc[:,6]-p.iloc[:,11]+p.iloc[:,16]-p.iloc[:,21]+p.iloc[:,26]-p.iloc[:,31]+p.iloc[:,36]-p.iloc[:,41]+p.iloc[:,46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7660cc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "C =14+p.iloc[:,2]-p.iloc[:,7]+p.iloc[:,12]-p.iloc[:,17]+p.iloc[:,22]-p.iloc[:,27]+p.iloc[:,32]-p.iloc[:,37]+p.iloc[:,42]-p.iloc[:,47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed08d01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N =38-p.iloc[:,3]+p.iloc[:,8]-p.iloc[:,13]+p.iloc[:,18]-p.iloc[:,23]+p.iloc[:,28]-p.iloc[:,33]+p.iloc[:,38]-p.iloc[:,43]+p.iloc[:,48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1daca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "O =8+p.iloc[:,4]-p.iloc[:,9]+p.iloc[:,14]-p.iloc[:,19]+p.iloc[:,24]-p.iloc[:,29]+p.iloc[:,34]-p.iloc[:,39]+p.iloc[:,44]-p.iloc[:,49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00c6f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['O']=O\n",
    "new_df['C']=C\n",
    "new_df['E']=E\n",
    "new_df['A']=A\n",
    "new_df['N']=N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14c7fbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('personality_ocean.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eCN6OZvQgBXb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "id": "eCN6OZvQgBXb",
    "outputId": "82da6500-b5ee-4fce-da90-7a1d8680ed92"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['y'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-285f7bc011b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m   \u001b[0mdf_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'person_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4306\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4307\u001b[0m         \"\"\"\n\u001b[1;32m-> 4308\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4309\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4310\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4151\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4153\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4186\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4188\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4189\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5589\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5590\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5591\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5592\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5593\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['y'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "samples= list(new_df.person_id.unique())\n",
    "num_samples = len(samples)\n",
    "train_ids = random.sample(samples,round(0.8*num_samples))\n",
    "test_ids = list(set(samples)-set(train_ids))\n",
    "\n",
    "df_train=pd.DataFrame()\n",
    "for i in train_ids:\n",
    "  df_train=df_train.append(new_df[new_df['person_id']==i])\n",
    "\n",
    "df_test=pd.DataFrame()\n",
    "for i in test_ids:\n",
    "  df_test=df_test.append(new_df[new_df['person_id']==i])\n",
    "\n",
    "X_train = df_train.drop('y',axis=1)\n",
    "X_test = df_test.drop('y',axis=1)\n",
    "y_train = df_train['y']\n",
    "y_test = df_test['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8924c137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 13, 25, 14,  2,  9, 17, 16, 30, 10, 24, 12, 19,  7, 29,  5, 21,\n",
       "        3, 23, 27, 22, 15, 26, 31,  8], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.person_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7c3fa5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  4,  6, 11, 18, 20], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.person_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eaac4b05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question\n",
      "person_id\n",
      "WC\n",
      "Analytic\n",
      "Clout\n",
      "Authentic\n",
      "Tone\n",
      "WPS\n",
      "Sixltr\n",
      "Dic\n",
      "function\n",
      "pronoun\n",
      "ppron\n",
      "i\n",
      "we\n",
      "you\n",
      "shehe\n",
      "they\n",
      "ipron\n",
      "article\n",
      "prep\n",
      "auxverb\n",
      "adverb\n",
      "conj\n",
      "negate\n",
      "verb\n",
      "adj\n",
      "compare\n",
      "interrog\n",
      "number\n",
      "quant\n",
      "affect\n",
      "posemo\n",
      "negemo\n",
      "anx\n",
      "anger\n",
      "sad\n",
      "social\n",
      "family\n",
      "friend\n",
      "female\n",
      "male\n",
      "cogproc\n",
      "insight\n",
      "cause\n",
      "discrep\n",
      "tentat\n",
      "certain\n",
      "differ\n",
      "percept\n",
      "see\n",
      "hear\n",
      "feel\n",
      "bio\n",
      "body\n",
      "health\n",
      "sexual\n",
      "ingest\n",
      "drives\n",
      "affiliation\n",
      "achieve\n",
      "power\n",
      "reward\n",
      "risk\n",
      "focuspast\n",
      "focuspresent\n",
      "focusfuture\n",
      "relativ\n",
      "motion\n",
      "space\n",
      "time\n",
      "work\n",
      "leisure\n",
      "home\n",
      "money\n",
      "relig\n",
      "death\n",
      "informal\n",
      "swear\n",
      "netspeak\n",
      "assent\n",
      "nonflu\n",
      "filler\n",
      "AllPunc\n",
      "Period\n",
      "Comma\n",
      "Colon\n",
      "SemiC\n",
      "QMark\n",
      "Exclam\n",
      "Dash\n",
      "Quote\n",
      "Apostro\n",
      "Parenth\n",
      "OtherP\n",
      "positive_assumption\n",
      "negative_assumption\n"
     ]
    }
   ],
   "source": [
    "for i in X_train.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "J9q8giftkS3R",
   "metadata": {
    "id": "J9q8giftkS3R"
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reset_index()\n",
    "X_train = X_train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8f150240",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['index'],inplace=True,axis=1)\n",
    "X_test.drop(['index'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0b3ae205",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop('person_id', axis=1, inplace=True)\n",
    "X_test.drop('person_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c3929b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "03e6962c",
   "metadata": {
    "id": "03e6962c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical features: 1\n",
      "Number of numerical features: 95\n"
     ]
    }
   ],
   "source": [
    "categorical_list = []\n",
    "numerical_list = []\n",
    "for i in X_train.columns.tolist():\n",
    "    if (X_train[i].dtype=='object') or (X_train[i].dtype=='bool'):\n",
    "        categorical_list.append(i)\n",
    "    else:\n",
    "        numerical_list.append(i)\n",
    "print('Number of categorical features:', str(len(categorical_list)))\n",
    "print('Number of numerical features:', str(len(numerical_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ddddb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_list.append('positive_assumption')\n",
    "categorical_list.append('negative_assumption')\n",
    "numerical_list.remove('positive_assumption')\n",
    "numerical_list.remove('negative_assumption')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1bb1fafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "# Instantiate encoder/scaler\n",
    "scaler = StandardScaler()\n",
    "ohe    = OneHotEncoder(sparse=False,drop='if_binary')\n",
    "\n",
    "# Scale and Encode Separate Columns\n",
    "scaled_columns  = pd.DataFrame(scaler.fit_transform(X_train[numerical_list]), columns = X_train[numerical_list].columns)\n",
    "encoded_columns =    pd.DataFrame(ohe.fit_transform(X_train[categorical_list]), columns =ohe.get_feature_names(categorical_list))\n",
    "\n",
    "# Concatenate (Column-Bind) Processed Columns Back Together\n",
    "X_train = pd.concat([scaled_columns.reset_index(), encoded_columns.reset_index()], axis=1)\n",
    "X_train.drop(['index','index'], inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "06bf00ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_columns  = pd.DataFrame(scaler.transform(X_test[numerical_list]), columns = X_test[numerical_list].columns)\n",
    "encoded_columns =    pd.DataFrame(ohe.transform(X_test[categorical_list]), columns =ohe.get_feature_names(categorical_list))\n",
    "\n",
    "# Concatenate (Column-Bind) Processed Columns Back Together\n",
    "X_test = pd.concat([scaled_columns.reset_index(), encoded_columns.reset_index()], axis=1)\n",
    "X_test.drop(['index','index'], inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "L2PhhiaTe7iN",
   "metadata": {
    "id": "L2PhhiaTe7iN"
   },
   "outputs": [],
   "source": [
    "df_train = X_train.copy()\n",
    "df_train['y'] = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "323dd930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212c615f",
   "metadata": {
    "id": "212c615f"
   },
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16886033",
   "metadata": {
    "id": "16886033"
   },
   "source": [
    "### null importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "202b0e15",
   "metadata": {
    "id": "202b0e15"
   },
   "outputs": [],
   "source": [
    "# df_train = X_train.copy()\n",
    "# y_trai\n",
    "df_train['y'] = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63743cc4",
   "metadata": {
    "id": "63743cc4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86f182a",
   "metadata": {
    "id": "e86f182a"
   },
   "outputs": [],
   "source": [
    "data = df_train.copy()\n",
    "\n",
    "\n",
    "\n",
    "# categorical_feats = df_train.columns[[-1,-2,-3]]\n",
    "\n",
    "# print(categorical_feats)\n",
    "# for f_ in categorical_feats:\n",
    "#     data[f_], _ = pd.factorize(data[f_])\n",
    "#     # Set feature type as categorical\n",
    "#     data[f_] = data[f_].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3018f9",
   "metadata": {
    "id": "4c3018f9",
    "outputId": "5bbea429-51a9-410a-8b4a-17c7a60a8288"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>confidence</th>\n",
       "      <th>gaze_0_x</th>\n",
       "      <th>gaze_0_y</th>\n",
       "      <th>gaze_0_z</th>\n",
       "      <th>gaze_1_x</th>\n",
       "      <th>gaze_1_y</th>\n",
       "      <th>gaze_1_z</th>\n",
       "      <th>gaze_angle_x</th>\n",
       "      <th>gaze_angle_y</th>\n",
       "      <th>...</th>\n",
       "      <th>AU26_c</th>\n",
       "      <th>AU28_c</th>\n",
       "      <th>AU45_c</th>\n",
       "      <th>question</th>\n",
       "      <th>person_id</th>\n",
       "      <th>WC</th>\n",
       "      <th>OtherP</th>\n",
       "      <th>y</th>\n",
       "      <th>positive_assumption</th>\n",
       "      <th>negative_assumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.326309</td>\n",
       "      <td>0.274022</td>\n",
       "      <td>-0.904674</td>\n",
       "      <td>0.158873</td>\n",
       "      <td>0.243419</td>\n",
       "      <td>-0.956821</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.271</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6416</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.336460</td>\n",
       "      <td>0.274016</td>\n",
       "      <td>-0.900949</td>\n",
       "      <td>0.161493</td>\n",
       "      <td>0.241291</td>\n",
       "      <td>-0.956922</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.271</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6417</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.341593</td>\n",
       "      <td>0.269892</td>\n",
       "      <td>-0.900263</td>\n",
       "      <td>0.166425</td>\n",
       "      <td>0.237461</td>\n",
       "      <td>-0.957035</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.267</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6418</th>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.341751</td>\n",
       "      <td>0.269591</td>\n",
       "      <td>-0.900292</td>\n",
       "      <td>0.166547</td>\n",
       "      <td>0.237231</td>\n",
       "      <td>-0.957070</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.266</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6419</th>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.341803</td>\n",
       "      <td>0.269438</td>\n",
       "      <td>-0.900319</td>\n",
       "      <td>0.166416</td>\n",
       "      <td>0.237016</td>\n",
       "      <td>-0.957146</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.266</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860059</th>\n",
       "      <td>44.320000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.191839</td>\n",
       "      <td>0.410695</td>\n",
       "      <td>-0.891362</td>\n",
       "      <td>0.040223</td>\n",
       "      <td>0.424845</td>\n",
       "      <td>-0.904372</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.435</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860060</th>\n",
       "      <td>44.360001</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.189389</td>\n",
       "      <td>0.405606</td>\n",
       "      <td>-0.894212</td>\n",
       "      <td>0.039152</td>\n",
       "      <td>0.419084</td>\n",
       "      <td>-0.907103</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.429</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860061</th>\n",
       "      <td>44.400002</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.187418</td>\n",
       "      <td>0.443895</td>\n",
       "      <td>-0.876260</td>\n",
       "      <td>0.030524</td>\n",
       "      <td>0.459217</td>\n",
       "      <td>-0.887799</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.473</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860062</th>\n",
       "      <td>44.439999</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.186500</td>\n",
       "      <td>0.458894</td>\n",
       "      <td>-0.868697</td>\n",
       "      <td>0.029780</td>\n",
       "      <td>0.475174</td>\n",
       "      <td>-0.879388</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.491</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860063</th>\n",
       "      <td>44.480000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.185974</td>\n",
       "      <td>0.464983</td>\n",
       "      <td>-0.865566</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.481289</td>\n",
       "      <td>-0.876205</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.498</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>787477 rows × 718 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        timestamp  confidence  gaze_0_x  gaze_0_y  gaze_0_z  gaze_1_x  \\\n",
       "6415     0.000000        0.98  0.326309  0.274022 -0.904674  0.158873   \n",
       "6416     0.040000        0.98  0.336460  0.274016 -0.900949  0.161493   \n",
       "6417     0.080000        0.98  0.341593  0.269892 -0.900263  0.166425   \n",
       "6418     0.120000        0.98  0.341751  0.269591 -0.900292  0.166547   \n",
       "6419     0.160000        0.98  0.341803  0.269438 -0.900319  0.166416   \n",
       "...           ...         ...       ...       ...       ...       ...   \n",
       "860059  44.320000        0.98  0.191839  0.410695 -0.891362  0.040223   \n",
       "860060  44.360001        0.98  0.189389  0.405606 -0.894212  0.039152   \n",
       "860061  44.400002        0.98  0.187418  0.443895 -0.876260  0.030524   \n",
       "860062  44.439999        0.93  0.186500  0.458894 -0.868697  0.029780   \n",
       "860063  44.480000        0.98  0.185974  0.464983 -0.865566  0.025003   \n",
       "\n",
       "        gaze_1_y  gaze_1_z  gaze_angle_x  gaze_angle_y  ...  AU26_c  AU28_c  \\\n",
       "6415    0.243419 -0.956821         0.255         0.271  ...       0       0   \n",
       "6416    0.241291 -0.956922         0.262         0.271  ...       0       0   \n",
       "6417    0.237461 -0.957035         0.267         0.267  ...       0       0   \n",
       "6418    0.237231 -0.957070         0.267         0.266  ...       0       0   \n",
       "6419    0.237016 -0.957146         0.267         0.266  ...       0       0   \n",
       "...          ...       ...           ...           ...  ...     ...     ...   \n",
       "860059  0.424845 -0.904372         0.129         0.435  ...       1       0   \n",
       "860060  0.419084 -0.907103         0.126         0.429  ...       1       0   \n",
       "860061  0.459217 -0.887799         0.123         0.473  ...       0       0   \n",
       "860062  0.475174 -0.879388         0.123         0.491  ...       0       0   \n",
       "860063  0.481289 -0.876205         0.121         0.498  ...       0       0   \n",
       "\n",
       "        AU45_c  question  person_id   WC  OtherP  y  positive_assumption  \\\n",
       "6415         0         1         28  119     0.0  0                    0   \n",
       "6416         0         1         28  119     0.0  0                    0   \n",
       "6417         0         1         28  119     0.0  0                    0   \n",
       "6418         0         1         28  119     0.0  0                    0   \n",
       "6419         0         1         28  119     0.0  0                    0   \n",
       "...        ...       ...        ...  ...     ... ..                  ...   \n",
       "860059       0        24         24  100     0.0  1                    0   \n",
       "860060       0        24         24  100     0.0  1                    0   \n",
       "860061       0        24         24  100     0.0  1                    0   \n",
       "860062       0        24         24  100     0.0  1                    0   \n",
       "860063       0        24         24  100     0.0  1                    0   \n",
       "\n",
       "        negative_assumption  \n",
       "6415                      0  \n",
       "6416                      0  \n",
       "6417                      0  \n",
       "6418                      0  \n",
       "6419                      0  \n",
       "...                     ...  \n",
       "860059                    0  \n",
       "860060                    0  \n",
       "860061                    0  \n",
       "860062                    0  \n",
       "860063                    0  \n",
       "\n",
       "[787477 rows x 718 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c1b468",
   "metadata": {
    "id": "c5c1b468"
   },
   "outputs": [],
   "source": [
    "def get_feature_importances(data, shuffle, seed=None):\n",
    "    # Gather real features\n",
    "    train_features = [f for f in data if f not in ['y', 'question','WC','positive_assumption','negative_assumption']]\n",
    "    # Go over fold and keep track of CV score (train and valid) and feature importances\n",
    "    \n",
    "    # Shuffle target if required\n",
    "    y = data['y'].copy()\n",
    "    if shuffle:\n",
    "        # Here you could as well use a binomial distribution\n",
    "        y = data['y'].copy().sample(frac=1.0)\n",
    "    \n",
    "    # Fit LightGBM in RF mode, yes it's quicker than sklearn RandomForest\n",
    "    dtrain = lgb.Dataset(data[train_features], y, free_raw_data=False, silent=True)\n",
    "    lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'rf',\n",
    "        'subsample': 0.623,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'num_leaves': 127,\n",
    "        'max_depth': 8,\n",
    "        'seed': seed,\n",
    "        'bagging_freq': 1,\n",
    "        'n_jobs': 4\n",
    "    }\n",
    "    \n",
    "    # Fit the model\n",
    "    clf = lgb.train(params=lgb_params, train_set=dtrain, num_boost_round=200)\n",
    "\n",
    "    # Get feature importances\n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df[\"feature\"] = list(train_features)\n",
    "    imp_df[\"importance_gain\"] = clf.feature_importance(importance_type='gain')\n",
    "    imp_df[\"importance_split\"] = clf.feature_importance(importance_type='split')\n",
    "    imp_df['trn_score'] = roc_auc_score(y, clf.predict(data[train_features]))\n",
    "    \n",
    "    return imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f719051b",
   "metadata": {
    "id": "f719051b",
    "outputId": "6c6881d4-9139-42fe-fd92-a20720302d8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 421357, number of negative: 366120\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.064860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 176490\n",
      "[LightGBM] [Info] Number of data points in the train set: 787477, number of used features: 713\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.535072 -> initscore=0.140519\n",
      "[LightGBM] [Info] Start training from score 0.140519\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "# Get the actual importance, i.e. without shuffling\n",
    "actual_imp_df = get_feature_importances(data=data, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c53da0",
   "metadata": {
    "id": "93c53da0",
    "outputId": "ef8ccbd0-4e1b-41a6-e718-07d1c3db4a06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72580373])"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_imp_df.trn_score.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4becfe",
   "metadata": {
    "id": "9c4becfe",
    "outputId": "cd7e92ec-407b-4d72-f879-0bef5d28963e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 421357, number of negative: 366120\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.049123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 176490\n",
      "[LightGBM] [Info] Number of data points in the train set: 787477, number of used features: 713\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.535072 -> initscore=0.140519\n",
      "[LightGBM] [Info] Start training from score 0.140519\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Done with    1 of   80 (Spent   1.4 min)[LightGBM] [Info] Number of positive: 421357, number of negative: 366120\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.087780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 176490\n",
      "[LightGBM] [Info] Number of data points in the train set: 787477, number of used features: 713\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.535072 -> initscore=0.140519\n",
      "[LightGBM] [Info] Start training from score 0.140519\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Done with    2 of   80 (Spent   2.7 min)[LightGBM] [Info] Number of positive: 421357, number of negative: 366120\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.140765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 176490\n",
      "[LightGBM] [Info] Number of data points in the train set: 787477, number of used features: 713\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.535072 -> initscore=0.140519\n",
      "[LightGBM] [Info] Start training from score 0.140519\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Done with    3 of   80 (Spent   4.1 min)[LightGBM] [Info] Number of positive: 421357, number of negative: 366120\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.062056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 176490\n",
      "[LightGBM] [Info] Number of data points in the train set: 787477, number of used features: 713\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.535072 -> initscore=0.140519\n",
      "[LightGBM] [Info] Start training from score 0.140519\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Done with    4 of   80 (Spent   5.5 min)"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-15ef08f258e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_runs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Get current run importances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mimp_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_feature_importances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mimp_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'run'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Concat the latest importances with the old ones\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-bea3c00c78bd>\u001b[0m in \u001b[0;36mget_feature_importances\u001b[1;34m(data, shuffle, seed)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlgb_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# Get feature importances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;31m# construct booster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         \u001b[0mbooster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[0;32m   2227\u001b[0m                 )\n\u001b[0;32m   2228\u001b[0m             \u001b[1;31m# construct booster object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2229\u001b[1;33m             \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2230\u001b[0m             \u001b[1;31m# copy the parameters from train_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2231\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1466\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1467\u001b[0m                 \u001b[1;31m# create train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1468\u001b[1;33m                 self._lazy_init(self.data, label=self.label,\n\u001b[0m\u001b[0;32m   1469\u001b[0m                                 \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1470\u001b[0m                                 \u001b[0minit_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m   1268\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init_from_csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1270\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init_from_np2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1271\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1272\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init_from_list_np2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__init_from_np2d\u001b[1;34m(self, mat, params_str, ref_dataset)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m         \u001b[0mptr_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_ptr_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_float_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1312\u001b[1;33m         _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n\u001b[0m\u001b[0;32m   1313\u001b[0m             \u001b[0mptr_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_ptr_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "null_imp_df = pd.DataFrame()\n",
    "nb_runs = 80\n",
    "import time\n",
    "start = time.time()\n",
    "dsp = ''\n",
    "for i in range(nb_runs):\n",
    "    # Get current run importances\n",
    "    imp_df = get_feature_importances(data=data, shuffle=True)\n",
    "    imp_df['run'] = i + 1 \n",
    "    # Concat the latest importances with the old ones\n",
    "    null_imp_df = pd.concat([null_imp_df, imp_df], axis=0)\n",
    "    # Erase previous message\n",
    "    for l in range(len(dsp)):\n",
    "        print('\\b', end='', flush=True)\n",
    "    # Display current run and time used\n",
    "    spent = (time.time() - start) / 60\n",
    "    dsp = 'Done with %4d of %4d (Spent %5.1f min)' % (i + 1, nb_runs, spent)\n",
    "    print(dsp, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a745e2",
   "metadata": {
    "id": "b4a745e2"
   },
   "outputs": [],
   "source": [
    "null_imp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2e5282",
   "metadata": {
    "id": "5c2e5282"
   },
   "outputs": [],
   "source": [
    "def display_distributions(actual_imp_df_, null_imp_df_, feature_):\n",
    "    plt.figure(figsize=(13, 6))\n",
    "    gs = gridspec.GridSpec(1, 2)\n",
    "    # Plot Split importances\n",
    "    ax = plt.subplot(gs[0, 0])\n",
    "    a = ax.hist(null_imp_df_.loc[null_imp_df_['feature'] == feature_, 'importance_split'].values, label='Null importances')\n",
    "    ax.vlines(x=actual_imp_df_.loc[actual_imp_df_['feature'] == feature_, 'importance_split'].mean(), \n",
    "               ymin=0, ymax=np.max(a[0]), color='r',linewidth=10, label='Real Target')\n",
    "    ax.legend()\n",
    "    ax.set_title('Split Importance of %s' % feature_.upper(), fontweight='bold')\n",
    "    plt.xlabel('Null Importance (split) Distribution for %s ' % feature_.upper())\n",
    "    # Plot Gain importances\n",
    "    ax = plt.subplot(gs[0, 1])\n",
    "    a = ax.hist(null_imp_df_.loc[null_imp_df_['feature'] == feature_, 'importance_gain'].values, label='Null importances')\n",
    "    ax.vlines(x=actual_imp_df_.loc[actual_imp_df_['feature'] == feature_, 'importance_gain'].mean(), \n",
    "               ymin=0, ymax=np.max(a[0]), color='r',linewidth=10, label='Real Target')\n",
    "    ax.legend()\n",
    "    ax.set_title('Gain Importance of %s' % feature_.upper(), fontweight='bold')\n",
    "    plt.xlabel('Null Importance (gain) Distribution for %s ' % feature_.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5b3d6e",
   "metadata": {
    "id": "3b5b3d6e"
   },
   "outputs": [],
   "source": [
    "display_distributions(actual_imp_df_=actual_imp_df, null_imp_df_=null_imp_df, feature_='LIVINGAPARTMENTS_AVG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde625b",
   "metadata": {
    "id": "8fde625b"
   },
   "outputs": [],
   "source": [
    "feature_scores = []\n",
    "for _f in actual_imp_df['feature'].unique():\n",
    "    f_null_imps_gain = null_imp_df.loc[null_imp_df['feature'] == _f, 'importance_gain'].values\n",
    "    f_act_imps_gain = actual_imp_df.loc[actual_imp_df['feature'] == _f, 'importance_gain'].mean()\n",
    "    gain_score = np.log(1e-10 + f_act_imps_gain / (1 + np.percentile(f_null_imps_gain, 75)))  # Avoid didvide by zero\n",
    "    f_null_imps_split = null_imp_df.loc[null_imp_df['feature'] == _f, 'importance_split'].values\n",
    "    f_act_imps_split = actual_imp_df.loc[actual_imp_df['feature'] == _f, 'importance_split'].mean()\n",
    "    split_score = np.log(1e-10 + f_act_imps_split / (1 + np.percentile(f_null_imps_split, 75)))  # Avoid didvide by zero\n",
    "    feature_scores.append((_f, split_score, gain_score))\n",
    "\n",
    "scores_df = pd.DataFrame(feature_scores, columns=['feature', 'split_score', 'gain_score'])\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "gs = gridspec.GridSpec(1, 2)\n",
    "# Plot Split importances\n",
    "ax = plt.subplot(gs[0, 0])\n",
    "sns.barplot(x='split_score', y='feature', data=scores_df.sort_values('split_score', ascending=False).iloc[0:70], ax=ax)\n",
    "ax.set_title('Feature scores wrt split importances', fontweight='bold', fontsize=14)\n",
    "# Plot Gain importances\n",
    "ax = plt.subplot(gs[0, 1])\n",
    "sns.barplot(x='gain_score', y='feature', data=scores_df.sort_values('gain_score', ascending=False).iloc[0:70], ax=ax)\n",
    "ax.set_title('Feature scores wrt gain importances', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1619a55",
   "metadata": {
    "id": "b1619a55"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9dfa57c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dfa57c4",
    "outputId": "78ab6a30-deab-4cef-b7f3-8903b13f698f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 1 sample size: 372\n",
      "label 0 sample size: 351\n"
     ]
    }
   ],
   "source": [
    "application_sample1 = df_train.loc[df_train.y==1].sample(frac=1, replace=False)\n",
    "print('label 1 sample size:', str(application_sample1.shape[0]))\n",
    "application_sample0 = df_train.loc[df_train.y==0].sample(frac=1, replace=False)\n",
    "print('label 0 sample size:', str(application_sample0.shape[0]))\n",
    "application = pd.concat([application_sample1, application_sample0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f61b7526",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f61b7526",
    "outputId": "d9aa0ae0-2f79-43b1-e69b-50b3f3e7993f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical features: 0\n",
      "Number of numerical features: 125\n"
     ]
    }
   ],
   "source": [
    "categorical_list = []\n",
    "numerical_list = []\n",
    "for i in application.columns.tolist():\n",
    "    if application[i].dtype=='object':\n",
    "        categorical_list.append(i)\n",
    "    else:\n",
    "        numerical_list.append(i)\n",
    "print('Number of categorical features:', str(len(categorical_list)))\n",
    "print('Number of numerical features:', str(len(numerical_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8cdc21cd",
   "metadata": {
    "id": "8cdc21cd"
   },
   "outputs": [],
   "source": [
    "# from sklearn.impute import SimpleImputer\n",
    "# application[numerical_list] = SimpleImputer(strategy='median').fit_transform(application[numerical_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "503123a2",
   "metadata": {
    "id": "503123a2"
   },
   "outputs": [],
   "source": [
    "X = application.drop(['y'], axis=1)\n",
    "y = application.y\n",
    "feature_name = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0a0787bd",
   "metadata": {
    "id": "0a0787bd"
   },
   "outputs": [],
   "source": [
    "def cor_selector(X, y):\n",
    "    cor_list = []\n",
    "    # calculate the correlation with y for each feature\n",
    "    for i in X.columns.tolist():\n",
    "        cor = np.corrcoef(X[i], y)[0, 1]\n",
    "        cor_list.append(cor)\n",
    "    # replace NaN with 0\n",
    "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "    # feature name\n",
    "    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-150:]].columns.tolist()\n",
    "    # feature selection? 0 for not select, 1 for select\n",
    "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
    "    return cor_support, cor_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a8bb1b69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8bb1b69",
    "outputId": "79f87948-8b15-4fea-e5bb-c5beaaa533ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 selected features\n",
      "['Parenth', 'Quote', 'Exclam', 'SemiC', 'see', 'work', 'anger', 'ipron', 'space', 'you', 'adj', 'focusfuture', 'reward', 'QMark', 'conj', 'sad', 'OtherP', 'question_15', 'quant', 'motion', 'i', 'focuspresent', 'Tone', 'discrep', 'family', 'Comma', 'female', 'hear', 'they', 'posemo', 'percept', 'feel', 'pronoun', 'leisure', 'Colon', 'prep', 'we', 'Sixltr', 'cause', 'friend', 'health', 'power', 'Apostro', 'verb', 'affect', 'filler', 'male', 'swear', 'body', 'compare', 'negate', 'home', 'ppron', 'sexual', 'negemo', 'bio', 'function', 'focuspast', 'positive_assumption_1', 'question_7', 'netspeak', 'death', 'achieve', 'affiliation', 'Analytic', 'tentat', 'certain', 'money', 'WPS', 'drives', 'ingest', 'auxverb', 'shehe', 'risk', 'adverb', 'AllPunc', 'Dash', 'nonflu', 'article', 'Period', 'differ', 'relativ', 'anx', 'Authentic', 'social', 'interrog', 'insight', 'relig', 'assent', 'Clout', 'Dic', 'question_4', 'negative_assumption_1', 'time', 'informal', 'number', 'cogproc', 'WC', 'question_D_1', 'question_18', 'question_11', 'question_22', 'question_8', 'question_6', 'question_25', 'question_23', 'question_1', 'question_13', 'question_5', 'question_14', 'question_17', 'question_D_2', 'question_3', 'question_21', 'question_19', 'question_2', 'question_27', 'question_12', 'question_26', 'question_9', 'question_10', 'question_16', 'question_20', 'question_24']\n"
     ]
    }
   ],
   "source": [
    "cor_support, cor_feature = cor_selector(X, y)\n",
    "print(str(len(cor_feature)), 'selected features')\n",
    "print(cor_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ce9d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "Sx-0FAwJuP8h",
   "metadata": {
    "id": "Sx-0FAwJuP8h"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "### chi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "taPez20PuP8p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "taPez20PuP8p",
    "outputId": "47e67af1-edff-4fb3-bedd-4e5042db0e16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=100, score_func=<function chi2 at 0x000002B6BE6D5040>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_norm = MinMaxScaler().fit_transform(X_train)\n",
    "chi_selector = SelectKBest(chi2, k=100)\n",
    "chi_selector.fit(X_train.abs(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "57PwAqKMunm8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57PwAqKMunm8",
    "outputId": "19ef14d4-7e2c-46bf-dc51-34fdc0269a38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 selected features\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chi_support = chi_selector.get_support()\n",
    "chi_feature = X_train.loc[:,chi_support].columns.tolist()\n",
    "print(str(len(chi_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X4YI5-Jvmke6",
   "metadata": {
    "id": "X4YI5-Jvmke6"
   },
   "source": [
    "### RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "wnP7RlPPm-Me",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnP7RlPPm-Me",
    "outputId": "d2621c76-44ba-454a-d976-5bed1f12d9e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 50080 features.\n",
      "Fitting estimator with 48580 features.\n",
      "Fitting estimator with 47080 features.\n",
      "Fitting estimator with 45580 features.\n",
      "Fitting estimator with 44080 features.\n",
      "Fitting estimator with 42580 features.\n",
      "Fitting estimator with 41080 features.\n",
      "Fitting estimator with 39580 features.\n",
      "Fitting estimator with 38080 features.\n",
      "Fitting estimator with 36580 features.\n",
      "Fitting estimator with 35080 features.\n",
      "Fitting estimator with 33580 features.\n",
      "Fitting estimator with 32080 features.\n",
      "Fitting estimator with 30580 features.\n",
      "Fitting estimator with 29080 features.\n",
      "Fitting estimator with 27580 features.\n",
      "Fitting estimator with 26080 features.\n",
      "Fitting estimator with 24580 features.\n",
      "Fitting estimator with 23080 features.\n",
      "Fitting estimator with 21580 features.\n",
      "Fitting estimator with 20080 features.\n",
      "Fitting estimator with 18580 features.\n",
      "Fitting estimator with 17080 features.\n",
      "Fitting estimator with 15580 features.\n",
      "Fitting estimator with 14080 features.\n",
      "Fitting estimator with 12580 features.\n",
      "Fitting estimator with 11080 features.\n",
      "Fitting estimator with 9580 features.\n",
      "Fitting estimator with 8080 features.\n",
      "Fitting estimator with 6580 features.\n",
      "Fitting estimator with 5080 features.\n",
      "Fitting estimator with 3580 features.\n",
      "Fitting estimator with 2080 features.\n",
      "Fitting estimator with 580 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LogisticRegression(), n_features_to_select=100, step=1500,\n",
       "    verbose=5)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "rfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=100, step=1500, verbose=5)\n",
    "rfe_selector.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "JH_ZY9sinfZ1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JH_ZY9sinfZ1",
    "outputId": "0c7c40ec-7b82-49f7-cb70-8f52bb79813a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 selected features\n"
     ]
    }
   ],
   "source": [
    "rfe_support = rfe_selector.get_support()\n",
    "rfe_feature = X_train.loc[:,rfe_support].columns.tolist()\n",
    "print(str(len(rfe_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3h6UUJvozyA",
   "metadata": {
    "id": "f3h6UUJvozyA"
   },
   "source": [
    "### SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f1Fk8m0vpBZ9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1Fk8m0vpBZ9",
    "outputId": "27b065e1-94bd-490c-ae9e-3f3e9e77036b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19788 selected features\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "embeded_lr_selector = SelectFromModel(LogisticRegression(penalty=\"l2\"), '1.25*median')\n",
    "embeded_lr_selector.fit(X_train, y_train)\n",
    "\n",
    "embeded_lr_support = embeded_lr_selector.get_support()\n",
    "embeded_lr_feature = X_train.loc[:,embeded_lr_support].columns.tolist()\n",
    "print(str(len(embeded_lr_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lEsxM2OKpzjO",
   "metadata": {
    "id": "lEsxM2OKpzjO"
   },
   "source": [
    "### SelectFromRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "wC1Pi3Map3Y5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wC1Pi3Map3Y5",
    "outputId": "52c00fa1-fd32-4dce-8ecc-6af972284458"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50080 selected features\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=100), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X_train, y_train)\n",
    "\n",
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X_train.loc[:,embeded_rf_support].columns.tolist()\n",
    "print(str(len(embeded_rf_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uK46dJsqr1rm",
   "metadata": {
    "id": "uK46dJsqr1rm"
   },
   "source": [
    "### SelectFromlgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "Xyrl3jAsr1ro",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xyrl3jAsr1ro",
    "outputId": "788b89bd-3eda-48e7-9ef1-b2b71ace5a5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50080 selected features\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbc=LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=32, colsample_bytree=0.2,\n",
    "            reg_alpha=3, reg_lambda=1, min_split_gain=0.01, min_child_weight=40)\n",
    "\n",
    "embeded_lgb_selector = SelectFromModel(lgbc, threshold='1.25*median')\n",
    "embeded_lgb_selector.fit(X_train, y_train)\n",
    "\n",
    "embeded_lgb_support = embeded_lgb_selector.get_support()\n",
    "embeded_lgb_feature = X_train.loc[:,embeded_lgb_support].columns.tolist()\n",
    "print(str(len(embeded_lgb_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18015e10",
   "metadata": {
    "id": "18015e10"
   },
   "source": [
    "# Models correlation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "EJW0b03Tld2z",
   "metadata": {
    "id": "EJW0b03Tld2z"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "228cc777",
   "metadata": {
    "id": "228cc777"
   },
   "outputs": [],
   "source": [
    "features = X_train[cor_feature]\n",
    "features2 = X_test[cor_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4t4BH4VPklGT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4t4BH4VPklGT",
    "outputId": "7f6d0ee8-d2d0-4f41-f006-c87282438b11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "17xh_Mqoii9g",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17xh_Mqoii9g",
    "outputId": "1d51b99c-b1dd-401d-94f3-05d2e3afdf41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27     1.0\n",
       "58     0.0\n",
       "89     1.0\n",
       "120    0.0\n",
       "151    1.0\n",
       "      ... \n",
       "751    1.0\n",
       "782    1.0\n",
       "813    0.0\n",
       "844    1.0\n",
       "874    0.0\n",
       "Name: y, Length: 723, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "77380da7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77380da7",
    "outputId": "79b65b8c-7805-42bb-82e1-40f2a610ab97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93        80\n",
      "           1       0.98      0.90      0.94        94\n",
      "\n",
      "    accuracy                           0.94       174\n",
      "   macro avg       0.94      0.94      0.94       174\n",
      "weighted avg       0.94      0.94      0.94       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# X, y = load_iris(return_X_y=True)\n",
    "clf = AdaBoostClassifier()\n",
    "# scores = cross_val_score(clf, features, y_train, cv=5)\n",
    "# print(scores.mean())\n",
    "clf.fit(features, y_train)\n",
    "y_pred = (clf.predict(features2)>0.5).astype(int)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2b2c5985",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parenth\n",
      "Quote\n",
      "Exclam\n",
      "SemiC\n",
      "see\n",
      "work\n",
      "anger\n",
      "ipron\n",
      "space\n",
      "you\n",
      "adj\n",
      "focusfuture\n",
      "reward\n",
      "QMark\n",
      "conj\n",
      "sad\n",
      "OtherP\n",
      "question_15\n",
      "quant\n",
      "motion\n",
      "i\n",
      "focuspresent\n",
      "Tone\n",
      "discrep\n",
      "family\n",
      "Comma\n",
      "female\n",
      "hear\n",
      "they\n",
      "posemo\n",
      "percept\n",
      "feel\n",
      "pronoun\n",
      "leisure\n",
      "Colon\n",
      "prep\n",
      "we\n",
      "Sixltr\n",
      "cause\n",
      "friend\n",
      "health\n",
      "power\n",
      "Apostro\n",
      "verb\n",
      "affect\n",
      "filler\n",
      "male\n",
      "swear\n",
      "body\n",
      "compare\n",
      "negate\n",
      "home\n",
      "ppron\n",
      "sexual\n",
      "negemo\n",
      "bio\n",
      "function\n",
      "focuspast\n",
      "positive_assumption_1\n",
      "question_7\n",
      "netspeak\n",
      "death\n",
      "achieve\n",
      "affiliation\n",
      "Analytic\n",
      "tentat\n",
      "certain\n",
      "money\n",
      "WPS\n",
      "drives\n",
      "ingest\n",
      "auxverb\n",
      "shehe\n",
      "risk\n",
      "adverb\n",
      "AllPunc\n",
      "Dash\n",
      "nonflu\n",
      "article\n",
      "Period\n",
      "differ\n",
      "relativ\n",
      "anx\n",
      "Authentic\n",
      "social\n",
      "interrog\n",
      "insight\n",
      "relig\n",
      "assent\n",
      "Clout\n",
      "Dic\n",
      "question_4\n",
      "negative_assumption_1\n",
      "time\n",
      "informal\n",
      "number\n",
      "cogproc\n",
      "WC\n",
      "question_D_1\n",
      "question_18\n",
      "question_11\n",
      "question_22\n",
      "question_8\n",
      "question_6\n",
      "question_25\n",
      "question_23\n",
      "question_1\n",
      "question_13\n",
      "question_5\n",
      "question_14\n",
      "question_17\n",
      "question_D_2\n",
      "question_3\n",
      "question_21\n",
      "question_19\n",
      "question_2\n",
      "question_27\n",
      "question_12\n",
      "question_26\n",
      "question_9\n",
      "question_10\n",
      "question_16\n",
      "question_20\n",
      "question_24\n"
     ]
    }
   ],
   "source": [
    "for i in features.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fbbf2475",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fbbf2475",
    "outputId": "6fb87daf-fbb8-456e-ba7d-4a5b918f877b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.52      0.58        87\n",
      "         1.0       0.61      0.75      0.67        87\n",
      "\n",
      "    accuracy                           0.63       174\n",
      "   macro avg       0.64      0.63      0.63       174\n",
      "weighted avg       0.64      0.63      0.63       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svclassifier = SVC(gamma='auto')\n",
    "svclassifier.fit(features, y_train)\n",
    "y_pred = svclassifier.predict(features2)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "91072e8d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91072e8d",
    "outputId": "f56961bf-a4a8-44c8-ba99-ca876ca85ee8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93 (+/- 0.02) [DecisionTreeClassifier]\n",
      "Accuracy: 0.60 (+/- 0.04) [KNNClassifier]\n",
      "Accuracy: 0.67 (+/- 0.02) [SVC]\n",
      "Accuracy: 0.90 (+/- 0.02) [voting]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf2 = KNeighborsClassifier()\n",
    "clf3 = SVC(kernel='rbf', probability=True)\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2), ('svc', clf3)],\n",
    "                        voting='soft', weights=[2, 2, 2])\n",
    "\n",
    "clf1 = clf1.fit(features, y_train)\n",
    "clf2 = clf2.fit(features, y_train)\n",
    "clf3 = clf3.fit(features, y_train)\n",
    "eclf = eclf.fit(features, y_train)\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['DecisionTreeClassifier', 'KNNClassifier', 'SVC', 'voting']):\n",
    "    scores = cross_val_score(clf, features, y_train, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "66e5760b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier score is 64.9425287356322%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.56      0.62        87\n",
      "         1.0       0.63      0.74      0.68        87\n",
      "\n",
      "    accuracy                           0.65       174\n",
      "   macro avg       0.65      0.65      0.65       174\n",
      "weighted avg       0.65      0.65      0.65       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf', probability=True,)\n",
    "svc.fit(features, y_train)\n",
    "predictionsSVC = svc.predict(features2)\n",
    "scoreSVC = accuracy_score(y_test, predictionsSVC)\n",
    "print(f\"Support Vector Classifier score is {scoreSVC * 100}%\\n\")\n",
    "print(classification_report(y_test, predictionsSVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a8d8ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.01               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.02               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.03               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.040000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.05               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.06               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.07               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.08               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.09               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.1               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.11               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.120000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.13               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.14               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.15               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.16               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.17               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.18               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.19               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.200000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.21               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.22               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.23               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.24               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.25               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.26               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.27               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.28               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.290000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.3               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.31               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.32               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.33               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.34               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.35               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.36               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.370000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.38               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.39               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.4               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.41               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.42               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.43               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.44               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.450000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.46               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.47               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.48               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.49               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.5               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.51               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.52               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.53               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.540000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.55               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.56               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.57               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.58               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.59               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.6               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.61               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.620000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.63               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.64               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.65               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.66               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.67               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.68               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.69               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.700000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.71               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.72               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.73               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.74               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.75               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.76               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.77               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.78               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.790000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.8               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.81               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.82               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.83               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.84               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.85               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.86               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.870000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.88               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.89               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.9               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.91               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.92               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.93               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.94               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.950000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.96               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.97               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.98               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "10.99               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.01               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.02               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.03               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.040000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.05               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.06               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.07               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.08               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.09               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.1               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.11               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.120000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.13               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.14               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.15               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.16               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.17               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.18               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.19               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.200000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.21               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.22               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.23               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.24               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.25               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.26               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.27               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.28               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.290000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.3               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.31               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.32               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.33               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.34               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.35               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.36               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.370000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.38               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.39               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.4               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.41               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.42               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.43               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.44               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.450000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.46               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.47               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.48               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.49               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.5               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.51               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.52               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.53               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.540000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.55               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.56               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.57               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.58               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.59               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.6               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.61               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.620000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.63               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.64               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.65               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.66               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.67               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.68               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.69               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.700000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.71               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.72               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.73               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.74               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.75               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.76               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.77               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.78               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.790000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.8               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.81               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.82               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.83               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.84               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.85               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.86               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.870000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.88               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.89               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.9               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.91               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.92               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.93               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.94               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.950000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.96               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.97               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.98               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n",
      "11.99               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.29      0.38        45\n",
      "         1.0       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.51      0.48        87\n",
      "weighted avg       0.52      0.51      0.48        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g = [0.01*x for x in range(1000,1200)]\n",
    "# g=[x for x in [0.5, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0]]\n",
    "\n",
    "for g1 in g:\n",
    "    svc = SVC(kernel='rbf', probability=True,gamma=g1)\n",
    "    svc.fit(features, y_train)\n",
    "    predictionsSVC = svc.predict(features2)\n",
    "#     scoreSVC = accuracy_score(y_test, predictionsSVC)\n",
    "#     print(f\"Support Vector Classifier score is {scoreSVC * 100}%\\n\")\n",
    "    print(g1,classification_report(y_test, predictionsSVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20a61de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.53      0.53        45\n",
      "         1.0       0.50      0.50      0.50        42\n",
      "\n",
      "    accuracy                           0.52        87\n",
      "   macro avg       0.52      0.52      0.52        87\n",
      "weighted avg       0.52      0.52      0.52        87\n",
      "\n",
      "0.002               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.56      0.56        45\n",
      "         1.0       0.53      0.55      0.54        42\n",
      "\n",
      "    accuracy                           0.55        87\n",
      "   macro avg       0.55      0.55      0.55        87\n",
      "weighted avg       0.55      0.55      0.55        87\n",
      "\n",
      "0.003               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.56      0.56        45\n",
      "         1.0       0.53      0.55      0.54        42\n",
      "\n",
      "    accuracy                           0.55        87\n",
      "   macro avg       0.55      0.55      0.55        87\n",
      "weighted avg       0.55      0.55      0.55        87\n",
      "\n",
      "0.004               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.56      0.56        45\n",
      "         1.0       0.53      0.55      0.54        42\n",
      "\n",
      "    accuracy                           0.55        87\n",
      "   macro avg       0.55      0.55      0.55        87\n",
      "weighted avg       0.55      0.55      0.55        87\n",
      "\n",
      "0.005               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.56      0.56        45\n",
      "         1.0       0.53      0.55      0.54        42\n",
      "\n",
      "    accuracy                           0.55        87\n",
      "   macro avg       0.55      0.55      0.55        87\n",
      "weighted avg       0.55      0.55      0.55        87\n",
      "\n",
      "0.006               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.53      0.55        45\n",
      "         1.0       0.52      0.55      0.53        42\n",
      "\n",
      "    accuracy                           0.54        87\n",
      "   macro avg       0.54      0.54      0.54        87\n",
      "weighted avg       0.54      0.54      0.54        87\n",
      "\n",
      "0.007               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.53      0.55        45\n",
      "         1.0       0.52      0.55      0.53        42\n",
      "\n",
      "    accuracy                           0.54        87\n",
      "   macro avg       0.54      0.54      0.54        87\n",
      "weighted avg       0.54      0.54      0.54        87\n",
      "\n",
      "0.008               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.51      0.53        45\n",
      "         1.0       0.51      0.55      0.53        42\n",
      "\n",
      "    accuracy                           0.53        87\n",
      "   macro avg       0.53      0.53      0.53        87\n",
      "weighted avg       0.53      0.53      0.53        87\n",
      "\n",
      "0.009000000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.51      0.53        45\n",
      "         1.0       0.51      0.55      0.53        42\n",
      "\n",
      "    accuracy                           0.53        87\n",
      "   macro avg       0.53      0.53      0.53        87\n",
      "weighted avg       0.53      0.53      0.53        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g = [0.001*x for x in range(1,10,1)]\n",
    "\n",
    "for g1 in g:\n",
    "    svc = SVC(kernel='rbf', probability=True,gamma=g1)\n",
    "    svc.fit(features, y_train)\n",
    "    predictionsSVC = svc.predict(features2)\n",
    "#     scoreSVC = accuracy_score(y_test, predictionsSVC)\n",
    "#     print(f\"Support Vector Classifier score is {scoreSVC * 100}%\\n\")\n",
    "    print(g1,classification_report(y_test, predictionsSVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "be3bc1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.56               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.561               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.562               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.5630000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.5640000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.5650000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.5660000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.5670000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.5680000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.5690000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.5700000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.5710000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.5720000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.5730000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.5740000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.5750000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.5760000000000001               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.577               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.578               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.579               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.58               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.581               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.582               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.583               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.584               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.585               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.586               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.587               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.588               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.589               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.59               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.591               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.592               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.593               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.594               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.595               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.596               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.597               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.598               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.599               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.6               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.601               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.602               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.603               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.604               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.605               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.606               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.607               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.608               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.609               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.611               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.612               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.613               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.614               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.615               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.616               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.617               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.618               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.619               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.62               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.621               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.622               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.623               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.624               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.625               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.626               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.627               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.628               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.629               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.63               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.631               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.632               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.633               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.634               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.635               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.636               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.637               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.84      0.70        45\n",
      "         1.0       0.70      0.38      0.49        42\n",
      "\n",
      "    accuracy                           0.62        87\n",
      "   macro avg       0.64      0.61      0.59        87\n",
      "weighted avg       0.64      0.62      0.60        87\n",
      "\n",
      "0.638               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.84      0.69        45\n",
      "         1.0       0.68      0.36      0.47        42\n",
      "\n",
      "    accuracy                           0.61        87\n",
      "   macro avg       0.63      0.60      0.58        87\n",
      "weighted avg       0.63      0.61      0.58        87\n",
      "\n",
      "0.639               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.84      0.69        45\n",
      "         1.0       0.68      0.36      0.47        42\n",
      "\n",
      "    accuracy                           0.61        87\n",
      "   macro avg       0.63      0.60      0.58        87\n",
      "weighted avg       0.63      0.61      0.58        87\n",
      "\n",
      "0.64               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.84      0.69        45\n",
      "         1.0       0.68      0.36      0.47        42\n",
      "\n",
      "    accuracy                           0.61        87\n",
      "   macro avg       0.63      0.60      0.58        87\n",
      "weighted avg       0.63      0.61      0.58        87\n",
      "\n",
      "0.641               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.84      0.69        45\n",
      "         1.0       0.68      0.36      0.47        42\n",
      "\n",
      "    accuracy                           0.61        87\n",
      "   macro avg       0.63      0.60      0.58        87\n",
      "weighted avg       0.63      0.61      0.58        87\n",
      "\n",
      "0.642               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.84      0.69        45\n",
      "         1.0       0.68      0.36      0.47        42\n",
      "\n",
      "    accuracy                           0.61        87\n",
      "   macro avg       0.63      0.60      0.58        87\n",
      "weighted avg       0.63      0.61      0.58        87\n",
      "\n",
      "0.643               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.84      0.69        45\n",
      "         1.0       0.68      0.36      0.47        42\n",
      "\n",
      "    accuracy                           0.61        87\n",
      "   macro avg       0.63      0.60      0.58        87\n",
      "weighted avg       0.63      0.61      0.58        87\n",
      "\n",
      "0.644               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.84      0.69        45\n",
      "         1.0       0.68      0.36      0.47        42\n",
      "\n",
      "    accuracy                           0.61        87\n",
      "   macro avg       0.63      0.60      0.58        87\n",
      "weighted avg       0.63      0.61      0.58        87\n",
      "\n",
      "0.645               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.84      0.69        45\n",
      "         1.0       0.68      0.36      0.47        42\n",
      "\n",
      "    accuracy                           0.61        87\n",
      "   macro avg       0.63      0.60      0.58        87\n",
      "weighted avg       0.63      0.61      0.58        87\n",
      "\n",
      "0.646               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.84      0.69        45\n",
      "         1.0       0.68      0.36      0.47        42\n",
      "\n",
      "    accuracy                           0.61        87\n",
      "   macro avg       0.63      0.60      0.58        87\n",
      "weighted avg       0.63      0.61      0.58        87\n",
      "\n",
      "0.647               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.84      0.69        45\n",
      "         1.0       0.68      0.36      0.47        42\n",
      "\n",
      "    accuracy                           0.61        87\n",
      "   macro avg       0.63      0.60      0.58        87\n",
      "weighted avg       0.63      0.61      0.58        87\n",
      "\n",
      "0.648               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.84      0.69        45\n",
      "         1.0       0.68      0.36      0.47        42\n",
      "\n",
      "    accuracy                           0.61        87\n",
      "   macro avg       0.63      0.60      0.58        87\n",
      "weighted avg       0.63      0.61      0.58        87\n",
      "\n",
      "0.649               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.84      0.69        45\n",
      "         1.0       0.68      0.36      0.47        42\n",
      "\n",
      "    accuracy                           0.61        87\n",
      "   macro avg       0.63      0.60      0.58        87\n",
      "weighted avg       0.63      0.61      0.58        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c1= [0.001*x for x in range(560,650)]\n",
    "\n",
    "for c in c1:\n",
    "    svc = SVC(kernel='rbf', probability=True,gamma=0.004,C=c)\n",
    "    svc.fit(features, y_train)\n",
    "    predictionsSVC = svc.predict(features2)\n",
    "    print(c,classification_report(y_test, predictionsSVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4c813b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.56      0.62        87\n",
      "         1.0       0.63      0.74      0.68        87\n",
      "\n",
      "    accuracy                           0.65       174\n",
      "   macro avg       0.65      0.65      0.65       174\n",
      "weighted avg       0.65      0.65      0.65       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf')\n",
    "svc.fit(features, y_train)\n",
    "predictionsSVC = svc.predict(features2)\n",
    "print(classification_report(y_test, predictionsSVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "88238eff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 827
    },
    "id": "88238eff",
    "outputId": "c730ca44-4e59-4566-cfe7-678f468ea6ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression score is 94.82758620689656% \n",
      "\n",
      "Support Vector Classifier score is 95.97701149425288%\n",
      "\n",
      "Decision Tree Classifier score is 95.97701149425288%\n",
      "\n",
      "Random Forest Classifier score is 95.97701149425288%\n",
      "\n",
      "KNN Classifier score is 50.57471264367817% with k = 1\n",
      "KNN Classifier score is 50.0% with k = 2\n",
      "KNN Classifier score is 52.29885057471264% with k = 3\n",
      "KNN Classifier score is 56.32183908045977% with k = 4\n",
      "KNN Classifier score is 57.47126436781609% with k = 5\n",
      "KNN Classifier score is 55.74712643678161% with k = 6\n",
      "KNN Classifier score is 55.74712643678161% with k = 7\n",
      "KNN Classifier score is 58.04597701149425% with k = 8\n",
      "KNN Classifier score is 55.172413793103445% with k = 9\n",
      "KNN Classifier score is 57.47126436781609% with k = 10\n",
      "KNN Classifier score is 55.172413793103445% with k = 11\n",
      "KNN Classifier score is 57.47126436781609% with k = 12\n",
      "KNN Classifier score is 54.59770114942529% with k = 13\n",
      "KNN Classifier score is 55.74712643678161% with k = 14\n",
      "KNN Classifier score is 56.32183908045977% with k = 15\n",
      "KNN Classifier score is 56.32183908045977% with k = 16\n",
      "KNN Classifier score is 57.47126436781609% with k = 17\n",
      "KNN Classifier score is 60.3448275862069% with k = 18\n",
      "KNN Classifier score is 54.02298850574713% with k = 19\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP Classifier score is 93.10344827586206%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fitting logistic regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(features, y_train)\n",
    "predictionsLR = lr.predict(features2)\n",
    "scoreLR = accuracy_score(y_test, predictionsLR)\n",
    "print(f\"Logistic Regression score is {scoreLR * 100}% \\n\")\n",
    "\n",
    "# fitting SVC\n",
    "svc = svm.LinearSVC()\n",
    "svc.fit(features, y_train)\n",
    "predictionsSVC = svc.predict(features2)\n",
    "scoreSVC = accuracy_score(y_test, predictionsSVC)\n",
    "print(f\"Support Vector Classifier score is {scoreSVC * 100}%\\n\")\n",
    "\n",
    "# fitting decision tree classifier\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(features, y_train)\n",
    "predictionsTree = clf.predict(features2)\n",
    "scoreTree = accuracy_score(y_test, predictionsTree)\n",
    "print(f\"Decision Tree Classifier score is {scoreTree * 100}%\\n\")\n",
    "\n",
    "# fitting Random Forest classifier\n",
    "clf1 = RandomForestClassifier(max_features=23)\n",
    "clf1.fit(features, y_train)\n",
    "predictionsTree1 = clf1.predict(features2)\n",
    "scoreTree1 = accuracy_score(y_test, predictionsTree1)\n",
    "print(f\"Random Forest Classifier score is {scoreTree1 * 100}%\\n\")\n",
    "\n",
    "# fitting XGBoost\n",
    "# xgb = XGBClassifier()\n",
    "# xgb.fit(features.to_numpy(), y_train)\n",
    "# predictionsXGB = xgb.predict(X_test)\n",
    "# predictionsXGB = (predictionsXGB>0.5).astype(int)\n",
    "# scoreXGB = accuracy_score(y_test, predictionsXGB)\n",
    "# print(f\"XG Boost Classifier score is {scoreXGB * 100}%\\n\")\n",
    "\n",
    "# fitting KNN Classifier\n",
    "K = range(1, 20)\n",
    "acc = []\n",
    "for k in K:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(features, y_train)\n",
    "    predictionsKNN = knn.predict(features2)\n",
    "    scoreKNN = accuracy_score(y_test, predictionsKNN)\n",
    "    print(f\"KNN Classifier score is {scoreKNN * 100}% with k = {k}\")\n",
    "    acc.append(scoreKNN*100)\n",
    "\n",
    "# Elbow plot:\n",
    "plt.plot(K, acc)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Elbow Curve without feature selection for Inter-Reseach Area\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# MLP / ANN\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=300, activation='relu', solver='adam', random_state=1)\n",
    "classifier.fit(features, y_train)\n",
    "predictionsMLP = classifier.predict(features2)\n",
    "scoreMLP = accuracy_score(y_test, predictionsMLP)\n",
    "print(f\"\\nMLP Classifier score is {scoreMLP * 100}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0d49c220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.61      0.62        87\n",
      "         1.0       0.62      0.64      0.63        87\n",
      "\n",
      "    accuracy                           0.63       174\n",
      "   macro avg       0.63      0.63      0.63       174\n",
      "weighted avg       0.63      0.63      0.63       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=6,leaf_size=1,p=1)\n",
    "knn.fit(features,y_train)\n",
    "pred = knn.predict(features2)\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630f4b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "leaf_size = list(range(1,50))\n",
    "n_neighbors = list(range(1,30))\n",
    "p=[1,2]\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "#Create new KNN object\n",
    "knn_2 = KNeighborsClassifier()\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(knn_2, hyperparameters, cv=10)\n",
    "#Fit the model\n",
    "best_model = clf.fit(features,y_train)\n",
    "#Print The value of best Hyperparameters\n",
    "print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f148ed88",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f148ed88",
    "outputId": "d9da354f-4381-4268-8df0-204c5d6ac719"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(features, y_train).predict(features2)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "      % (X_test.shape[0], (y_test != y_pred).sum()))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "070f2d7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "070f2d7d",
    "outputId": "cf431877-dd83-4e90-e613-19aef83d7c50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      1.00      0.93        39\n",
      "         1.0       1.00      0.88      0.93        48\n",
      "\n",
      "    accuracy                           0.93        87\n",
      "   macro avg       0.93      0.94      0.93        87\n",
      "weighted avg       0.94      0.93      0.93        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "# X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# evaluate the model\n",
    "# model = GradientBoostingClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "# row = [[2.56999479, -0.13019997, 3.16075093, -4.35936352, -1.61271951, -1.39352057, -2.48924933, -1.93094078, 3.26130366, 2.05692145]]\n",
    "yhat = model.predict(features2)\n",
    "\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "236ec010",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "236ec010",
    "outputId": "20c99687-42f9-44ce-9c03-a0f43f522398"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.56      0.61        54\n",
      "         1.0       0.43      0.55      0.48        33\n",
      "\n",
      "    accuracy                           0.55        87\n",
      "   macro avg       0.55      0.55      0.54        87\n",
      "weighted avg       0.58      0.55      0.56        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# histogram-based gradient boosting for classification in scikit-learn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# evaluate the model\n",
    "# model = HistGradientBoostingClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, features, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = HistGradientBoostingClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "yhat = model.predict(features2)\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f6c009a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "7f6c009a",
    "outputId": "6612033c-34dc-40d2-efcc-72eb0b1e458c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:18:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      1.00      0.97        42\n",
      "         1.0       1.00      0.93      0.97        45\n",
      "\n",
      "    accuracy                           0.97        87\n",
      "   macro avg       0.97      0.97      0.97        87\n",
      "weighted avg       0.97      0.97      0.97        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xgboost for classification\n",
    "from numpy import asarray\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "# from sklearn.datasets import make_classification\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "# X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# evaluate the model\n",
    "# model = XGBClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, features, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = XGBClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "yhat = model.predict(features2)\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2294b541",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2294b541",
    "outputId": "3ab5d55a-c374-4759-ad71-97e3d645f029"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.98      0.95        43\n",
      "         1.0       0.98      0.93      0.95        44\n",
      "\n",
      "    accuracy                           0.95        87\n",
      "   macro avg       0.95      0.95      0.95        87\n",
      "weighted avg       0.96      0.95      0.95        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lightgbm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# evaluate the model\n",
    "# model = LGBMClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, features, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = LGBMClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "yhat = model.predict(features2)\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a2275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732a6df9",
   "metadata": {
    "id": "732a6df9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "Rl4RaMhButB_",
   "metadata": {
    "id": "Rl4RaMhButB_"
   },
   "source": [
    "# Models chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0vxQ4vywutB_",
   "metadata": {
    "id": "0vxQ4vywutB_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "D0oMFrX6utB_",
   "metadata": {
    "id": "D0oMFrX6utB_"
   },
   "outputs": [],
   "source": [
    "features = X_train[chi_feature]\n",
    "features2 = X_test[chi_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "awxGthAiutB_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "awxGthAiutB_",
    "outputId": "6baa7e87-1948-4dc5-e770-9cdd91fd4226"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "m26_abtautB_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m26_abtautB_",
    "outputId": "f12bd8d0-3047-4f6e-97b8-f219e8e224a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "Il7_aME5utCA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Il7_aME5utCA",
    "outputId": "e0f56dee-9826-4e23-8499-02b37c2ebfb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.54      0.65        69\n",
      "           1       0.24      0.56      0.33        18\n",
      "\n",
      "    accuracy                           0.54        87\n",
      "   macro avg       0.53      0.55      0.49        87\n",
      "weighted avg       0.70      0.54      0.58        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# X, y = load_iris(return_X_y=True)\n",
    "clf = AdaBoostClassifier()\n",
    "# scores = cross_val_score(clf, features, y_train, cv=5)\n",
    "# print(scores.mean())\n",
    "clf.fit(features, y_train)\n",
    "y_pred = (clf.predict(features2)>0.5).astype(int)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "QuxXByxlutCA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QuxXByxlutCA",
    "outputId": "8229f790-5371-4f67-8800-525f4c62e19b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.71      0.59        45\n",
      "         1.0       0.43      0.24      0.31        42\n",
      "\n",
      "    accuracy                           0.48        87\n",
      "   macro avg       0.47      0.47      0.45        87\n",
      "weighted avg       0.47      0.48      0.45        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svclassifier = SVC(gamma='auto')\n",
    "svclassifier.fit(features, y_train)\n",
    "y_pred = svclassifier.predict(features2)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cMi0n7AQutCA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cMi0n7AQutCA",
    "outputId": "188e629a-7cae-4ada-b8fe-79250e88cfe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65 (+/- 0.03) [DecisionTreeClassifier]\n",
      "Accuracy: 0.64 (+/- 0.03) [KNNClassifier]\n",
      "Accuracy: 0.66 (+/- 0.03) [SVC]\n",
      "Accuracy: 0.68 (+/- 0.03) [voting]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf2 = KNeighborsClassifier()\n",
    "clf3 = SVC(kernel='rbf', probability=True)\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2), ('svc', clf3)],\n",
    "                        voting='soft', weights=[2, 2, 2])\n",
    "\n",
    "clf1 = clf1.fit(features, y_train)\n",
    "clf2 = clf2.fit(features, y_train)\n",
    "clf3 = clf3.fit(features, y_train)\n",
    "eclf = eclf.fit(features, y_train)\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['DecisionTreeClassifier', 'KNNClassifier', 'SVC', 'voting']):\n",
    "    scores = cross_val_score(clf, features, y_train, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "YBuJ2yqmutCA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "YBuJ2yqmutCA",
    "outputId": "fe7662a0-23e6-4261-f06d-2fb419367958"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression score is 51.724137931034484% \n",
      "\n",
      "Support Vector Classifier score is 51.724137931034484%\n",
      "\n",
      "Decision Tree Classifier score is 50.57471264367817%\n",
      "\n",
      "Random Forest Classifier score is 52.87356321839081%\n",
      "\n",
      "KNN Classifier score is 51.724137931034484% with k = 1\n",
      "KNN Classifier score is 52.87356321839081% with k = 2\n",
      "KNN Classifier score is 52.87356321839081% with k = 3\n",
      "KNN Classifier score is 56.32183908045977% with k = 4\n",
      "KNN Classifier score is 54.02298850574713% with k = 5\n",
      "KNN Classifier score is 55.172413793103445% with k = 6\n",
      "KNN Classifier score is 54.02298850574713% with k = 7\n",
      "KNN Classifier score is 55.172413793103445% with k = 8\n",
      "KNN Classifier score is 54.02298850574713% with k = 9\n",
      "KNN Classifier score is 57.47126436781609% with k = 10\n",
      "KNN Classifier score is 56.32183908045977% with k = 11\n",
      "KNN Classifier score is 54.02298850574713% with k = 12\n",
      "KNN Classifier score is 55.172413793103445% with k = 13\n",
      "KNN Classifier score is 57.47126436781609% with k = 14\n",
      "KNN Classifier score is 57.47126436781609% with k = 15\n",
      "KNN Classifier score is 56.32183908045977% with k = 16\n",
      "KNN Classifier score is 57.47126436781609% with k = 17\n",
      "KNN Classifier score is 55.172413793103445% with k = 18\n",
      "KNN Classifier score is 57.47126436781609% with k = 19\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP Classifier score is 52.87356321839081%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fitting logistic regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(features, y_train)\n",
    "predictionsLR = lr.predict(features2)\n",
    "scoreLR = accuracy_score(y_test, predictionsLR)\n",
    "print(f\"Logistic Regression score is {scoreLR * 100}% \\n\")\n",
    "\n",
    "# fitting SVC\n",
    "svc = svm.LinearSVC()\n",
    "svc.fit(features, y_train)\n",
    "predictionsSVC = svc.predict(features2)\n",
    "scoreSVC = accuracy_score(y_test, predictionsSVC)\n",
    "print(f\"Support Vector Classifier score is {scoreSVC * 100}%\\n\")\n",
    "\n",
    "# fitting decision tree classifier\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(features, y_train)\n",
    "predictionsTree = clf.predict(features2)\n",
    "scoreTree = accuracy_score(y_test, predictionsTree)\n",
    "print(f\"Decision Tree Classifier score is {scoreTree * 100}%\\n\")\n",
    "\n",
    "# fitting Random Forest classifier\n",
    "clf1 = RandomForestClassifier(max_features=23)\n",
    "clf1.fit(features, y_train)\n",
    "predictionsTree1 = clf1.predict(features2)\n",
    "scoreTree1 = accuracy_score(y_test, predictionsTree1)\n",
    "print(f\"Random Forest Classifier score is {scoreTree1 * 100}%\\n\")\n",
    "\n",
    "# fitting XGBoost\n",
    "# xgb = XGBClassifier()\n",
    "# xgb.fit(features.to_numpy(), y_train)\n",
    "# predictionsXGB = xgb.predict(X_test)\n",
    "# predictionsXGB = (predictionsXGB>0.5).astype(int)\n",
    "# scoreXGB = accuracy_score(y_test, predictionsXGB)\n",
    "# print(f\"XG Boost Classifier score is {scoreXGB * 100}%\\n\")\n",
    "\n",
    "# fitting KNN Classifier\n",
    "K = range(1, 20)\n",
    "acc = []\n",
    "for k in K:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(features, y_train)\n",
    "    predictionsKNN = knn.predict(features2)\n",
    "    scoreKNN = accuracy_score(y_test, predictionsKNN)\n",
    "    print(f\"KNN Classifier score is {scoreKNN * 100}% with k = {k}\")\n",
    "    acc.append(scoreKNN*100)\n",
    "\n",
    "# Elbow plot:\n",
    "plt.plot(K, acc)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Elbow Curve without feature selection for Inter-Reseach Area\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# MLP / ANN\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=300, activation='relu', solver='adam', random_state=1)\n",
    "classifier.fit(features, y_train)\n",
    "predictionsMLP = classifier.predict(features2)\n",
    "scoreMLP = accuracy_score(y_test, predictionsMLP)\n",
    "print(f\"\\nMLP Classifier score is {scoreMLP * 100}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "92jo2kOtutCA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92jo2kOtutCA",
    "outputId": "89ff8df8-5c72-4b04-b159-5c07009bd96c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 87 points : 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.84      0.66        45\n",
      "         1.0       0.56      0.21      0.31        42\n",
      "\n",
      "    accuracy                           0.54        87\n",
      "   macro avg       0.55      0.53      0.48        87\n",
      "weighted avg       0.55      0.54      0.49        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(features, y_train).predict(features2)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "      % (X_test.shape[0], (y_test != y_pred).sum()))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "Kj6dYRuQutCA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kj6dYRuQutCA",
    "outputId": "f673ba74-ef52-4c7d-fab4-9041ad051c52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.53      0.63        66\n",
      "         1.0       0.26      0.52      0.35        21\n",
      "\n",
      "    accuracy                           0.53        87\n",
      "   macro avg       0.52      0.53      0.49        87\n",
      "weighted avg       0.65      0.53      0.56        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "# X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# evaluate the model\n",
    "# model = GradientBoostingClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "# row = [[2.56999479, -0.13019997, 3.16075093, -4.35936352, -1.61271951, -1.39352057, -2.48924933, -1.93094078, 3.26130366, 2.05692145]]\n",
    "yhat = model.predict(features2)\n",
    "\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "enHD5HdYutCB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "enHD5HdYutCB",
    "outputId": "3895dba7-87f7-4c46-b096-6181b8f513e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.07      0.75      0.12         4\n",
      "         1.0       0.98      0.49      0.66        83\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.62      0.39        87\n",
      "weighted avg       0.93      0.51      0.63        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# histogram-based gradient boosting for classification in scikit-learn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# evaluate the model\n",
    "# model = HistGradientBoostingClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, features, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = HistGradientBoostingClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "yhat = model.predict(features2)\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "xBesZOlkutCB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "xBesZOlkutCB",
    "outputId": "1ab49c2d-f24d-4d11-d1f1-9ecebf9b89a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:05:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.55      0.67        71\n",
      "         1.0       0.24      0.62      0.34        16\n",
      "\n",
      "    accuracy                           0.56        87\n",
      "   macro avg       0.55      0.59      0.51        87\n",
      "weighted avg       0.75      0.56      0.61        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xgboost for classification\n",
    "from numpy import asarray\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "# from sklearn.datasets import make_classification\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "# X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# evaluate the model\n",
    "# model = XGBClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, features, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = XGBClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "yhat = model.predict(features2)\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "71ZGaSpPutCB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71ZGaSpPutCB",
    "outputId": "da7db305-08d0-4720-8d64-76ce9a8b6d76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.07      0.75      0.12         4\n",
      "         1.0       0.98      0.49      0.66        83\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.52      0.62      0.39        87\n",
      "weighted avg       0.93      0.51      0.63        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lightgbm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "# from sklearn.datasets import make_classification\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# evaluate the model\n",
    "# model = LGBMClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, features, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = LGBMClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "yhat = model.predict(features2)\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZLWT-1RtutCB",
   "metadata": {
    "id": "ZLWT-1RtutCB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "VoP0_tbUmPcu",
   "metadata": {
    "id": "VoP0_tbUmPcu"
   },
   "source": [
    "# Models rfe features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ZAFnTYc2mPc1",
   "metadata": {
    "id": "ZAFnTYc2mPc1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7bI-4T2qmPc1",
   "metadata": {
    "id": "7bI-4T2qmPc1"
   },
   "outputs": [],
   "source": [
    "features = X_train[rfe_feature]\n",
    "features2 = X_test[rfe_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "xMvcCaO_mPc2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xMvcCaO_mPc2",
    "outputId": "327711eb-8f6a-4f0f-b1c3-9f76d2ec4d71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6HIGdTFWmPc2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6HIGdTFWmPc2",
    "outputId": "0e617e5f-b459-4446-fcc9-b5e02c8aa963"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3oKAnumSmPc2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3oKAnumSmPc2",
    "outputId": "b79d069c-9db2-4477-e785-adedd15956a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.49      0.56        59\n",
      "           1       0.29      0.43      0.34        28\n",
      "\n",
      "    accuracy                           0.47        87\n",
      "   macro avg       0.47      0.46      0.45        87\n",
      "weighted avg       0.53      0.47      0.49        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# X, y = load_iris(return_X_y=True)\n",
    "clf = AdaBoostClassifier()\n",
    "# scores = cross_val_score(clf, features, y_train, cv=5)\n",
    "# print(scores.mean())\n",
    "clf.fit(features, y_train)\n",
    "y_pred = (clf.predict(features2)>0.5).astype(int)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "pUUQ50WxmPc2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pUUQ50WxmPc2",
    "outputId": "119b34ca-d047-44e4-af08-07820e8fc607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.64      0.60        45\n",
      "         1.0       0.54      0.45      0.49        42\n",
      "\n",
      "    accuracy                           0.55        87\n",
      "   macro avg       0.55      0.55      0.55        87\n",
      "weighted avg       0.55      0.55      0.55        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svclassifier = SVC(gamma='auto')\n",
    "svclassifier.fit(features, y_train)\n",
    "y_pred = svclassifier.predict(features2)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "12141LsmmPc3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12141LsmmPc3",
    "outputId": "2b824337-feab-4105-b9d0-c797884bbfec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.62 (+/- 0.02) [DecisionTreeClassifier]\n",
      "Accuracy: 0.68 (+/- 0.03) [KNNClassifier]\n",
      "Accuracy: 0.72 (+/- 0.03) [SVC]\n",
      "Accuracy: 0.65 (+/- 0.03) [voting]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf2 = KNeighborsClassifier()\n",
    "clf3 = SVC(kernel='rbf', probability=True)\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2), ('svc', clf3)],\n",
    "                        voting='soft', weights=[2, 2, 2])\n",
    "\n",
    "clf1 = clf1.fit(features, y_train)\n",
    "clf2 = clf2.fit(features, y_train)\n",
    "clf3 = clf3.fit(features, y_train)\n",
    "eclf = eclf.fit(features, y_train)\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['DecisionTreeClassifier', 'KNNClassifier', 'SVC', 'voting']):\n",
    "    scores = cross_val_score(clf, features, y_train, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9ba5121f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier score is 55.172413793103445%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.64      0.60        45\n",
      "         1.0       0.54      0.45      0.49        42\n",
      "\n",
      "    accuracy                           0.55        87\n",
      "   macro avg       0.55      0.55      0.55        87\n",
      "weighted avg       0.55      0.55      0.55        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf', probability=True)\n",
    "svc.fit(features, y_train)\n",
    "predictionsSVC = svc.predict(features2)\n",
    "scoreSVC = accuracy_score(y_test, predictionsSVC)\n",
    "print(f\"Support Vector Classifier score is {scoreSVC * 100}%\\n\")\n",
    "print(classification_report(y_test,predictionsSVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ft02PlTrmPc3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 827
    },
    "id": "ft02PlTrmPc3",
    "outputId": "2c17b87c-c92c-497f-eb33-043862725a7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression score is 55.172413793103445% \n",
      "\n",
      "Support Vector Classifier score is 55.172413793103445%\n",
      "\n",
      "Decision Tree Classifier score is 51.724137931034484%\n",
      "\n",
      "Random Forest Classifier score is 48.275862068965516%\n",
      "\n",
      "KNN Classifier score is 44.827586206896555% with k = 1\n",
      "KNN Classifier score is 45.97701149425287% with k = 2\n",
      "KNN Classifier score is 45.97701149425287% with k = 3\n",
      "KNN Classifier score is 51.724137931034484% with k = 4\n",
      "KNN Classifier score is 50.57471264367817% with k = 5\n",
      "KNN Classifier score is 51.724137931034484% with k = 6\n",
      "KNN Classifier score is 45.97701149425287% with k = 7\n",
      "KNN Classifier score is 43.67816091954023% with k = 8\n",
      "KNN Classifier score is 44.827586206896555% with k = 9\n",
      "KNN Classifier score is 44.827586206896555% with k = 10\n",
      "KNN Classifier score is 44.827586206896555% with k = 11\n",
      "KNN Classifier score is 44.827586206896555% with k = 12\n",
      "KNN Classifier score is 44.827586206896555% with k = 13\n",
      "KNN Classifier score is 49.42528735632184% with k = 14\n",
      "KNN Classifier score is 45.97701149425287% with k = 15\n",
      "KNN Classifier score is 49.42528735632184% with k = 16\n",
      "KNN Classifier score is 43.67816091954023% with k = 17\n",
      "KNN Classifier score is 47.12643678160919% with k = 18\n",
      "KNN Classifier score is 44.827586206896555% with k = 19\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEWCAYAAACe8xtsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABDmElEQVR4nO2deXhcZ3Xwf0f7aJetxdbIjrc4dmwnJphA4hASO1Cy4EApBb7yEZaSUihNoGwBCnEoX8vSQguUEJaWPawBkrIkseMshRAcsshrYstOopGtxdZu7TrfH/deeazMSDPS3FnP73n06O7vmbud+57znnNEVTEMwzCMeMhLtQCGYRhG5mHKwzAMw4gbUx6GYRhG3JjyMAzDMOLGlIdhGIYRN6Y8DMMwjLhJufIQkbeIyENh8yoiq1IpU6YhIktFZEBE8mfYJmXnVUTOEZHHRKRfRP4+FTIkGxH5bxH5Jx+Oe6uI/KMPxxUR+S8R6RaRRxJ9fCM609+BmUJSlIeIHBWRIfcF5/19KRltx4KILBaRb4jIMfcFd0BEtotIWapliwVVfVZVy1V1AkBEdonIXyejbRG5WUS+O8tmHwR2qWqFqv7HPNtL2m9LNZFeKqr6TlX9pA/NXQK8HGhS1QvnezARWeZ+sBTEuH1CP25E5DIRmXTfNf0iclBE3pqo46cD7rPQLSLFqWg/mT2PV7kvOO/v75LYdlREZAHweyAAXKSqFTgPUTWwcg7Hi+lhyTHOAvamWgiw6zMDZwFHVXUw3h1TfU5naL9NVcuBSuC9wNdE5JzkSeYfIrIMeCmgwLZZto1qkZgXqur7H3AUuCLKurcAD4XNK/D3QAvQBXwWyHPX5QEfA54BOoBvA1Xuum8B/+BOB93jvMudXwWcBCRC+/8ENHttRFi/zD1WQdiyXcBfh8n/v8Dn3Tb+GegB1odtXwcMAfXu/DXA4+52vwPOi9L2duCL7nQhMAh8xp0PAMNATbiMwKeACXfdAPClsPP6TuBpoBv4snc+ZjmvlwGtka4n8EpgFBhz23oiwm/YOU2e1UAx8DngWaAduBUIuNvXAHcBna6cd+F8DRPpt83h+vzTTO1HkH8VcD/Qi3M//jBs3RrgHve4B4G/DFv338A/hc1HvebAEuBn7m8+4f6ute7vnHB/a0+U474DOOTK8EugcdqzFPGaT/uNb5/W1vYYj/1u99hHZntuXLm/DPwP0A/8AVjprnvA3XbQbf/1MZyzo8CHgCeBkfDrP8N92wG8Luye/zBw2D3nPwIWuOtKgO+6y3uAPwIN7roq4BvAMSCEcz/lu+tW4tzvJ3Dule8B1TNd5/B3IM492Q0cAa6c5Z36cZz7+t+Au6at+2/gK8Cv3HN6BdAI/NRt+wjw92HbX4jzAd3j/q4vAUWzvtdjVQDz+SN+5XEfsABYCjzF6RfB23Bu5hVAuXshvhO27k53+v+4N8UPw9b9Ikr7D+M+LFHWL2P2l9M48B6cl3cA+CbwqbDt3w38xp2+wL2JXwzkA9e556c4QttbgGZ3+mL3N/0hbN0TUR7UKfmmnde7cHpUS92b6JUxnNfLiKI83Ombge/Ocv3PkAf4As7LaAFQAdwJ/LO7biHwWqDUXfdj4OczHGsu1ydq+xFk/wHwUZyXTQlwibu8DHgOeKt73AtwXhjrwh7gf5rtmrvzT+Aot7JpbbyFsGcjwnG3uG1e4B7ri8ADsVzzGJ7DWI59j3sOn6d4p18XV+6TOC+qApwX6+3TjrcqbH7G58SdfhznhRyp/ctw71v32m0DJoEXuMtuxHn2m9zf91XgB+66v3HviVK37RcCle66n7vblgH1wCPA37jrVuFYLYpxPhgfAL7grpvtOo/hKOt84G+BNiIo+rDfdwh4lyvbGK5yCzvXvcBm97eXAo/iKJwinOe8Bfgzd/sXAi9xr8syYD9w46zv9dk2SMSfe6EHcDSb9/eOKDetEnaDuydohzu9A7c34c6f4564Ahyt3+OerFvdG8C7eb4FvC+KbE8D75xB9mXM/nJ6dto+VwAtYfP/C7zZnf4K8Mlp2x8EXhahba93sRDnK+kjQCvOC3478B9RHtQp+aad10vC5n8EfDiG83oZCVQegOB8Da0MW38REb5e3XUbge5Ix5rL9ZlD+98GbsPt/YQtfz3w4LRlXwU+EfYAey/5qNfcbbuTaV/OkZ6NCMf9Bm5P1J0vd6/bstmu+WxtxXjsLbE+N67cXw9bfxVwYNr9Ga48ZnxO3HvwbTO0fxmOsujB6ZlMEPZCxHlBbg2bX8zpe/5tRLAIAA3usQJhy94I3BdFhlcDj4XdYzNd50Nh86Xu+VgU5biXuLLWuvMHgPdOu0e+HTb/Yp7/jroJ+K8ox78RuCPaufX+kunzeLWqVof9fW2GbZ8Lm34Gp8uF+/+ZaesKcLTuYRwFtRHHFngX0ObaOF+GY3qIxAmcG2c+PDdtficQEJEXi8hZrkx3uOvOAv5BRHq8P5yvp8Zpx0BVh4DdrvyXur/hdzhfFDP9pmgcD5s+hfNCgBnOa5zHj4U63C+hsN//G3c5IlIqIl8VkWdEpA/n6616nnbb8OszY/sR+CCOwnlERPaKyNvc5WcBL552Hf8KWBThGDNd8yXAM6o6PoffdcZ1U9UBnPs5GLZNtGueiGNPv+9nIx5ZYnlOnoMzRhsOiMhA2Po2Va3G8Xn8B05vKvz4d4Qdez+OgmkAvgP8FrhdRNpE5DMiUujuUwgcC9vvqzg9EESkXkRuF5GQe+9+F6h125vtOk+dG1U95U5GOz/XAXerapc7/313WTjh1+YsoHHaufyI+1sRkdUicpeIHHfl/n9hckclXZ2HSzjtYF2K04XD/X9W2HZLcUwS7e78/cBf4NjrQiJyP/BmHDv641Hauhd4jYhsV9XJCOs9B2Ip0OdOT39B6BkzqpMi8iOcr5J2HJtkv7v6ORyT1qeiyDOd+3Fu+hfg2F7vB/4Mp/v/QJR9NMryaMx0Xhtxfjsw5XwLf9HG21YXjv9nnaqGIqz/B5yez4tV9biIbAQew3mBR2ov3uszW/tn7qh6HMecgIhcAtwrIg/gXMf7VfXlsx2DGa65iFwELBWRgggvltnO7RnXzR0duBDHFj9fYjl2vNc+HmJ5Tpwui+qzzKCIVHVERD4EHBSRV6vqz93jv01V/zfKbtuB7a5j+lc4vZ5f4fQ8aqMogX92ZTpPVU+IyKtx/Afe74l2nWNGRALAXwL5IuIpnGKcD6zzVfUJ72eH7fYcTs/67CiH/QrOM/ZGVe0XkRtx3qMzkvI4jyh8QERqRGQJcAPwQ3f5D4D3ishyESnH0ZA/DLsY9wN/x+mX6i4cW/dD6g5jjcC/4XyZfMvtJSAiQRH5NxE5T1U7cR6YN4lIvvvlGcsorO/jmDb+yp32+BrwTrdXIiJSJiJXi0hFlON4CnCfqo66v+mvcW6Gzij7tOPYNWNlpvP6FFDiyliI41gPHxrYDiwTkZjuJVdBfw34vIh4X2xBEfkzd5MKnJd7jzsS7hMz/bZ4r08M7Z+BiLxORJrc2W6ch3ICp2e7WkT+r4gUun8vEpG1EQ4z0zV/BMdJ+S/u8hIR2Rz2W5tEpCjKz/k+8FYR2SjOcM3/h+MTOxrt98eBn8eOxPR7Nt7nZEbcZ+dfcez+4Ji2PxX2zNeJyLXu9OUissH9UOrDMRFNqOox4G7gX0WkUkTyRGSliLzMPWYFrnleRILAB8JEmOk6x8Orce6/c3EsGhtxBlc8iPOeiMQjQJ+IfEhEAu5zsl5EXhQmdx8wICJrcHwus5JM5XGnnBnncccM2/4Cx8HzOM7ojG+4y7+J06V8AGfEwDCOcvC4H+dEeMrjIZwv0mhf6KjqSRxn9BjwBxHpx/EB9OI4pcD58vwATrd9HY7paEZU9Q84X8WNwK/Dlu92j/clnJfRIRybZzR+h+P78H7DPpzfHfU3Af8O/IU4Y8BjiauIel5VtRfH7/R1nJf0II7fxePH7v8TIvKnGNoCZ5TMIeBht5t8L05vAxxndgCnh/Awjklptt8W7/WZqf3pvAjnvhjAcbLfoKpH3J7kK4A34HylHwc+zZmKFZj5mrsfNa/CcbY+i3NuX+/uuhOnB35cRLqYhqruAP4RZxTNMRyl+YZZfntM+HnsKNyM8wHXIyJ/OYfnJBa+ifP1/yqc++iXwN3uM/8wjm8AnJ7rT3BeqPtx3iteLNObcZzO+1y5fsJps/d2HEd/L85762dew7Nc53i4DsdX8ayqHvf+cM7TX0mEYcthbW/Eeb67cJ7nKneT9+MMMurHUdo/nH6MSHhDNQ3DMAwjZtLVbGUYhmGkMaY8DMMwjLgx5WEYhmHEjSkPwzAMI258jfMQkaM4HvwJYFxVN4nIZ3E8/6M46Tbeqqo9Mx2ntrZWly1b5qeohmEYWcejjz7aparRAmDnha+jrVzlsSksEhIReQWwU1XHReTTAKr6oZmOs2nTJt29e7dvchqGYWQjIvKoqm7y49hJN1up6t1hQX1eYjLDMAwjg/BbeShOEM6jInJ9hPVvIyyALhwRuV5EdovI7s7OaIHUhmEYRirwW3lsVtULgCuBd4vIpd4KEfkoTv6k70XaUVVvU9VNqrqprs4Xk51hGIYxR3xVHqra5v7vwMkqeyGAiFyHU+jlr9RC3A3DMDIO35SHm/yrwpvGyQO0R0ReiZNbaFtY6mHDMAwjg/BzqG4DTr58r53vq+pvROQQTvK4e9x1D6vqO32UwzAMw0gwvikPVW0Bzo+wfJVfbRqGYRjJwSLMM4QHn+5kb1tvSmVQVe54rJWOvuGUymEYRuox5ZEhfPAnT/KOb+3m1Oici5DNm9/ubee9P3yCHzwSb/VRwzCyDVMeGcDo+CTH+4Zp6x3my/cdmn0HHxganeCTd+0DoLXbxjkYRq5jyiMDON47jCosKCvitgdaaOkcSLoMX77vEKGeIWpKCwn1DCW9fcMw0gtTHhmA97L+xKvOpaQgn5vv3Ecyw2OOdA1y2wMtvOYFQTavqqXNlIdh5DymPDIAT3mc31TNe1++mgee6uS3e9uT0raqsv3OvRQV5HHTlWsI1gRo6xlmctJiOw0jlzHlkQGEuh3lsbi6hDdfdBZrFlXwybv2MTQ64Xvbd+9rZ9fBTm684mzqK0toqg4wOjFJ18CI720bhpG+mPLIANp6hqirKKa4IJ+C/DxuuXY9oZ4h353nQ6MT3HLnPs5pqOC6i5cB0FgdADC/h2HkOKY8MoBQzxBB96UNcOHyBbzmBUFue6CFI12DvrX7lV2Ok/yWa9dRmO/cKsEaUx6GYZjyyAhCPUNTL22Pm65cQ1FBHtvv3OuL8/xo1yC3PtDCtRsbefGKhVPLPSXmmdIMw8hNTHmkOar6vJ4HQH1lCTdecTa7DnZy977EOs89J3lhnvCRq9aesa6ipJCKkgIbcWUYOY4pjzSna2CU0fHJ5ykPgOsuXsY5DRXccmdinef37u/gvoOdvPflq2moLHne+mB1wMxWhpHjmPJIc7yXdCTlUZifxy3XriPUM8RXdiXGeT48NsH2O/eyuqF8ykk+naaaAK1mtjKMnMaUR5rjmYcaIygPgBevWMi1Gxu59f4WjibAef6fuw7T2j3E9m3rp5zk02msDpjZyjByHFMeaY7nmJ7uMA/nI1etTYjz/JkTg9x6/2G2nd/IRSsXRt0uWB2gb3ic/uGxObdlGEZmY8ojzQn1DFFRXEBVoDDqNg2u8/y+g53cu79jzm3dcuc+CvOEj169dsbtbLiuYRi+Kg8ROSoizSLyuIjsdpe9TkT2isikiGzys/1sINQzFNVkFc51Fy9jdUM52+/cy/BY/M7ze/e1s+NABzdccXZEJ3k4njxmujKM3CUZPY/LVXWjqnqKYg/w58ADSWg74wl1Pz/GIxKF+Xls37ae1u4h/nPX4bjaGB6bYPtde1lVX85bNy+fdfsmi/UwjJwn6WYrVd2vqgeT3W6mEinGIxoXrVzItvMbufX+wzxzInbn+a33H+a5k0Pcsm1dVCd5OLXlxRTl59FqPQ/DyFn8Vh4K3C0ij4rI9fHsKCLXi8huEdnd2dnpk3jpzcDIOL1DYzGZrTw+evVaCvOEW+7cF9P2z544xVd2Heaa8xZz8aramPbJyxMWV5fQ1mPlaA0jV/FbeWxW1QuAK4F3i8ilse6oqrep6iZV3VRXV+efhGmM51OIxWzl0VBZwg1XnM2OAx3cG0Pk+S137SU/Bif5dILVAUJWUdAwchZflYeqtrn/O4A7gAv9bC/bmBqmG0fPA+Ctm5dzdn052++a2Xm+80A79+7v4IatZ7O4Kr42LMrcMHIb35SHiJSJSIU3DbwCx1luxMhM0eUzUZifx/Zr1/HcySFuvT+y83x4bIKbf7mPlXVlMTnJp9NYHaCjf4TR8cm49zUMI/Pxs+fRADwkIk8AjwD/o6q/EZHXiEgrcBHwPyLyWx9lyGhCPUMU5gv1FcVx73vxylquOW8xX9l1mGdPPN+8dNsDLTx78hS3XLueooL4b4NgTQBVp766YRi5h2/KQ1VbVPV892+dqn7KXX6HqjaparGqNqjqn/klQ6YT6h5icVWAvDyZ0/4fvXot+XnCLXftPWP5cydP8eX7DnH1hsVsjtFJPh1vuG5rj/k9DCMXsQjzNKatZ4jG6pkD9mZicVWAG7aezb37O9h54LTz/Ja79pGfJ3zsmvic5OGcDhS0nodh5CKmPNIYJ8ajdF7HeOvm5aysK+PmX+5jeGyC+w50cM++dt6zJX4neTiLXaVmgYKGkZuY8khTxiYmae8bjmuYbiSKCpya58+ePMUXdz7NzXfuZUVdGW+/JH4neTjFBfnUVxQTMrOVYeQkBakWwIjM8d5hJhWC8zBbeWxeVcvV5y3my/c5I6++8/YL5+Qkn46Tmt3MVoaRi1jPI005PUx3fmYrj49dvZby4gKuPm8xLz07MUGXwRqL9TCMXMV6HmlKLHU84mFxVYBdH7iM6hlSu8dLU3WAe/a1Mzmpcx4RZhhGZmI9jzTFS02yuGr+ZiuP2vJiCmJIfBgrjdUBRscnOTE4mrBjGoaRGZjySFNCPUPUlhdTUpifalGi4kW+m+nKMHIPUx5pSqgntjoeqcSTz4pCGUbuYcojTXFiPBJnsvKDRisKZRg5iymPNERVaYujCFSqqAoUUlFcYGYrw8hBTHmkIScGRxkem0x75QE2XNcwchVTHmmI50OIp4JgqmisDpjZyjByEFMeaUiiYzz8xIpCGUZuYsojDfFexk0Jii73k2BNgN6hMQZGxlMtimEYScRX5SEiR0WkWUQeF5Hd7rIFInKPiDzt/q/xU4ZMJNQzRFlRPpWB9E8AcDo1u/U+DCOXSEbP43JV3aiqm9z5DwM7VPVsYIc7b4QR6nZiPETSP+VH0IbrGkZOkgqz1bXAt9zpbwGvToEMaU2oZygjnOVgUeaGkav4rTwUuFtEHhWR691lDap6DMD9X++zDBlHJsR4eNRXFFOYL6Y8DCPH8NuovllV20SkHrhHRA7EuqOrbK4HWLp0qV/ypR2nRsfpPjWWESOtAPLyhMVVNlzXMHINX3seqtrm/u8A7gAuBNpFZDGA+78jyr63qeomVd1UV5eY+hOZwNQw3QzpeQA0VpeYw9wwcgzflIeIlIlIhTcNvALYA/wSuM7d7DrgF37JkImcLgKVOcojWF1qZivDyDH8NFs1AHe4I4YKgO+r6m9E5I/Aj0Tk7cCzwOt8lCHjmFIeGWK2AkfW9r5hxiYmKUxgvRDDMNIX35SHqrYA50dYfgLY6le7mU5bzxAFeUJ9RXpn1A0nWF3CpDp115csSP/ARsMw5o99JqYZoe4hFlWVkJ9BZV29OutmujKM3MGUR5oRyqBhuh6eic1GXBlG7mDKI81o6xnOOOXh1Vm3EVeGkTuY8kgjxicmOd43nFHOcoCSwnxqy4vNbGUYOYQpjzTieN8wE5OacT0PsKJQhpFrmPJII9p6hoHMKAI1nWB1iSkPw8ghTHmkEaGeU0BmxXh4BKsDtPUMoaqpFsUwjCRgyiONyMTUJB7B6gDDY5OcGBxNtSiGYSQBUx5pRKhnmIVlRZQU5qdalLixolDGB378BDf97MmUyqCqvOqLD/Ht3x9NqRy5gCmPNCLUM5SRJiuwWA8DHny6i3v2daTUdNnWO0xzqJc/Hu1OmQy5gimPNCLUfSojTVZwut66Oc1zk8GRcY73DdM1MEJ730jK5Ghu7QWcZ8nwF1MeaYKq0tYznJEjrQAqAwWUFeWb8shRjp4YnJpuDvWmTI49btt2H/qPKY80ofvUGENjExnb8xARJ9bDzFY5SUtnmPJo7UmZHE+6yqOjf4TR8cmUyZELmPJIE6ZGWmWozwOcEVf2xZebHOlylMfSBaUp63moKntCvZQU5qFulmfDP0x5pAmZWARqOo1urIeRexzpGiRYHWDTshqaQ30pcZq39Q5zcnCUy1bXA9DaY34PPzHlkSZkg/II1gToPjXGqdHxVItiJJmWzgGW15ZxXrAqZU5zz1n+yvWLgNMZGwx/8F15iEi+iDwmIne58+eLyO9FpFlE7hSRSr9lyARC3UOUFuVTXVqYalHmjKf4zO+RW6gqLV2DLK8tY0NTFZAap/meUC/5ecLla5yeh92H/pKMnscNwP6w+a8DH1bVDcAdwAeSIEPa09YzRGN1ALdsb0YypTzMdJVTnBgcpX94nBV1ZZy7uIo8SY3yaA71cnZ9OVWBQuoqiqfS/Rj+4KvyEJEm4GocheFxDvCAO30P8Fo/ZcgUMrEI1HSmAgVNeeQU3kir5bVlBIryWVVfPjVkNll4zvINQafn4+RaM7OVn/jd8/gC8EEgfMzcHmCbO/06YEmkHUXkehHZLSK7Ozs7fRUyHcjk6HKP+ooSCvLEzAU5xpGuAQBW1JYDsD5YlfSex7HeYU4Mjk6ZzaxEgP/4pjxE5BqgQ1UfnbbqbcC7ReRRoAKImElPVW9T1U2quqmurs4vMdOCodEJTg6OZnzPIz9PWFRVYiOucoyWrkGK8vOmPn42BKvo7B+hvS95X/6eslof1vMI9QwxOWlZnv3Cz57HZmCbiBwFbge2iMh3VfWAqr5CVV8I/AA47KMMGUE2jLTysFiP3KOlc5CzFpaSn+f46zzTkTf6KRk0tzrO8nMXO+NvgtUBRscty7Of+KY8VPUmVW1S1WXAG4CdqvomEakHEJE84GPArX7JkClMKY8MN1sBFmWegxxxR1p5nNtYmXSnuecs9zJS2+AN/0lFnMcbReQp4ADQBvxXCmRIKzwzT6bmtQonWB3geN8w4xOWGiIXmJhUnjkxyIq68qllpUUFrKwrT5ry8JzlnskKTj9L9iHjHwXJaERVdwG73Ol/B/49Ge1mCqHuIfLzhIaK4lSLMm+C1QEm1anH3lRTmmpxDJ9p7T7F2ISyIqznAY7p6sFDXUmRYcpZHqY8vF68+d/8wyLM04BQzxCLKksoyM/8y2F1PXKLFjen1fK6M5XH+iQ6zac7ywGqAoVUFBeY2cpHMv9tlQVkQ4yHx1RFwV57aHOBI26Mx/Sex3lNyXOa7wn1kidMOcs9GqsDtNpHjG+Y8kgDQt2ZH+PhYSlKcouWrgEqSwpYUFZ0xvJkOs0dZ3kFgaIzyzcHayxRp5+Y8kgx4xOTHO8bzpqeR0lhPrXlRWYuyBGOdA2yvK78eWl1PKe535HmkZzlHjZs3F9MeaSYjv4RJiY1K0ZaeTRWBwhZaoic4EjnICunmaw8NiQh0twpfTs6ZSYLp7E6QO/QGAMjluXZD0x5pJhsivHwCFYHrIZ0DnBqdJy23uEzYjzCWR+soqN/hA4fneaeTyViz8NGXPnKrMpDRK5xA/oMH5iqIJhFPQ/PXJCKgkBG8jja5XwgTB9p5ZGM9OzNUZzlYP43v4lFKbwBeFpEPiMia/0WKNcITQUIlqRYksTRWB1geGyS7lNjqRbF8BGv9Gy0nse5iysRn53m0ZzlYFHmfjOr8lDVNwEvwMlB9V9uIafrRaTCd+lygFDPEAvKiigtSkq8ZlKwWI/coKXTyaYbTXmUFfvrNJ/JWQ5QX1FMYb6Y8vCJmMxRqtoH/BQnweFi4DXAn0TkPT7KlhOEuoeyqtcB9sWXKxzpGmRxVcmMHz4bglU86VOsh+cs3xCMXIw0L09YXGW51vwiFp/Hq0TkDmAnUAhcqKpXAucD7/dZvqynLYsCBD1MeeQGLdMSIkbCT6e55yzfEGGklUdjtZUI8ItYeh6vAz6vquep6mdVtQNAVU/h1OYw5oiqutHl2ZUDqrq0kNKifPviy2JUlZbOAVZEcZZ7TKVn98F0dTqyPLryCFaX2keMT8SiPD4BPOLNiEhARJYBqOoOn+TKCXpOjXFqdCLrzFYiQmO1RfdmMycHR+kbHmd5bfmM261r9M9p3hzqZVV9eURnuUewuoT2vmHGLMtzwolFefyYM8vITrjLjHnifRE1ZVGMh4dF92Y33kir6TmtpuOX01xVaQ71RXWWewRr3CzPvRa0mmhiUR4FqjpVjsudLppheyNGTlcQzC6zFVgN6WynxUuIOIvZCvyJNG/vG6FrYITzZlMe7rNl92LiiUV5dIrINm9GRK4FkpOoP8vxfALZZrYCp+dxcnCUodGJVIti+EBL1yCF+RLTYI/1wSra+0bo6E/c17+njGZylsPpZ8v8b4knFuXxTuAjIvKsiDwHfAj4m1gbEJF8EXlMRO5y5zeKyMMi8riI7BaRC+cmeubT1jNESWHe8zKSZgM24iq7OdI1wNIFpTHVoPGc5ok0XTW39szqLIewEgF2HyacWIIED6vqS4BzgXNV9WJVPRRHGzcA+8PmPwNsV9WNwMfd+ZzEq+MxPSNpNjAVKGgPbVbS0nlm6dmZmHKat/YlrP1YnOXgZXkutvvQB2IKaxaRq4F1QIn3olPVW2LYrwm4GvgU8D53sQJeVE8VTh3znCTUM5RV2XTDsS++7MWpW36KLWvqY9q+rLiAFbVlCfN7eM7yS1fXxrR9sLrElIcPzKo8RORWoBS4HPg68BeEDd2dhS8AHwTCU5ncCPxWRD6H0/O5OEq71wPXAyxdujTG5jKLtp4h1jVGjo7NdBoqisnPE7M1ZyFtPUOMTkzOGiAYzoZgFQ+3nExI+56zfMMsznKPYE2AA8f7E9K2cZpYfB4Xq+qbgW5V3Q5cBCyZbScRuQboUNVHp636W+C9qroEeC/wjUj7q+ptqrpJVTfV1dXFIGZmMTw2QdfAaNZFl3sU5OexqNK++LKRw25Oq1jNVuA4zY/3DSfEaT7lLI9VebgxR5blObHEojy8q31KRBqBMWB5DPttBraJyFGcnFhbROS7wHXAz9xtfgzkpMP8dDbd7FQeYLEe2cps2XQjkUin+VQa9hh77V6W5xODo7NvbMRMLMrjThGpBj4L/Ak4Cvxgtp1U9SZVbVLVZThp3Xe6GXrbgJe5m20Bno5f7MynbSrGI4uVR40lpctGjnQNUlFcQG157KME1wWrEuY03xPqZWVdecyZqIPmf/OFGc++WwRqh6r2AD91h9uWqOp8Ph/eAfy7iBTg9Gqun8exMpapIlBZGF3uEawOcLxvmPGJyZiGdBqZgTPSqiyuUYLlCXSaN4d6eemq2JzlcGaJgPOaqufdvuEwo/JQ1UkR+VccPweqOgKMxNuIqu4CdrnTDwEvjPcY2UaoZ4g8gYbK7AsQ9GisDjAxqXT0j2S1eS7XONI1yIuW1cS9XyKc5u19w3T2j8yaliQciznyh1g+B+8WkddKNgYjpJBQzxCLKksozOIvcov1yD6GxyYI9QzNmhAxEp7TvLM/7u/PKbzaIOfNElkeTlWgkLKifLsPE0wsb6734Ti2R0SkT0T6RSRx0T45Sqh7KKtNVmA1pLORqYSIMeS0mk4inObxOsvByfJs/rfEE0uEeYWq5qlqkapWuvPZGZyQRLI5QNBjKq+QffFlDXMZaeUx5TSfh/KI11nu0Wgj/xJOLEGCl0ZarqoPJF6c3GBiUjneO5zVI60ASosKWFBWZA9tFjEf5VFeXMDyeTrN43WWewSrAzzxXM+c2zWeTyzq+wNh0yU4cRmP4gyzNeZAR/8w45Oa9WYrcGM9zFyQNRzuHGBRZQllxfF9+XtsCFbxyJG5Oc3n4iz3CNYE6D41xqnR8bh7LUZkYjFbvSrs7+XAeqDdf9Gyl9Op2LNfeVgN6eziSAx1y2diQ7CKY71zc5rHUrM8GhbrkXjmMtSnFUeBGHNkqoJgDigPr4a0pYbIDo50DbJ8Ds5yj/XzcJo3h3oRgXMXx+9y9ZRHq/WCE0YsPo8v4mTCBUfZbASe8FGmrCcXUpN4BGsCnBqdoOfUGDVZWLcklzg5OErPqbFZS8/OhJcItDnUy+UxZuX18JzlczGZ2bDxxBPLVdgdNj0O/EBV/9cneXKCUPcQ1aWFc7YbZxLBsBFXpjwymyNdXkLEuSuPipLCOUeaN4d62TwHZzlAfUUJBXliZqsEEsvb6yfAsKpOwFRlwFJVPeWvaNlLm1sEKhcIryE9F0enkT54dcvnEiAYzoam+J3m7X3DdMzRWQ6QnycsqiqxwRsJJBafxw4g/E0XAO71R5zcIJRLyqPGAgWzhZauQQryhCXzHCXoOc27BmJ3mjfPIbJ8OpblObHEojxKVHXAm3GnS/0TKbtRVULd2R8g6FFTWkhJYZ6ZC7KAI52DLF0YW93ymfB6D/GYrubjLPdw6nrMv56I4RDLXTAoIhd4MyLyQsDeBHOkb2icwdEJmnIgxgPc1BD2xZcVHOkanJez3MNzmu9pjV15zMdZ7hGsOZ3l2Zg/sVyJG4Efi4hXa3wx8HrfJMpyWnscV1GumK0AgjWlpjwynIlJ5ciJQV52zvyres7FaT4fZ7mHl+X5eN8wTTVmPJkvsQQJ/hFYg1M+9l3A2gilZY0YyaUAQY+gBQpmPG09Q4yOx1e3fCbWB6tijvXomKez3ON0oKD/pqvJSeVbvztKz6nsrV44q/IQkXcDZaq6R1WbgXIReVesDbijsx5zC0khIj8Ukcfdv6Mi8vicpc9ApioI5ojZCpyHtmtglOGxiVSLYsyR+eS0isSGYBVtvcOciMFpHm/N8micjvXwf6Boc6iXT/xyL9/63TO+t5UqYvF5vMOtJAiAqnbjVAOMlRuA/WH7v15VN6rqRuCnnK5nnhOEeoYoLshjYQ7FPFiAVubT0unGeCSw5wGxOc09Z/m6ONKwR6KxKnkj/7zfteNA9mZyikV55IUXghKRfCCmN5+INAFXA1+PsE6AvySGeujZhDdMN5dqa3kPrZmuMpcjXYOUFxdQV1GckOOtC7qR5jE4zfeEellRWzbvoNpAUT4Ly4oIJcFs5Znknmztpb0vO0d4xaI8fgv8SES2isgWnJf9r2M8/heADwKRhje8FGhX1acj7Sgi14vIbhHZ3dnZGWNz6U+oZzinTFZgsR7ZQIubEDFRHz2VJYUxp2dvDvXO22TlEaxJzsi/5lDvlI/lvgMdvreXCmJRHh/CCRT8W+DdwJOcGTQYERG5BuiYwbn+Rmbodajqbaq6SVU31dXNf4RHuhDqzp0AQY9FlSXkiZmtMpmWzvll041ELE7zjr5h2vvm7yz3aKwKEOr21+cxMj7BU+39vOr8RoLVAe7dn6PKQ1UngYeBFmATsJUwH8YMbAa2ichR4HZgi4h8F0BECoA/B344N7Ezk+GxCboGRnJqpBVAQX4eiypLTHlkKMNjE7T1Ds0rp1UkzovBaZ4oZ7lHsMYJFPQzy/PB4/2MTSgbglVcsbaehw51ZuVgkajKQ0RWi8jHRWQ/8CXgOQBVvVxVvzTbgVX1JlVtUtVlwBuAnar6Jnf1FcABVW2d9y/III71OrbPXOt5AFZDOoN55sQpVBM30sojFqf5lLM8UcqjOsDQ2ATdp8YScrxIeL/nvKYqtqxtYHhskt8fPuFbe6lipp7HAZxexqtU9RJV/SKQKPX5BnLMUQ6nbf655vMAyyuUyZweaTW/hIjT8ZzmM5muPGd5eYIyUHu9fj8/ZJpbe6kKFNJUE+AlKxZQVpTPvfuzb9TVTMrjtcBx4D4R+ZqIbAXm5C1T1V2qek3Y/FtU9da5HCuTmYrxyMGeR2N1gOO9w0xMWlGoTKPFi/FIsNkqFqd5Ip3lwFRaID8/ZDyZRYTignxeenYdOw90ZF1BtKjKQ1XvUNXX40SX7wLeCzSIyFdE5BVJki+raO0ZQgQWVZWkWpSkE6wJMD6pdPRn57DFbOZI1yD1FcUJ+/oPx3Ga90Vc19GfWGc5nP5w80t5eM7ycJm3rK3nWO8w+45F/p2ZSiwO80FV/Z7bc2gCHgc+7Ldg2Uioe4iGihIK55mVNBNJhrnA8IeWzoGE+zs8NgQrCfUMcXLw+Wk89iTYWQ5QXVpIoDDft/sw3FnusWVNPSKwI8tGXcX1FlPVk6r6VVXd4pdA2Uxbz1BO+jvgdL1283tkHke6BllRl1h/h8dMTvPm1r6EOsvBzfJcE/AtYDXS6LDa8mI2LqlmR5bFe+TeJ3AKyaUiUNNpNOWRkXQPjtI9z7rlM+Epj0hO8+ZQL8sT6Cz38HPwxp6Q4yxfsuDM53zrmnqeeK4nq8y2pjySxOSkcqw3d4pATaesuIDq0kIzW2UYLQlOiDidypJCli0s5cnWnuet25NgZ7lHo4/KoznUy/pg5fMi8beubQCyK9rclEeS6BwYYWxCc9ZsBV4lN1MemYSXTTfRAYLhRHKad/QPc7xv2Bfl0VQT4OTgKEOjiQ3cGxmf4ODx/ogO/jWLKmisKskqv4cpjyTR6n5xN+VozwMs1iMTOdI1QH6esGSBf8WTNgSrnuc098xYiRxp5eHXiKunjg88z1nuISJsXdvAg093ZU20uSmPJOHdqLlqtgLXXNA9lHXj3bOZls5Bli4o9XWE4Iam5zvNp5zl80zDHgm//G9TkeXB6ojrt66tZ2hsgt+3ZEe0uSmPJJGLRaCm01QTYHB0gr6h8VSLYsRIouqWz0Qkp7nnLK8oKUx4e94zmGgTanOoJ6Kz3OMlKxZSWpTPziwxXZnySBKh7iGqAoW+BFplCp65oDUJldyM+TM5qRzpSnw23el4TvPw2h5+OcsBGiqKyc+ThA/eiOYs9ygpzOeSVbXs2N+eFb1vUx5JItSTuyOtPBqTWEPamD/H+oYZGZ9MeFqSSKwPVk2ZfTr7R3xzlsPpLM+J7HnM5CwP54q1DbT1DrP/WH/C2k4VpjySRFsOx3h4nC4KZT2PTMCvhIiR8Jzm3YOjvjrLPYLVAVoTqDxmcpaHc9kapzbRziwoT2vKI0mEuoemkrLlKgvLiiguyLMRVxlCMobpemwIizT3eiB+OMs9El0iINa6I/UVJZy/pDorCkSZ8kgCvUNj9I+M01idewkRwxERN9bDzFaZQEvnIGVF+dQnqG75TKybpjxW+OQs92isLuF4X+KyPDeHeqksKWBpDEOar1hTzxOtPXT2Ry+ClQmY8kgCp1Ox+zdWPlMI1iTWXGD4R0vXIMvrEle3fCaqAoWctbCUPaFe9oR6fTVZgfMsTkwq7X2J+ZDxZI7lXG1ZW48q3Hcws3sfpjySQC4XgZpOsNoqCmYKR7oGWJ4Ef4fH+mAVvzt8gmO9/jnLPTwrQCJMqKPjkxw83h+zzOcurmRxVQk7MrxAlO/KQ0TyReQxEbkrbNl7ROSgiOwVkc/4LUOqOR0gmNtmK3BGXHUNjGRNlG22MjI+QWv3kO/DdMPZEKyid8gpD+t3z6MpgbEeT7X3MzoxGbPMIsKWNfUZH22ejJ7HDcB+b0ZELgeuBc5T1XXA55IgQ0pp6xmiqCCP2jL/bcfpjjfizKvnbqQnXt3ylUlwlnuEf7l7JWr9whs23pqAXnB4zfJYuWJtA6dGJ/jDkZPzbj9V+BqxJiJNwNXAp4D3uYv/FvgXVR0BUNW0Nvz1nhrj4SPzSyfw2HM9BKsD5OX5bztOd04P103uV60RHy2d/mbTjcT6Ruflu6K2jEofneUApUUF1JQWJsRsFY+z3OOilQsJFOazY387L1tdN28ZUoHf4c5fAD4IVIQtWw28VEQ+BQwD71fVP07fUUSuB64HWLp0qc9iRmZ8YpLX3/Z7Dhyff0DPFW5K5lzHe8Ceau/nkrNrUyyNEY0jPqdij0RVaSFrF1eycYm/JiuPRBWFam6N3VnuUVKYz+ZVtezY38H2bZqUQQmJxjflISLXAB2q+qiIXDatzRrgJcCLgB+JyAqdFq+vqrcBtwFs2rQpJbH83/79Mxw43s+nXrOejUuq53WsZQvtKxscc8GK2jLuO9jB2y5ZnmpxjCi0dA5QV1Hs63DZSPzob16StDLNwerAVA9rrnjO8rduXhb3vlesrefe/e0cbO9nzSJ/zXR+4GfPYzOwTUSuAkqAShH5LtAK/MxVFo+IyCRQC3T6KEvcdPQP8/l7nuLS1XX8nwuXZuSXQbqydW093/rdMwyMjOd0rq90Jhk5rSKRTGXVWB3gwae7UJ37l3+8zvJwtqypB5za5pmoPHxT8ap6k6o2qeoy4A3ATlV9E/BzYAuAiKwGioAuv+SYK//yqwOMjE+yfds6UxwJZsuaBkYnJnno6bT6XjDCSEY23VQTrA5wanRiaoTXXIg1sjwS9ZUlnNdUlbFDdlMR5/FNYIWI7AFuB66bbrJKNX88epKfPRbiHZcuN6euD2xaVkNlSUFWpGjIRnpPjXFicDQpaUlSiTdcdz4jrppDvVSUFHDWwrkFAG9d08Bjz/XQNZB50eZJUR6quktVr3GnR1X1Taq6XlUvUNWdyZAhVsYnJvnHn++hsaqEd1++KtXiZCWF+Xlcdk499x3oSFh6CCNxtHQ5CRGTGSCYChJRFGpPqJf1jfE5y8PZ6kWbZ2Btc4swn8Z3Hnac5B9/1bmUFpk93i+2rq3nxOAoT7T2pFoUYxqpGGmVCoLV8wsUHB2f5MCx/qlKiHNhXWMliypL2GnKI7Pp7B/h3+5+ipeeXcufrVuUanGymstW15OfJxlr781mWjoHyc+TuOIWMpEFZUWUFObNOV3OfJzlHiLClrX1PPBUJyPjmRVtbsojjH/59QGGxyfMSZ4EqkoL2XRWDTvM75F2HOkaZElNgKKC7H49iAiN1YE5m632TNUsn19cytY19QyOTvCHlsyKNs/uuyMOdh89yU//1Mpfv3QFK+qy29abLmxdW8+B4/20WnGotKIlRcN0U4FTImBuymO+znKPzatqKSnMyzjTlSkPXCf5L/bSWFXCe7aYkzxZbHWj7jPtoclmnLrlyc2mm0qaaube82iep7Pcw6ttfm+G1TY35QF87w/Psv9YHx+7xpzkyWRlXTnLa8vMdJVGHO8bZnhsMuuH6Xo0VgXoGhiNO7ttIpzl4WxZ00Br9xBPtQ8k5HjJIOeVR9fACJ+7+yCXrKrlyvXmJE82W9bU8/vDJxgcGU+1KAZhpWdzxWw1x9TsiXCWh7N1rRttnkG1zXNeefzLrw8wPDbBzeYkTwlb19YzOjHJg0+nXZKBnKSl043xyJGeR3COsR575hFZHomGyhI2BKsyqhee08rj0We6+cmjrbz9khWsqs8NG2+68aJlC6goKWBnBn1xZTMtXYMECvNZVJkbhcumAgXjHK7bHOqloriAsxI4nHnLmnr+9Gw3JzIk2jxnlcfEpPKPP9/DYnOSp5TC/DxetrqOnQc6mbRo85TjJUTMlV74oqoS8iR+s9WeUC/rgpUJrdFzxdoGVGHXwczI+ZazyuN7f3iGfcf6+NjV51JmmV1TyhVrG+gaGLFo8zSgpXMwZ0xW4Hy8LKosoTUO5TE2Mcn+OGqWx8r6YCUNlcUZ4/fISeVxYmCEz/32IJtXLeSqDeYkTzUvW11HntiQ3VTj1C0/xcoccZZ7NMYZ6/FUez+j44lzlnt4tc0feKqL0fHJhB7bD3JSeXz6Nwc4NWqR5OlCTVkRm85aYFl2U8xzJ08xqbnjLPcIxhnrMRVZ3lSdcFm2rmlgYGScRzKgtnnOKY8/PdvNj3a38vZLlrOqvmL2HYyksHVtPfuP9SWkprQxNw5P1S3PrcEjweoAx3qGY87w7Iez3GPzqlqKC/K4NwNyvuWU8piYVD7+iz0sqizhPVvPTrU4RhjeOHczXaWOXMmmO53G6gDjk0pnf2yjnJpDfQl3lnsEitza5gfSP9rcd+UhIvki8piI3OXO3ywiIRF53P27ym8ZPL7/yLPsCfXx0avXWvnTNGNlXTlnLSy1LLsp5EjnILXlRVQFklu3PNV4gYKhntlzrI1NTLL/WF/CneXhbF1bz3MnhzjUkd7R5snoedwA7J+27POqutH9+1USZODk4Cif++1BLl65kGvOW5yMJo04EBG2rmngd4dPcGrUos1TQUvXQM71OuB0oGAsFQX9cpaH49U2T3cfoK/KQ0SagKuBr/vZTix85jcHGBwZNyd5GrN1bT2j45M8ZNHmKcGpW55b/g4ILwo1POu2iY4sj8TiqgDrGivTPnDW757HF4APAtPHnf2diDwpIt8UkZpIO4rI9SKyW0R2d3bOL2jmsWe7uf2Pz/G2S5ZzdoM5ydOVFy1bQEVxQUalaMgWeofG6BoYzbmRVgBlxQVUlxbGZLZqDvVSXlzAsoX+nqetaxt49JluugdHfW1nPvimPETkGqBDVR+dtuorwEpgI3AM+NdI+6vqbaq6SVU31dXVzVkOx0m+l4bKYv7enORpTVFBHpeeU8fOgx0WbZ5kctVZ7tFYFYgpRUlzqI91jf44y8PZuqaeSYX7Dqbvh5SfPY/NwDYROQrcDmwRke+qaruqTqjqJPA14EIfZeD2Pz5Lc6iXj159rjnJM4Cta+rp7B+h2TUPGMnhSJfjnF2Zgz0PcJzms5mtkuEs99gQrKKuopgdaTz60Le3qareBNwEICKXAe9X1TeJyGJVPeZu9hpgj18ynBwc5TO/OchFKxbyKnOSZwSXn1NPnsCO/e2cv6Ta17YGR8YzIpI3GRw41k+ewJIsr1sejWB1gN8fPoGqRvWJPt0+wOj4ZMJqeMxEXp6wdU09//PkMUbHJ9OyJHAqPsU/IyIbAQWOAn/jV0Of/e1Bx0l+rTnJM4WasiJeeFYNOw508L5XnONbO3fvPc67v/8nxibMPOaxbGEpxQX5qRYjJQSrAwyMjNM3NE5VaeShyslwloezZU09t//xOf549CSbV9Umpc14SIryUNVdwC53+v8mo02At1y8jA3BKlabkzyj2LKmgU//5gDHeodYXBVI+PEHR8b5xC/3sqK2nDdeuCThx89U/O7ppTOnYz2GoiqPZDnLPS45u5YPvvKctPVDZbUT4JxFFZyzyBRHpnHF2no+/ZsD7NjfwZteclbCj/+l+w5xrHeYL/2fF/DCsxYk/PhG5hFeFOrcxsqI2zSHepPiLPcoLSrgXZelb7mI9DOkGTnPqvpyli4o9SVVyeHOAb7+YAuvvaDJFIcxxemiUJGH645NTLIvSc7yTMGUh5F2eKmp//dQF0OjEwk7rqpy8y/3UlKYz4evXJOw4xqZT215EcUFebT1Rh5xlUxneaZgysNIS65Y28DI+CQPHUpctPlv9hznwae7+IeXr6auojhhxzUyHxEhWB091sNzlvuZliTTMOVhpCUXLl9AeXHiapufGh3nk3ftY82iCl/8KEbm01gdiFpR0HOWL0+SszwTMOVhpCVFBXlcurqWHfsTE23+pZ2HaOsd5pOvXk9Bvt32xvMJzlBRsDnUy7lJdJZnAvYUGWnL1jUNdPSPsKdtftHmLZ0DfO3BFv78giAvWmZOciMywZoAnf0jDI+d6WcbT2JkeSZhysNIWy47pw4R5pUoUVX5xC/3UlKQz01Xrk2gdEa24Y24OjbNaf50xwAj45OmPKZhysNIWxaWF3PB0hp2zMPv8du9jpP8veYkN2bhdGr2M01XXp41G2l1JqY8jLRm69p69oT6OB5lCOVMDI1O8Mm79rNmUQVvvsic5MbMNHlR5tNGXO0xZ3lETHkYac3WNQ3A3Gqbf/m+Q4R6hrjlWnOSG7PTUFmCCM8bcWXO8sjYE2WkNasbymmqCcRd2/xI1yC3PdDCa14Q5MLl5iQ3ZqeoII+GipIzzFbjE5PsazNneSRMeRhpjYhwxdoGHooj2tyLJC8qyOMmiyQ34iBYc2agoDnLo2PKw0h7tqypZ2R8kt8dji3a/O597dz/VCfvfflq6itLfJbOyCYaqwO09Z5WHs0WWR4VUx5G2vPiFQsoK8rn3hiG7A6NTnDLnfs4p6GC68xJbsRJsDrAsZ7hqcDUPaFeyoryWZGmadFTiSkPI+0pLsjn0tV17DzQjurM0eb/uctzkq8zJ7kRN8GaAKMTk3QOjABeGvYqc5ZHwPenS0TyReQxEblr2vL3i4iKSPqVyDLSji1r6mnvG2FvW1/UbY52DfLV+1u4dmMjL16xMInSGdlCsNoxc4Z6hqYiy81kFZlkfJrdAOwPXyAiS4CXA88moX0jC7h8TT0icG+UUVeqys13Ok7yj1xlkeTG3AhWOzXcQ91DHOocYHhskg1NkYtD5Tq+Kg8RaQKuBr4+bdXngQ/i1DE3jFmpLS/mBUuqo8Z73LOvnV0HO7nxirNpMCe5MUcaw3oeza1ezfLqFEqUvvjd8/gCjpKY9BaIyDYgpKpPzLSjiFwvIrtFZHdnZ6e/UhoZwda1DTzZ2kt735nR5sNjE9xy1z5WN5Rz3cXLUiOckRVUlBRSWVJAW8+QOctnwTflISLXAB2q+mjYslLgo8DHZ9tfVW9T1U2quqmurs4vMY0MYuvaeuD50eb/ueswrd1DbN+2nkJzkhvzJFhTSqh7yJzls+Dnk7YZ2CYiR4HbgS3Ad4DlwBPu8ibgTyKyyEc5jCzhnIYKgtWBM7LsPnNikFvvP8y28xu5aKU5yY35E6wu4dmTp9hnzvIZ8U15qOpNqtqkqsuANwA7VfW1qlqvqsvc5a3ABap63C85jOxBRNi6tp6HDnVO1VzYfuc+CvOEj15tTnIjMQSrAzzdYc7y2bA+vpFRbF3bwPDYJL8/fIJ797Wz80AHN16x2pzkRsIIutl1AUtLMgMFyWhEVXcBuyIsX5aM9o3s4cXLF1BalM//NB/jD0dOcHZ9OW/ZvCzVYhlZhFcUqrQon+W15SmWJn1JivIwjERRUpjPS8+u5SePtgLw/Xe82JzkRkLxikKta6wk35zlUbGnzsg4tq51anxcc95iLl5pCQqMxOKZrcxZPjPW8zAyjqs2LGZfWx/vunxlqkUxspC68mLe9/LVXLVhcapFSWtktkRz6cCmTZt09+7dqRbDMAwjoxCRR1V1kx/HNrOVYRiGETemPAzDMIy4MeVhGIZhxI0pD8MwDCNuTHkYhmEYcWPKwzAMw4gbUx6GYRhG3JjyMAzDMOImI4IERaQTeCbVcsxCLdCVaiFiwORMLJkiJ2SOrCZn4jhLVX2pppcRyiMTEJHdfkVyJhKTM7FkipyQObKanJmBma0MwzCMuDHlYRiGYcSNKY/EcVuqBYgRkzOxZIqckDmympwZgPk8DMMwjLixnodhGIYRN6Y8DMMwjLgx5REjIrJERO4Tkf0isldEboiwzWUi0isij7t/H0+FrK4sR0Wk2ZXjeZW0xOE/ROSQiDwpIhekQMZzws7V4yLSJyI3TtsmJedURL4pIh0isids2QIRuUdEnnb/10TZ95UictA9tx9OkayfFZED7rW9Q0Sqo+w7432SBDlvFpFQ2PW9Ksq+STunUeT8YZiMR0Xk8Sj7Ju18phxVtb8Y/oDFwAXudAXwFHDutG0uA+5KtayuLEeB2hnWXwX8GhDgJcAfUixvPnAcJ6gp5ecUuBS4ANgTtuwzwIfd6Q8Dn47yOw4DK4Ai4Inp90mSZH0FUOBOfzqSrLHcJ0mQ82bg/THcG0k7p5HknLb+X4GPp/p8pvrPeh4xoqrHVPVP7nQ/sB8IplaqeXEt8G11eBioFpFUFm3eChxW1bTIJKCqDwAnpy2+FviWO/0t4NURdr0QOKSqLao6Ctzu7ucbkWRV1btVddydfRho8lOGWIhyTmMhqed0JjlFRIC/BH7gV/uZgimPOSAiy4AXAH+IsPoiEXlCRH4tIuuSK9kZKHC3iDwqItdHWB8EngubbyW1yvANRH8g0+WcNqjqMXA+JoD6CNuk23kFeBtOLzMSs90nyeDvXPPaN6OYAtPpnL4UaFfVp6OsT4fzmRRMecSJiJQDPwVuVNW+aav/hGN2OR/4IvDzJIsXzmZVvQC4Eni3iFw6bb1E2Ccl47ZFpAjYBvw4wup0OqexkDbnFUBEPgqMA9+Lssls94nffAVYCWwEjuGYhKaTTuf0jczc60j1+UwapjziQEQKcRTH91T1Z9PXq2qfqg64078CCkWkNslierK0uf87gDtwuv7htAJLwuabgLbkSPc8rgT+pKrt01ek0zkF2j3Tnvu/I8I2aXNeReQ64Brgr9Q1yE8nhvvEV1S1XVUnVHUS+FqU9tPinIpIAfDnwA+jbZPq85lMTHnEiGvr/AawX1X/Lco2i9ztEJELcc7vieRJOSVHmYhUeNM4ztM90zb7JfBmd9TVS4BezySTAqJ+zaXLOXX5JXCdO30d8IsI2/wROFtElrs9qje4+yUVEXkl8CFgm6qeirJNLPeJr0zzs70mSvtpcU6BK4ADqtoaaWU6nM+kkmqPfab8AZfgdJWfBB53/64C3gm8093m74C9OKNBHgYuTpGsK1wZnnDl+ai7PFxWAb6MM4qlGdiUIllLcZRBVdiylJ9THGV2DBjD+fJ9O7AQ2AE87f5f4G7bCPwqbN+rcEbjHfbOfQpkPYTjJ/Du1VunyxrtPkmynN9x778ncRTC4lSf00hyusv/27svw7ZN2flM9Z+lJzEMwzDixsxWhmEYRtyY8jAMwzDixpSHYRiGETemPAzDMIy4MeVhGIZhxI0pD8OYAyIyEDZ9lZtpd2kqZTKMZFKQagEMI5MRka04aVNeoarPploew0gWpjwMY46IyEtxUmpcpaqHUy2PYSQTCxI0jDkgImNAP3CZqj6ZankMI9mYz8Mw5sYY8DucFBuGkXOY8jCMuTGJUxToRSLykVQLYxjJxnwehjFHVPWUiFwDPCgi7ar6jVTLZBjJwpSHYcwDVT3ppj9/QES6VDVSmnbDyDrMYW4YhmHEjfk8DMMwjLgx5WEYhmHEjSkPwzAMI25MeRiGYRhxY8rDMAzDiBtTHoZhGEbcmPIwDMMw4ub/A8o4rKmxjRsFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP Classifier score is 49.42528735632184%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fitting logistic regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(features, y_train)\n",
    "predictionsLR = lr.predict(features2)\n",
    "scoreLR = accuracy_score(y_test, predictionsLR)\n",
    "print(f\"Logistic Regression score is {scoreLR * 100}% \\n\")\n",
    "\n",
    "# fitting SVC\n",
    "svc = svm.LinearSVC()\n",
    "svc.fit(features, y_train)\n",
    "predictionsSVC = svc.predict(features2)\n",
    "scoreSVC = accuracy_score(y_test, predictionsSVC)\n",
    "print(f\"Support Vector Classifier score is {scoreSVC * 100}%\\n\")\n",
    "\n",
    "# fitting decision tree classifier\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(features, y_train)\n",
    "predictionsTree = clf.predict(features2)\n",
    "scoreTree = accuracy_score(y_test, predictionsTree)\n",
    "print(f\"Decision Tree Classifier score is {scoreTree * 100}%\\n\")\n",
    "\n",
    "# fitting Random Forest classifier\n",
    "clf1 = RandomForestClassifier(max_features=23)\n",
    "clf1.fit(features, y_train)\n",
    "predictionsTree1 = clf1.predict(features2)\n",
    "scoreTree1 = accuracy_score(y_test, predictionsTree1)\n",
    "print(f\"Random Forest Classifier score is {scoreTree1 * 100}%\\n\")\n",
    "\n",
    "# fitting XGBoost\n",
    "# xgb = XGBClassifier()\n",
    "# xgb.fit(features.to_numpy(), y_train)\n",
    "# predictionsXGB = xgb.predict(X_test)\n",
    "# predictionsXGB = (predictionsXGB>0.5).astype(int)\n",
    "# scoreXGB = accuracy_score(y_test, predictionsXGB)\n",
    "# print(f\"XG Boost Classifier score is {scoreXGB * 100}%\\n\")\n",
    "\n",
    "# fitting KNN Classifier\n",
    "K = range(1, 20)\n",
    "acc = []\n",
    "for k in K:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(features, y_train)\n",
    "    predictionsKNN = knn.predict(features2)\n",
    "    scoreKNN = accuracy_score(y_test, predictionsKNN)\n",
    "    print(f\"KNN Classifier score is {scoreKNN * 100}% with k = {k}\")\n",
    "    acc.append(scoreKNN*100)\n",
    "\n",
    "# Elbow plot:\n",
    "plt.plot(K, acc)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Elbow Curve without feature selection for Inter-Reseach Area\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# MLP / ANN\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=300, activation='relu', solver='adam', random_state=1)\n",
    "classifier.fit(features, y_train)\n",
    "predictionsMLP = classifier.predict(features2)\n",
    "scoreMLP = accuracy_score(y_test, predictionsMLP)\n",
    "print(f\"\\nMLP Classifier score is {scoreMLP * 100}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "yc8ST0-KmPc3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yc8ST0-KmPc3",
    "outputId": "70a837cf-0a7a-46c1-d476-e1e6a5a43af8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 87 points : 38\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(features, y_train).predict(features2)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "      % (X_test.shape[0], (y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "db697daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.55      0.67        71\n",
      "         1.0       0.24      0.62      0.34        16\n",
      "\n",
      "    accuracy                           0.56        87\n",
      "   macro avg       0.55      0.59      0.51        87\n",
      "weighted avg       0.75      0.56      0.61        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "MzUZBG3OmPc3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MzUZBG3OmPc3",
    "outputId": "ebb3f185-8cfd-40c0-b260-ffda72b5b491"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.57      0.60        51\n",
      "         1.0       0.48      0.56      0.51        36\n",
      "\n",
      "    accuracy                           0.56        87\n",
      "   macro avg       0.56      0.56      0.56        87\n",
      "weighted avg       0.57      0.56      0.57        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "# X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# evaluate the model\n",
    "# model = GradientBoostingClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "# row = [[2.56999479, -0.13019997, 3.16075093, -4.35936352, -1.61271951, -1.39352057, -2.48924933, -1.93094078, 3.26130366, 2.05692145]]\n",
    "yhat = model.predict(features2)\n",
    "\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "gl9ZEeFImPc4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gl9ZEeFImPc4",
    "outputId": "d130c683-b2eb-4b37-b00e-6a33d3ef5ad6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.50      0.54        52\n",
      "         1.0       0.38      0.46      0.42        35\n",
      "\n",
      "    accuracy                           0.48        87\n",
      "   macro avg       0.48      0.48      0.48        87\n",
      "weighted avg       0.50      0.48      0.49        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# histogram-based gradient boosting for classification in scikit-learn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# evaluate the model\n",
    "# model = HistGradientBoostingClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, features, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = HistGradientBoostingClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "yhat = model.predict(features2)\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "chk-JdFmmPc4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "chk-JdFmmPc4",
    "outputId": "bb271dec-ea1e-4d10-f2c6-1512a8968b2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.52      0.54        48\n",
      "         1.0       0.45      0.49      0.47        39\n",
      "\n",
      "    accuracy                           0.51        87\n",
      "   macro avg       0.50      0.50      0.50        87\n",
      "weighted avg       0.51      0.51      0.51        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xgboost for classification\n",
    "from numpy import asarray\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# evaluate the model\n",
    "# model = XGBClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, features, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = XGBClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "yhat = model.predict(features2)\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "yTS9Ii_zmPc4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yTS9Ii_zmPc4",
    "outputId": "b8e75f5b-28f3-48ed-8c5f-16b05301df9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.48      0.52        52\n",
      "         1.0       0.36      0.43      0.39        35\n",
      "\n",
      "    accuracy                           0.46        87\n",
      "   macro avg       0.46      0.45      0.45        87\n",
      "weighted avg       0.48      0.46      0.46        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lightgbm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# evaluate the model\n",
    "# model = LGBMClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, features, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = LGBMClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "yhat = model.predict(features2)\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "RKVX4MyBmPc4",
   "metadata": {
    "id": "RKVX4MyBmPc4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1r_X3Et_owwx",
   "metadata": {
    "id": "1r_X3Et_owwx"
   },
   "source": [
    "# Models embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pPK2Yxltoww6",
   "metadata": {
    "id": "pPK2Yxltoww6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "nIWGQWBOoww6",
   "metadata": {
    "id": "nIWGQWBOoww6"
   },
   "outputs": [],
   "source": [
    "features = X_train[embeded_lr_feature]\n",
    "features2 = X_test[embeded_lr_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "NHYfxjl7oww6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NHYfxjl7oww6",
    "outputId": "da6939bb-d592-4436-fa01-ea7bd295481e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 139,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9-7uYPMDoww7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-7uYPMDoww7",
    "outputId": "353d454a-29b9-4322-de7f-3043930e8af5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 140,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "gpV4yAsvoww7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gpV4yAsvoww7",
    "outputId": "01cc12c2-a00f-490a-9f5e-35c720e0a380"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.52      0.39        27\n",
      "           1       0.69      0.48      0.57        60\n",
      "\n",
      "    accuracy                           0.49        87\n",
      "   macro avg       0.50      0.50      0.48        87\n",
      "weighted avg       0.57      0.49      0.51        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# X, y = load_iris(return_X_y=True)\n",
    "clf = AdaBoostClassifier()\n",
    "# scores = cross_val_score(clf, features, y_train, cv=5)\n",
    "# print(scores.mean())\n",
    "clf.fit(features, y_train)\n",
    "y_pred = (clf.predict(features2)>0.5).astype(int)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "AAJHjOUvoww7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AAJHjOUvoww7",
    "outputId": "42a5dccf-450f-428e-a326-f4e29fd0147e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.20      0.29        45\n",
      "           1       0.49      0.81      0.61        42\n",
      "\n",
      "    accuracy                           0.49        87\n",
      "   macro avg       0.51      0.50      0.45        87\n",
      "weighted avg       0.51      0.49      0.44        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svclassifier = SVC(gamma='auto')\n",
    "svclassifier.fit(features, y_train)\n",
    "y_pred = svclassifier.predict(features2)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "Zc-QrRafoww7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zc-QrRafoww7",
    "outputId": "b70423ec-217b-4c83-df64-985cb4bdbc79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.51 (+/- 0.04) [DecisionTreeClassifier]\n",
      "Accuracy: 0.54 (+/- 0.01) [KNNClassifier]\n",
      "Accuracy: 0.59 (+/- 0.02) [SVC]\n",
      "Accuracy: 0.53 (+/- 0.04) [voting]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf2 = KNeighborsClassifier()\n",
    "clf3 = SVC(kernel='rbf', probability=True)\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2), ('svc', clf3)],\n",
    "                        voting='soft', weights=[2, 2, 2])\n",
    "\n",
    "clf1 = clf1.fit(features, y_train)\n",
    "clf2 = clf2.fit(features, y_train)\n",
    "clf3 = clf3.fit(features, y_train)\n",
    "eclf = eclf.fit(features, y_train)\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['DecisionTreeClassifier', 'KNNClassifier', 'SVC', 'voting']):\n",
    "    scores = cross_val_score(clf, features, y_train, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "Eq9XOSgqoww8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 827
    },
    "id": "Eq9XOSgqoww8",
    "outputId": "71677c5e-90c3-4307-e3f8-d80b7348b426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression score is 56.32183908045977% \n",
      "\n",
      "Support Vector Classifier score is 55.172413793103445%\n",
      "\n",
      "Decision Tree Classifier score is 47.12643678160919%\n",
      "\n",
      "Random Forest Classifier score is 48.275862068965516%\n",
      "\n",
      "KNN Classifier score is 48.275862068965516% with k = 1\n",
      "KNN Classifier score is 49.42528735632184% with k = 2\n",
      "KNN Classifier score is 44.827586206896555% with k = 3\n",
      "KNN Classifier score is 42.5287356321839% with k = 4\n",
      "KNN Classifier score is 45.97701149425287% with k = 5\n",
      "KNN Classifier score is 42.5287356321839% with k = 6\n",
      "KNN Classifier score is 51.724137931034484% with k = 7\n",
      "KNN Classifier score is 49.42528735632184% with k = 8\n",
      "KNN Classifier score is 49.42528735632184% with k = 9\n",
      "KNN Classifier score is 51.724137931034484% with k = 10\n",
      "KNN Classifier score is 50.57471264367817% with k = 11\n",
      "KNN Classifier score is 44.827586206896555% with k = 12\n",
      "KNN Classifier score is 45.97701149425287% with k = 13\n",
      "KNN Classifier score is 48.275862068965516% with k = 14\n",
      "KNN Classifier score is 49.42528735632184% with k = 15\n",
      "KNN Classifier score is 51.724137931034484% with k = 16\n",
      "KNN Classifier score is 51.724137931034484% with k = 17\n",
      "KNN Classifier score is 51.724137931034484% with k = 18\n",
      "KNN Classifier score is 50.57471264367817% with k = 19\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP Classifier score is 50.57471264367817%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fitting logistic regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(features, y_train)\n",
    "predictionsLR = lr.predict(features2)\n",
    "scoreLR = accuracy_score(y_test, predictionsLR)\n",
    "print(f\"Logistic Regression score is {scoreLR * 100}% \\n\")\n",
    "\n",
    "# fitting SVC\n",
    "svc = svm.LinearSVC()\n",
    "svc.fit(features, y_train)\n",
    "predictionsSVC = svc.predict(features2)\n",
    "scoreSVC = accuracy_score(y_test, predictionsSVC)\n",
    "print(f\"Support Vector Classifier score is {scoreSVC * 100}%\\n\")\n",
    "\n",
    "# fitting decision tree classifier\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(features, y_train)\n",
    "predictionsTree = clf.predict(features2)\n",
    "scoreTree = accuracy_score(y_test, predictionsTree)\n",
    "print(f\"Decision Tree Classifier score is {scoreTree * 100}%\\n\")\n",
    "\n",
    "# fitting Random Forest classifier\n",
    "clf1 = RandomForestClassifier(max_features=23)\n",
    "clf1.fit(features, y_train)\n",
    "predictionsTree1 = clf1.predict(features2)\n",
    "scoreTree1 = accuracy_score(y_test, predictionsTree1)\n",
    "print(f\"Random Forest Classifier score is {scoreTree1 * 100}%\\n\")\n",
    "\n",
    "# fitting XGBoost\n",
    "# xgb = XGBClassifier()\n",
    "# xgb.fit(features.to_numpy(), y_train)\n",
    "# predictionsXGB = xgb.predict(X_test)\n",
    "# predictionsXGB = (predictionsXGB>0.5).astype(int)\n",
    "# scoreXGB = accuracy_score(y_test, predictionsXGB)\n",
    "# print(f\"XG Boost Classifier score is {scoreXGB * 100}%\\n\")\n",
    "\n",
    "# fitting KNN Classifier\n",
    "K = range(1, 20)\n",
    "acc = []\n",
    "for k in K:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(features, y_train)\n",
    "    predictionsKNN = knn.predict(features2)\n",
    "    scoreKNN = accuracy_score(y_test, predictionsKNN)\n",
    "    print(f\"KNN Classifier score is {scoreKNN * 100}% with k = {k}\")\n",
    "    acc.append(scoreKNN*100)\n",
    "\n",
    "# Elbow plot:\n",
    "plt.plot(K, acc)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Elbow Curve without feature selection for Inter-Reseach Area\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# MLP / ANN\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=300, activation='relu', solver='adam', random_state=1)\n",
    "classifier.fit(features, y_train)\n",
    "predictionsMLP = classifier.predict(features2)\n",
    "scoreMLP = accuracy_score(y_test, predictionsMLP)\n",
    "print(f\"\\nMLP Classifier score is {scoreMLP * 100}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6hGyZp0qoww8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6hGyZp0qoww8",
    "outputId": "d6e255f4-7e11-4d9b-f9d6-e3bf7afa77f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 87 points : 44\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(features, y_train).predict(features2)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "      % (X_test.shape[0], (y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3qjXatsCoww8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3qjXatsCoww8",
    "outputId": "c0ce3641-71ae-4cf5-f773-5a0a062407f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.52      0.37        25\n",
      "           1       0.71      0.48      0.58        62\n",
      "\n",
      "    accuracy                           0.49        87\n",
      "   macro avg       0.50      0.50      0.47        87\n",
      "weighted avg       0.59      0.49      0.52        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "# X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# evaluate the model\n",
    "# model = GradientBoostingClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "# row = [[2.56999479, -0.13019997, 3.16075093, -4.35936352, -1.61271951, -1.39352057, -2.48924933, -1.93094078, 3.26130366, 2.05692145]]\n",
    "yhat = model.predict(features2)\n",
    "\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "aF0L1T-roww9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aF0L1T-roww9",
    "outputId": "7b01d0f1-71c3-4760-8934-c4eab9d2ccf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.60      0.37        20\n",
      "           1       0.81      0.51      0.62        67\n",
      "\n",
      "    accuracy                           0.53        87\n",
      "   macro avg       0.54      0.55      0.50        87\n",
      "weighted avg       0.68      0.53      0.57        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# histogram-based gradient boosting for classification in scikit-learn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# evaluate the model\n",
    "# model = HistGradientBoostingClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, features, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = HistGradientBoostingClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "yhat = model.predict(features2)\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "E8MzWy3goww9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "E8MzWy3goww9",
    "outputId": "bb271dec-ea1e-4d10-f2c6-1512a8968b2e"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-3e5eb772ea61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# fit the model on the whole dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;31m# make a single prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m             train_dmatrix = DMatrix(X, label=training_labels,\n\u001b[0;32m--> 726\u001b[0;31m                                     missing=self.missing, nthread=self.n_jobs)\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         self._Booster = train(xgb_options, train_dmatrix, self.get_num_boosting_rounds(),\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[1;32m    424\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mfeature_names\u001b[0;34m(self, feature_names)\u001b[0m\n\u001b[1;32m    868\u001b[0m                        \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'['\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m']'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'<'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m                        for f in feature_names):\n\u001b[0;32m--> 870\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feature_names may not contain [, ] or <'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# reset feature_types also\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names may not contain [, ] or <"
     ]
    }
   ],
   "source": [
    "# xgboost for classification\n",
    "from numpy import asarray\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# evaluate the model\n",
    "# model = XGBClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, features, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = XGBClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "yhat = model.predict(features2)\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "Tdax6s_Ooww9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tdax6s_Ooww9",
    "outputId": "775d69c5-06ca-4c3c-f428-59688a9936a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.65      0.35        17\n",
      "           1       0.86      0.51      0.64        70\n",
      "\n",
      "    accuracy                           0.54        87\n",
      "   macro avg       0.55      0.58      0.50        87\n",
      "weighted avg       0.74      0.54      0.59        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lightgbm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# evaluate the model\n",
    "# model = LGBMClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, features, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = LGBMClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "yhat = model.predict(features2)\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cbbPd1unoww_",
   "metadata": {
    "id": "cbbPd1unoww_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "AULrRtEVqIWj",
   "metadata": {
    "id": "AULrRtEVqIWj"
   },
   "source": [
    "# Models embed rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "Bmnf27hTqIWj",
   "metadata": {
    "id": "Bmnf27hTqIWj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "zdmSCMlaBD1v",
   "metadata": {
    "id": "zdmSCMlaBD1v"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "Cq2mqFUaqIWj",
   "metadata": {
    "id": "Cq2mqFUaqIWj"
   },
   "outputs": [],
   "source": [
    "features = X_train[embeded_rf_feature]\n",
    "features2 = X_test[embeded_rf_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "IlWMhzoyqIWj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IlWMhzoyqIWj",
    "outputId": "b9064bd9-6a6d-41c8-9517-d8fec8b592d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3nxlWCrkqIWk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3nxlWCrkqIWk",
    "outputId": "48d683d2-3259-4035-df21-0f7920d62e76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "UVTrWTLkqIWk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UVTrWTLkqIWk",
    "outputId": "f8ba19c5-ab85-4dbf-c310-532164bd8d6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.42      0.29        24\n",
      "           1       0.67      0.44      0.53        63\n",
      "\n",
      "    accuracy                           0.44        87\n",
      "   macro avg       0.44      0.43      0.41        87\n",
      "weighted avg       0.54      0.44      0.47        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# X, y = load_iris(return_X_y=True)\n",
    "clf = AdaBoostClassifier()\n",
    "# scores = cross_val_score(clf, features, y_train, cv=5)\n",
    "# print(scores.mean())\n",
    "clf.fit(features, y_train)\n",
    "y_pred = (clf.predict(features2)>0.5).astype(int)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "nEyl39i9qIWk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nEyl39i9qIWk",
    "outputId": "9acbb15a-e4fe-472b-a26c-5bb3c55e6ee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.20      0.28        45\n",
      "           1       0.47      0.76      0.58        42\n",
      "\n",
      "    accuracy                           0.47        87\n",
      "   macro avg       0.47      0.48      0.43        87\n",
      "weighted avg       0.47      0.47      0.43        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svclassifier = SVC(gamma='auto')\n",
    "svclassifier.fit(features, y_train)\n",
    "y_pred = svclassifier.predict(features2)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1mNhIbZ6qIWl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1mNhIbZ6qIWl",
    "outputId": "6a479b0e-573b-424a-bb76-7f41c1522636"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.51 (+/- 0.01) [DecisionTreeClassifier]\n",
      "Accuracy: 0.52 (+/- 0.03) [KNNClassifier]\n",
      "Accuracy: 0.55 (+/- 0.02) [SVC]\n",
      "Accuracy: 0.53 (+/- 0.04) [voting]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf2 = KNeighborsClassifier()\n",
    "clf3 = SVC(kernel='rbf', probability=True)\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2), ('svc', clf3)],\n",
    "                        voting='soft', weights=[2, 2, 2])\n",
    "\n",
    "clf1 = clf1.fit(features, y_train)\n",
    "clf2 = clf2.fit(features, y_train)\n",
    "clf3 = clf3.fit(features, y_train)\n",
    "eclf = eclf.fit(features, y_train)\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['DecisionTreeClassifier', 'KNNClassifier', 'SVC', 'voting']):\n",
    "    scores = cross_val_score(clf, features, y_train, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "_QMoPvFCqIWl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 827
    },
    "id": "_QMoPvFCqIWl",
    "outputId": "02c251f4-e884-4c10-be29-437c6a5c8f9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression score is 49.42528735632184% \n",
      "\n",
      "Support Vector Classifier score is 52.87356321839081%\n",
      "\n",
      "Decision Tree Classifier score is 47.12643678160919%\n",
      "\n",
      "Random Forest Classifier score is 51.724137931034484%\n",
      "\n",
      "KNN Classifier score is 47.12643678160919% with k = 1\n",
      "KNN Classifier score is 44.827586206896555% with k = 2\n",
      "KNN Classifier score is 47.12643678160919% with k = 3\n",
      "KNN Classifier score is 47.12643678160919% with k = 4\n",
      "KNN Classifier score is 50.57471264367817% with k = 5\n",
      "KNN Classifier score is 45.97701149425287% with k = 6\n",
      "KNN Classifier score is 52.87356321839081% with k = 7\n",
      "KNN Classifier score is 51.724137931034484% with k = 8\n",
      "KNN Classifier score is 54.02298850574713% with k = 9\n",
      "KNN Classifier score is 52.87356321839081% with k = 10\n",
      "KNN Classifier score is 51.724137931034484% with k = 11\n",
      "KNN Classifier score is 51.724137931034484% with k = 12\n",
      "KNN Classifier score is 54.02298850574713% with k = 13\n",
      "KNN Classifier score is 54.02298850574713% with k = 14\n",
      "KNN Classifier score is 50.57471264367817% with k = 15\n",
      "KNN Classifier score is 48.275862068965516% with k = 16\n",
      "KNN Classifier score is 47.12643678160919% with k = 17\n",
      "KNN Classifier score is 45.97701149425287% with k = 18\n",
      "KNN Classifier score is 48.275862068965516% with k = 19\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP Classifier score is 47.12643678160919%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fitting logistic regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(features, y_train)\n",
    "predictionsLR = lr.predict(features2)\n",
    "scoreLR = accuracy_score(y_test, predictionsLR)\n",
    "print(f\"Logistic Regression score is {scoreLR * 100}% \\n\")\n",
    "\n",
    "# fitting SVC\n",
    "svc = svm.LinearSVC()\n",
    "svc.fit(features, y_train)\n",
    "predictionsSVC = svc.predict(features2)\n",
    "scoreSVC = accuracy_score(y_test, predictionsSVC)\n",
    "print(f\"Support Vector Classifier score is {scoreSVC * 100}%\\n\")\n",
    "\n",
    "# fitting decision tree classifier\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(features, y_train)\n",
    "predictionsTree = clf.predict(features2)\n",
    "scoreTree = accuracy_score(y_test, predictionsTree)\n",
    "print(f\"Decision Tree Classifier score is {scoreTree * 100}%\\n\")\n",
    "\n",
    "# fitting Random Forest classifier\n",
    "clf1 = RandomForestClassifier(max_features=23)\n",
    "clf1.fit(features, y_train)\n",
    "predictionsTree1 = clf1.predict(features2)\n",
    "scoreTree1 = accuracy_score(y_test, predictionsTree1)\n",
    "print(f\"Random Forest Classifier score is {scoreTree1 * 100}%\\n\")\n",
    "\n",
    "# fitting XGBoost\n",
    "# xgb = XGBClassifier()\n",
    "# xgb.fit(features.to_numpy(), y_train)\n",
    "# predictionsXGB = xgb.predict(X_test)\n",
    "# predictionsXGB = (predictionsXGB>0.5).astype(int)\n",
    "# scoreXGB = accuracy_score(y_test, predictionsXGB)\n",
    "# print(f\"XG Boost Classifier score is {scoreXGB * 100}%\\n\")\n",
    "\n",
    "# fitting KNN Classifier\n",
    "K = range(1, 20)\n",
    "acc = []\n",
    "for k in K:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(features, y_train)\n",
    "    predictionsKNN = knn.predict(features2)\n",
    "    scoreKNN = accuracy_score(y_test, predictionsKNN)\n",
    "    print(f\"KNN Classifier score is {scoreKNN * 100}% with k = {k}\")\n",
    "    acc.append(scoreKNN*100)\n",
    "\n",
    "# Elbow plot:\n",
    "plt.plot(K, acc)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Elbow Curve without feature selection for Inter-Reseach Area\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# MLP / ANN\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=300, activation='relu', solver='adam', random_state=1)\n",
    "classifier.fit(features, y_train)\n",
    "predictionsMLP = classifier.predict(features2)\n",
    "scoreMLP = accuracy_score(y_test, predictionsMLP)\n",
    "print(f\"\\nMLP Classifier score is {scoreMLP * 100}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48RYtYwlqIWl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48RYtYwlqIWl",
    "outputId": "30b47bb2-fe4c-49eb-cbd7-9b1279b7da94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 87 points : 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.58      0.52        45\n",
      "           1       0.41      0.31      0.35        42\n",
      "\n",
      "    accuracy                           0.45        87\n",
      "   macro avg       0.44      0.44      0.44        87\n",
      "weighted avg       0.44      0.45      0.44        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(features, y_train).predict(features2)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "      % (X_test.shape[0], (y_test != y_pred).sum()))\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cg9mr6wsqIWl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cg9mr6wsqIWl",
    "outputId": "0a8bf105-408d-4d20-cea3-8627e7388ad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.56      0.42        27\n",
      "           1       0.71      0.50      0.59        60\n",
      "\n",
      "    accuracy                           0.52        87\n",
      "   macro avg       0.52      0.53      0.50        87\n",
      "weighted avg       0.60      0.52      0.53        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "# from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "# X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# evaluate the model\n",
    "# model = GradientBoostingClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "# row = [[2.56999479, -0.13019997, 3.16075093, -4.35936352, -1.61271951, -1.39352057, -2.48924933, -1.93094078, 3.26130366, 2.05692145]]\n",
    "yhat = model.predict(features2)\n",
    "\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "s2Get55oqIWm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s2Get55oqIWm",
    "outputId": "7a45668e-1321-4445-c01c-27585745a3dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.54      0.24        13\n",
      "           1       0.86      0.49      0.62        74\n",
      "\n",
      "    accuracy                           0.49        87\n",
      "   macro avg       0.51      0.51      0.43        87\n",
      "weighted avg       0.75      0.49      0.56        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# histogram-based gradient boosting for classification in scikit-learn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# evaluate the model\n",
    "# model = HistGradientBoostingClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, features, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = HistGradientBoostingClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "yhat = model.predict(features2)\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "O-luGAMlqIWm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 672
    },
    "id": "O-luGAMlqIWm",
    "outputId": "8feeace8-f1ea-460a-a79a-0ed34314e77e"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-6eac32dd02d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# fit the model on the whole dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;31m# make a single prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m             train_dmatrix = DMatrix(X, label=training_labels,\n\u001b[0;32m--> 726\u001b[0;31m                                     missing=self.missing, nthread=self.n_jobs)\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         self._Booster = train(xgb_options, train_dmatrix, self.get_num_boosting_rounds(),\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[1;32m    424\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mfeature_names\u001b[0;34m(self, feature_names)\u001b[0m\n\u001b[1;32m    868\u001b[0m                        \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'['\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m']'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'<'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m                        for f in feature_names):\n\u001b[0;32m--> 870\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feature_names may not contain [, ] or <'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# reset feature_types also\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names may not contain [, ] or <"
     ]
    }
   ],
   "source": [
    "# xgboost for classification\n",
    "from numpy import asarray\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "# from sklearn.datasets import make_classification\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "# X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# evaluate the model\n",
    "# model = XGBClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, features, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = XGBClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "yhat = model.predict(features2)\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "nrsbgcjAqIWm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nrsbgcjAqIWm",
    "outputId": "e964b6b7-7a2f-4352-e286-3cf5f39cef88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.58      0.42        26\n",
      "           1       0.74      0.51      0.60        61\n",
      "\n",
      "    accuracy                           0.53        87\n",
      "   macro avg       0.54      0.54      0.51        87\n",
      "weighted avg       0.62      0.53      0.55        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lightgbm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# evaluate the model\n",
    "# model = LGBMClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, features, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = LGBMClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "yhat = model.predict(features2)\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NlnIinX5qIWm",
   "metadata": {
    "id": "NlnIinX5qIWm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7gp8UbHXsLIl",
   "metadata": {
    "id": "7gp8UbHXsLIl"
   },
   "source": [
    "# Models lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "csjsHeECsLIl",
   "metadata": {
    "id": "csjsHeECsLIl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dDYneZwsLIm",
   "metadata": {
    "id": "6dDYneZwsLIm"
   },
   "outputs": [],
   "source": [
    "features = X_train[embeded_lgb_feature]\n",
    "features2 = X_test[embeded_lgb_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CsoCCfXHsLIm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CsoCCfXHsLIm",
    "outputId": "da6939bb-d592-4436-fa01-ea7bd295481e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 139,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brwSG0XusLIm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brwSG0XusLIm",
    "outputId": "353d454a-29b9-4322-de7f-3043930e8af5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 140,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wYsauz-WsLIm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wYsauz-WsLIm",
    "outputId": "01cc12c2-a00f-490a-9f5e-35c720e0a380"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.52      0.39        27\n",
      "           1       0.69      0.48      0.57        60\n",
      "\n",
      "    accuracy                           0.49        87\n",
      "   macro avg       0.50      0.50      0.48        87\n",
      "weighted avg       0.57      0.49      0.51        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# X, y = load_iris(return_X_y=True)\n",
    "clf = AdaBoostClassifier()\n",
    "# scores = cross_val_score(clf, features, y_train, cv=5)\n",
    "# print(scores.mean())\n",
    "clf.fit(features, y_train)\n",
    "y_pred = (clf.predict(features2)>0.5).astype(int)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NIFvhMJIsLIn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIFvhMJIsLIn",
    "outputId": "42a5dccf-450f-428e-a326-f4e29fd0147e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.20      0.29        45\n",
      "           1       0.49      0.81      0.61        42\n",
      "\n",
      "    accuracy                           0.49        87\n",
      "   macro avg       0.51      0.50      0.45        87\n",
      "weighted avg       0.51      0.49      0.44        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svclassifier = SVC(gamma='auto')\n",
    "svclassifier.fit(features, y_train)\n",
    "y_pred = svclassifier.predict(features2)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wo_0lws6sLIn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wo_0lws6sLIn",
    "outputId": "b70423ec-217b-4c83-df64-985cb4bdbc79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.51 (+/- 0.04) [DecisionTreeClassifier]\n",
      "Accuracy: 0.54 (+/- 0.01) [KNNClassifier]\n",
      "Accuracy: 0.59 (+/- 0.02) [SVC]\n",
      "Accuracy: 0.53 (+/- 0.04) [voting]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf2 = KNeighborsClassifier()\n",
    "clf3 = SVC(kernel='rbf', probability=True)\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2), ('svc', clf3)],\n",
    "                        voting='soft', weights=[2, 2, 2])\n",
    "\n",
    "clf1 = clf1.fit(features, y_train)\n",
    "clf2 = clf2.fit(features, y_train)\n",
    "clf3 = clf3.fit(features, y_train)\n",
    "eclf = eclf.fit(features, y_train)\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['DecisionTreeClassifier', 'KNNClassifier', 'SVC', 'voting']):\n",
    "    scores = cross_val_score(clf, features, y_train, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bJs0YZDsLIn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 827
    },
    "id": "6bJs0YZDsLIn",
    "outputId": "71677c5e-90c3-4307-e3f8-d80b7348b426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression score is 56.32183908045977% \n",
      "\n",
      "Support Vector Classifier score is 55.172413793103445%\n",
      "\n",
      "Decision Tree Classifier score is 47.12643678160919%\n",
      "\n",
      "Random Forest Classifier score is 48.275862068965516%\n",
      "\n",
      "KNN Classifier score is 48.275862068965516% with k = 1\n",
      "KNN Classifier score is 49.42528735632184% with k = 2\n",
      "KNN Classifier score is 44.827586206896555% with k = 3\n",
      "KNN Classifier score is 42.5287356321839% with k = 4\n",
      "KNN Classifier score is 45.97701149425287% with k = 5\n",
      "KNN Classifier score is 42.5287356321839% with k = 6\n",
      "KNN Classifier score is 51.724137931034484% with k = 7\n",
      "KNN Classifier score is 49.42528735632184% with k = 8\n",
      "KNN Classifier score is 49.42528735632184% with k = 9\n",
      "KNN Classifier score is 51.724137931034484% with k = 10\n",
      "KNN Classifier score is 50.57471264367817% with k = 11\n",
      "KNN Classifier score is 44.827586206896555% with k = 12\n",
      "KNN Classifier score is 45.97701149425287% with k = 13\n",
      "KNN Classifier score is 48.275862068965516% with k = 14\n",
      "KNN Classifier score is 49.42528735632184% with k = 15\n",
      "KNN Classifier score is 51.724137931034484% with k = 16\n",
      "KNN Classifier score is 51.724137931034484% with k = 17\n",
      "KNN Classifier score is 51.724137931034484% with k = 18\n",
      "KNN Classifier score is 50.57471264367817% with k = 19\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP Classifier score is 50.57471264367817%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fitting logistic regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(features, y_train)\n",
    "predictionsLR = lr.predict(features2)\n",
    "scoreLR = accuracy_score(y_test, predictionsLR)\n",
    "print(f\"Logistic Regression score is {scoreLR * 100}% \\n\")\n",
    "\n",
    "# fitting SVC\n",
    "svc = svm.LinearSVC()\n",
    "svc.fit(features, y_train)\n",
    "predictionsSVC = svc.predict(features2)\n",
    "scoreSVC = accuracy_score(y_test, predictionsSVC)\n",
    "print(f\"Support Vector Classifier score is {scoreSVC * 100}%\\n\")\n",
    "\n",
    "# fitting decision tree classifier\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(features, y_train)\n",
    "predictionsTree = clf.predict(features2)\n",
    "scoreTree = accuracy_score(y_test, predictionsTree)\n",
    "print(f\"Decision Tree Classifier score is {scoreTree * 100}%\\n\")\n",
    "\n",
    "# fitting Random Forest classifier\n",
    "clf1 = RandomForestClassifier(max_features=23)\n",
    "clf1.fit(features, y_train)\n",
    "predictionsTree1 = clf1.predict(features2)\n",
    "scoreTree1 = accuracy_score(y_test, predictionsTree1)\n",
    "print(f\"Random Forest Classifier score is {scoreTree1 * 100}%\\n\")\n",
    "\n",
    "# fitting XGBoost\n",
    "# xgb = XGBClassifier()\n",
    "# xgb.fit(features.to_numpy(), y_train)\n",
    "# predictionsXGB = xgb.predict(X_test)\n",
    "# predictionsXGB = (predictionsXGB>0.5).astype(int)\n",
    "# scoreXGB = accuracy_score(y_test, predictionsXGB)\n",
    "# print(f\"XG Boost Classifier score is {scoreXGB * 100}%\\n\")\n",
    "\n",
    "# fitting KNN Classifier\n",
    "K = range(1, 20)\n",
    "acc = []\n",
    "for k in K:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(features, y_train)\n",
    "    predictionsKNN = knn.predict(features2)\n",
    "    scoreKNN = accuracy_score(y_test, predictionsKNN)\n",
    "    print(f\"KNN Classifier score is {scoreKNN * 100}% with k = {k}\")\n",
    "    acc.append(scoreKNN*100)\n",
    "\n",
    "# Elbow plot:\n",
    "plt.plot(K, acc)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Elbow Curve without feature selection for Inter-Reseach Area\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# MLP / ANN\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=300, activation='relu', solver='adam', random_state=1)\n",
    "classifier.fit(features, y_train)\n",
    "predictionsMLP = classifier.predict(features2)\n",
    "scoreMLP = accuracy_score(y_test, predictionsMLP)\n",
    "print(f\"\\nMLP Classifier score is {scoreMLP * 100}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7SG5P3posLIn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7SG5P3posLIn",
    "outputId": "d6e255f4-7e11-4d9b-f9d6-e3bf7afa77f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 87 points : 44\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(features, y_train).predict(features2)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "      % (X_test.shape[0], (y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uPIkabCcsLIn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uPIkabCcsLIn",
    "outputId": "c0ce3641-71ae-4cf5-f773-5a0a062407f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.52      0.37        25\n",
      "           1       0.71      0.48      0.58        62\n",
      "\n",
      "    accuracy                           0.49        87\n",
      "   macro avg       0.50      0.50      0.47        87\n",
      "weighted avg       0.59      0.49      0.52        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "# X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# evaluate the model\n",
    "# model = GradientBoostingClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "# row = [[2.56999479, -0.13019997, 3.16075093, -4.35936352, -1.61271951, -1.39352057, -2.48924933, -1.93094078, 3.26130366, 2.05692145]]\n",
    "yhat = model.predict(features2)\n",
    "\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YZDLqKSusLIo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YZDLqKSusLIo",
    "outputId": "7b01d0f1-71c3-4760-8934-c4eab9d2ccf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.60      0.37        20\n",
      "           1       0.81      0.51      0.62        67\n",
      "\n",
      "    accuracy                           0.53        87\n",
      "   macro avg       0.54      0.55      0.50        87\n",
      "weighted avg       0.68      0.53      0.57        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# histogram-based gradient boosting for classification in scikit-learn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# evaluate the model\n",
    "# model = HistGradientBoostingClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, features, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = HistGradientBoostingClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "yhat = model.predict(features2)\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "qtPiaBScsLIo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "qtPiaBScsLIo",
    "outputId": "bb271dec-ea1e-4d10-f2c6-1512a8968b2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.54      0.67        72\n",
      "         1.0       0.21      0.60      0.32        15\n",
      "\n",
      "    accuracy                           0.55        87\n",
      "   macro avg       0.54      0.57      0.49        87\n",
      "weighted avg       0.75      0.55      0.61        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xgboost for classification\n",
    "from numpy import asarray\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "# X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# evaluate the model\n",
    "# model = XGBClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, features, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = XGBClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "yhat = model.predict(features2)\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mry6H3SWsLIo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mry6H3SWsLIo",
    "outputId": "775d69c5-06ca-4c3c-f428-59688a9936a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.65      0.35        17\n",
      "           1       0.86      0.51      0.64        70\n",
      "\n",
      "    accuracy                           0.54        87\n",
      "   macro avg       0.55      0.58      0.50        87\n",
      "weighted avg       0.74      0.54      0.59        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lightgbm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "# evaluate the model\n",
    "# model = LGBMClassifier()\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, features, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = LGBMClassifier()\n",
    "model.fit(features, y_train)\n",
    "# make a single prediction\n",
    "yhat = model.predict(features2)\n",
    "print(classification_report(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "rXqaehoIsLIo",
   "metadata": {
    "id": "rXqaehoIsLIo"
   },
   "outputs": [],
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2a894a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90dbcfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=pd.read_csv('personality_ocean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c972bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>What is your age (in years) ?</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>What is the highest degree or level of school you have completed? If currently enrolled, mention current degree _Master’s degree</th>\n",
       "      <th>Employment Status: Are you currently…?_Employed for wages</th>\n",
       "      <th>Employment Status: Are you currently…?_Out of work but not currently looking for work</th>\n",
       "      <th>Are you.. ?_Right-handed</th>\n",
       "      <th>Do you wear prescription glasses (spectacles)?_Yes</th>\n",
       "      <th>Which of the following job profiles are you comfortable interviewing for? (No questions testing your knowledge will be asked in the interview)_Coding</th>\n",
       "      <th>Which of the following job profiles are you comfortable interviewing for? (No questions testing your knowledge will be asked in the interview)_Consulting</th>\n",
       "      <th>...</th>\n",
       "      <th>I (The respondent) [Often feel blue.]_Slightly agree</th>\n",
       "      <th>I (The respondent) [Often feel blue.]_Slightly disagree</th>\n",
       "      <th>I (The respondent) [Am full of ideas.]_Neutral</th>\n",
       "      <th>I (The respondent) [Am full of ideas.]_Slightly agree</th>\n",
       "      <th>I (The respondent) [Am full of ideas.]_Slightly disagree</th>\n",
       "      <th>O</th>\n",
       "      <th>E</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>26</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>17.2</td>\n",
       "      <td>25</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>30.966667</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>25</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    person_id  What is your age (in years) ?  Gender_Male  \\\n",
       "0           1                             23            1   \n",
       "1           2                             21            1   \n",
       "2           3                             22            1   \n",
       "3           4                             22            0   \n",
       "4           5                             31            1   \n",
       "5           6                             22            1   \n",
       "6           7                             24            1   \n",
       "7           8                             24            0   \n",
       "8           9                             22            0   \n",
       "9          10                             21            0   \n",
       "10         11                             23            1   \n",
       "11         12                             25            1   \n",
       "12         13                             22            0   \n",
       "13         14                             23            1   \n",
       "14         15                             22            1   \n",
       "15         16                             22            0   \n",
       "16         17                             23            1   \n",
       "17         18                             22            0   \n",
       "18         19                             22            1   \n",
       "19         20                             22            0   \n",
       "20         21                             23            0   \n",
       "21         22                             22            0   \n",
       "22         23                             24            0   \n",
       "23         24                             25            1   \n",
       "24         25                             23            1   \n",
       "25         26                             22            0   \n",
       "26         27                             19            0   \n",
       "27         28                             22            1   \n",
       "28         29                             22            0   \n",
       "29         30                             24            0   \n",
       "30         31                             22            1   \n",
       "\n",
       "    What is the highest degree or level of school you have completed? If currently enrolled, mention current degree _Master’s degree  \\\n",
       "0                                                   1                                                                                  \n",
       "1                                                   1                                                                                  \n",
       "2                                                   0                                                                                  \n",
       "3                                                   0                                                                                  \n",
       "4                                                   1                                                                                  \n",
       "5                                                   1                                                                                  \n",
       "6                                                   0                                                                                  \n",
       "7                                                   1                                                                                  \n",
       "8                                                   1                                                                                  \n",
       "9                                                   1                                                                                  \n",
       "10                                                  0                                                                                  \n",
       "11                                                  1                                                                                  \n",
       "12                                                  1                                                                                  \n",
       "13                                                  0                                                                                  \n",
       "14                                                  0                                                                                  \n",
       "15                                                  1                                                                                  \n",
       "16                                                  0                                                                                  \n",
       "17                                                  0                                                                                  \n",
       "18                                                  0                                                                                  \n",
       "19                                                  0                                                                                  \n",
       "20                                                  1                                                                                  \n",
       "21                                                  1                                                                                  \n",
       "22                                                  0                                                                                  \n",
       "23                                                  0                                                                                  \n",
       "24                                                  1                                                                                  \n",
       "25                                                  0                                                                                  \n",
       "26                                                  0                                                                                  \n",
       "27                                                  1                                                                                  \n",
       "28                                                  0                                                                                  \n",
       "29                                                  0                                                                                  \n",
       "30                                                  0                                                                                  \n",
       "\n",
       "    Employment Status: Are you currently…?_Employed for wages  \\\n",
       "0                                                   0           \n",
       "1                                                   0           \n",
       "2                                                   1           \n",
       "3                                                   0           \n",
       "4                                                   0           \n",
       "5                                                   0           \n",
       "6                                                   1           \n",
       "7                                                   0           \n",
       "8                                                   0           \n",
       "9                                                   0           \n",
       "10                                                  1           \n",
       "11                                                  1           \n",
       "12                                                  0           \n",
       "13                                                  1           \n",
       "14                                                  1           \n",
       "15                                                  0           \n",
       "16                                                  1           \n",
       "17                                                  0           \n",
       "18                                                  0           \n",
       "19                                                  1           \n",
       "20                                                  0           \n",
       "21                                                  0           \n",
       "22                                                  0           \n",
       "23                                                  1           \n",
       "24                                                  0           \n",
       "25                                                  1           \n",
       "26                                                  0           \n",
       "27                                                  0           \n",
       "28                                                  0           \n",
       "29                                                  0           \n",
       "30                                                  1           \n",
       "\n",
       "    Employment Status: Are you currently…?_Out of work but not currently looking for work  \\\n",
       "0                                                   0                                       \n",
       "1                                                   0                                       \n",
       "2                                                   0                                       \n",
       "3                                                   0                                       \n",
       "4                                                   0                                       \n",
       "5                                                   0                                       \n",
       "6                                                   0                                       \n",
       "7                                                   0                                       \n",
       "8                                                   0                                       \n",
       "9                                                   0                                       \n",
       "10                                                  0                                       \n",
       "11                                                  0                                       \n",
       "12                                                  0                                       \n",
       "13                                                  0                                       \n",
       "14                                                  0                                       \n",
       "15                                                  0                                       \n",
       "16                                                  0                                       \n",
       "17                                                  0                                       \n",
       "18                                                  0                                       \n",
       "19                                                  0                                       \n",
       "20                                                  0                                       \n",
       "21                                                  0                                       \n",
       "22                                                  0                                       \n",
       "23                                                  0                                       \n",
       "24                                                  0                                       \n",
       "25                                                  0                                       \n",
       "26                                                  0                                       \n",
       "27                                                  0                                       \n",
       "28                                                  0                                       \n",
       "29                                                  1                                       \n",
       "30                                                  0                                       \n",
       "\n",
       "    Are you.. ?_Right-handed  \\\n",
       "0                          0   \n",
       "1                          1   \n",
       "2                          1   \n",
       "3                          1   \n",
       "4                          1   \n",
       "5                          1   \n",
       "6                          1   \n",
       "7                          1   \n",
       "8                          1   \n",
       "9                          1   \n",
       "10                         1   \n",
       "11                         1   \n",
       "12                         1   \n",
       "13                         1   \n",
       "14                         1   \n",
       "15                         1   \n",
       "16                         1   \n",
       "17                         1   \n",
       "18                         1   \n",
       "19                         1   \n",
       "20                         1   \n",
       "21                         1   \n",
       "22                         1   \n",
       "23                         1   \n",
       "24                         1   \n",
       "25                         1   \n",
       "26                         1   \n",
       "27                         1   \n",
       "28                         1   \n",
       "29                         1   \n",
       "30                         1   \n",
       "\n",
       "    Do you wear prescription glasses (spectacles)?_Yes  \\\n",
       "0                                                   1    \n",
       "1                                                   1    \n",
       "2                                                   1    \n",
       "3                                                   0    \n",
       "4                                                   1    \n",
       "5                                                   1    \n",
       "6                                                   1    \n",
       "7                                                   1    \n",
       "8                                                   1    \n",
       "9                                                   0    \n",
       "10                                                  1    \n",
       "11                                                  0    \n",
       "12                                                  0    \n",
       "13                                                  0    \n",
       "14                                                  0    \n",
       "15                                                  1    \n",
       "16                                                  1    \n",
       "17                                                  0    \n",
       "18                                                  1    \n",
       "19                                                  0    \n",
       "20                                                  1    \n",
       "21                                                  1    \n",
       "22                                                  1    \n",
       "23                                                  1    \n",
       "24                                                  1    \n",
       "25                                                  1    \n",
       "26                                                  1    \n",
       "27                                                  1    \n",
       "28                                                  1    \n",
       "29                                                  1    \n",
       "30                                                  1    \n",
       "\n",
       "    Which of the following job profiles are you comfortable interviewing for? (No questions testing your knowledge will be asked in the interview)_Coding  \\\n",
       "0                                                   1                                                                                                       \n",
       "1                                                   0                                                                                                       \n",
       "2                                                   0                                                                                                       \n",
       "3                                                   0                                                                                                       \n",
       "4                                                   0                                                                                                       \n",
       "5                                                   0                                                                                                       \n",
       "6                                                   1                                                                                                       \n",
       "7                                                   0                                                                                                       \n",
       "8                                                   0                                                                                                       \n",
       "9                                                   0                                                                                                       \n",
       "10                                                  0                                                                                                       \n",
       "11                                                  0                                                                                                       \n",
       "12                                                  0                                                                                                       \n",
       "13                                                  0                                                                                                       \n",
       "14                                                  0                                                                                                       \n",
       "15                                                  0                                                                                                       \n",
       "16                                                  0                                                                                                       \n",
       "17                                                  0                                                                                                       \n",
       "18                                                  0                                                                                                       \n",
       "19                                                  0                                                                                                       \n",
       "20                                                  0                                                                                                       \n",
       "21                                                  0                                                                                                       \n",
       "22                                                  0                                                                                                       \n",
       "23                                                  0                                                                                                       \n",
       "24                                                  0                                                                                                       \n",
       "25                                                  0                                                                                                       \n",
       "26                                                  0                                                                                                       \n",
       "27                                                  0                                                                                                       \n",
       "28                                                  0                                                                                                       \n",
       "29                                                  0                                                                                                       \n",
       "30                                                  0                                                                                                       \n",
       "\n",
       "    Which of the following job profiles are you comfortable interviewing for? (No questions testing your knowledge will be asked in the interview)_Consulting  \\\n",
       "0                                                   0                                                                                                           \n",
       "1                                                   0                                                                                                           \n",
       "2                                                   0                                                                                                           \n",
       "3                                                   0                                                                                                           \n",
       "4                                                   0                                                                                                           \n",
       "5                                                   1                                                                                                           \n",
       "6                                                   0                                                                                                           \n",
       "7                                                   0                                                                                                           \n",
       "8                                                   1                                                                                                           \n",
       "9                                                   0                                                                                                           \n",
       "10                                                  0                                                                                                           \n",
       "11                                                  0                                                                                                           \n",
       "12                                                  0                                                                                                           \n",
       "13                                                  0                                                                                                           \n",
       "14                                                  0                                                                                                           \n",
       "15                                                  0                                                                                                           \n",
       "16                                                  0                                                                                                           \n",
       "17                                                  0                                                                                                           \n",
       "18                                                  0                                                                                                           \n",
       "19                                                  0                                                                                                           \n",
       "20                                                  0                                                                                                           \n",
       "21                                                  0                                                                                                           \n",
       "22                                                  0                                                                                                           \n",
       "23                                                  0                                                                                                           \n",
       "24                                                  0                                                                                                           \n",
       "25                                                  0                                                                                                           \n",
       "26                                                  0                                                                                                           \n",
       "27                                                  0                                                                                                           \n",
       "28                                                  1                                                                                                           \n",
       "29                                                  0                                                                                                           \n",
       "30                                                  1                                                                                                           \n",
       "\n",
       "    ...  I (The respondent) [Often feel blue.]_Slightly agree  \\\n",
       "0   ...                                                  0      \n",
       "1   ...                                                  0      \n",
       "2   ...                                                  0      \n",
       "3   ...                                                  0      \n",
       "4   ...                                                  0      \n",
       "5   ...                                                  0      \n",
       "6   ...                                                  1      \n",
       "7   ...                                                  1      \n",
       "8   ...                                                  1      \n",
       "9   ...                                                  0      \n",
       "10  ...                                                  0      \n",
       "11  ...                                                  0      \n",
       "12  ...                                                  0      \n",
       "13  ...                                                  0      \n",
       "14  ...                                                  0      \n",
       "15  ...                                                  1      \n",
       "16  ...                                                  0      \n",
       "17  ...                                                  0      \n",
       "18  ...                                                  0      \n",
       "19  ...                                                  0      \n",
       "20  ...                                                  0      \n",
       "21  ...                                                  0      \n",
       "22  ...                                                  1      \n",
       "23  ...                                                  0      \n",
       "24  ...                                                  0      \n",
       "25  ...                                                  0      \n",
       "26  ...                                                  0      \n",
       "27  ...                                                  0      \n",
       "28  ...                                                  0      \n",
       "29  ...                                                  0      \n",
       "30  ...                                                  0      \n",
       "\n",
       "    I (The respondent) [Often feel blue.]_Slightly disagree  \\\n",
       "0                                                   0         \n",
       "1                                                   0         \n",
       "2                                                   0         \n",
       "3                                                   1         \n",
       "4                                                   1         \n",
       "5                                                   0         \n",
       "6                                                   0         \n",
       "7                                                   0         \n",
       "8                                                   0         \n",
       "9                                                   1         \n",
       "10                                                  1         \n",
       "11                                                  0         \n",
       "12                                                  1         \n",
       "13                                                  1         \n",
       "14                                                  1         \n",
       "15                                                  0         \n",
       "16                                                  0         \n",
       "17                                                  1         \n",
       "18                                                  1         \n",
       "19                                                  1         \n",
       "20                                                  1         \n",
       "21                                                  1         \n",
       "22                                                  0         \n",
       "23                                                  0         \n",
       "24                                                  1         \n",
       "25                                                  1         \n",
       "26                                                  0         \n",
       "27                                                  1         \n",
       "28                                                  0         \n",
       "29                                                  0         \n",
       "30                                                  1         \n",
       "\n",
       "    I (The respondent) [Am full of ideas.]_Neutral  \\\n",
       "0                                                1   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "5                                                0   \n",
       "6                                                0   \n",
       "7                                                0   \n",
       "8                                                1   \n",
       "9                                                1   \n",
       "10                                               0   \n",
       "11                                               0   \n",
       "12                                               1   \n",
       "13                                               0   \n",
       "14                                               0   \n",
       "15                                               0   \n",
       "16                                               0   \n",
       "17                                               1   \n",
       "18                                               0   \n",
       "19                                               0   \n",
       "20                                               0   \n",
       "21                                               0   \n",
       "22                                               1   \n",
       "23                                               0   \n",
       "24                                               0   \n",
       "25                                               1   \n",
       "26                                               0   \n",
       "27                                               0   \n",
       "28                                               0   \n",
       "29                                               0   \n",
       "30                                               0   \n",
       "\n",
       "    I (The respondent) [Am full of ideas.]_Slightly agree  \\\n",
       "0                                                   0       \n",
       "1                                                   0       \n",
       "2                                                   1       \n",
       "3                                                   0       \n",
       "4                                                   0       \n",
       "5                                                   0       \n",
       "6                                                   0       \n",
       "7                                                   1       \n",
       "8                                                   0       \n",
       "9                                                   0       \n",
       "10                                                  0       \n",
       "11                                                  1       \n",
       "12                                                  0       \n",
       "13                                                  0       \n",
       "14                                                  0       \n",
       "15                                                  1       \n",
       "16                                                  0       \n",
       "17                                                  0       \n",
       "18                                                  1       \n",
       "19                                                  1       \n",
       "20                                                  0       \n",
       "21                                                  1       \n",
       "22                                                  0       \n",
       "23                                                  0       \n",
       "24                                                  1       \n",
       "25                                                  0       \n",
       "26                                                  1       \n",
       "27                                                  0       \n",
       "28                                                  1       \n",
       "29                                                  1       \n",
       "30                                                  1       \n",
       "\n",
       "    I (The respondent) [Am full of ideas.]_Slightly disagree   O          E  \\\n",
       "0                                                   0         19  25.000000   \n",
       "1                                                   0         18   7.000000   \n",
       "2                                                   0         12  22.000000   \n",
       "3                                                   1         14  15.000000   \n",
       "4                                                   0         16  17.000000   \n",
       "5                                                   0         13  25.000000   \n",
       "6                                                   0         14  34.000000   \n",
       "7                                                   0         13  10.000000   \n",
       "8                                                   0         10  34.000000   \n",
       "9                                                   0         14  30.000000   \n",
       "10                                                  0         10  23.000000   \n",
       "11                                                  0         16  20.000000   \n",
       "12                                                  0         16  19.000000   \n",
       "13                                                  0         17  15.000000   \n",
       "14                                                  1         18  34.000000   \n",
       "15                                                  0         16  22.000000   \n",
       "16                                                  0         13  21.000000   \n",
       "17                                                  0         12  23.000000   \n",
       "18                                                  0         17  28.000000   \n",
       "19                                                  0         18  15.000000   \n",
       "20                                                  1          9  20.000000   \n",
       "21                                                  0         15  33.000000   \n",
       "22                                                  0          5  26.000000   \n",
       "23                                                  0         16  16.000000   \n",
       "24                                                  0         12  10.000000   \n",
       "25                                                  0         10  30.000000   \n",
       "26                                                  0         16  30.966667   \n",
       "27                                                  0         19  34.000000   \n",
       "28                                                  0         17  19.000000   \n",
       "29                                                  0         13  21.000000   \n",
       "30                                                  0         16  25.000000   \n",
       "\n",
       "       C   A   N  \n",
       "0   13.0  17  35  \n",
       "1    6.0   6  33  \n",
       "2   27.0  17  36  \n",
       "3   15.0  20  41  \n",
       "4   15.0  18  36  \n",
       "5   24.0  22  37  \n",
       "6   21.0  24  38  \n",
       "7   16.0  26  33  \n",
       "8   28.0  26  30  \n",
       "9   15.0  23  35  \n",
       "10  14.0  16  37  \n",
       "11   5.0  23  40  \n",
       "12  19.0  20  41  \n",
       "13  11.0  17  31  \n",
       "14  17.2  25  34  \n",
       "15  19.0  17  35  \n",
       "16  24.0  25  33  \n",
       "17   7.0  13  35  \n",
       "18  22.0  20  42  \n",
       "19  19.0  17  38  \n",
       "20  25.0  17  27  \n",
       "21   8.0  24  34  \n",
       "22  12.0  20  42  \n",
       "23  20.0  25  28  \n",
       "24  13.0  19  30  \n",
       "25  15.0  26  37  \n",
       "26  11.0  24  38  \n",
       "27  18.0  25  39  \n",
       "28  19.0  21  35  \n",
       "29  17.0  20  44  \n",
       "30  15.0  22  33  \n",
       "\n",
       "[31 rows x 203 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7539c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df2 =new_df.iloc[:,-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b0ee917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(\"Test Plots\")\n",
    "a = sns.kdeplot(new_df2.iloc[:,0],legend=True)\n",
    "a = sns.kdeplot(new_df2.iloc[:,1],legend=True)\n",
    "a = sns.kdeplot(new_df2.iloc[:,2],legend=True)\n",
    "a = sns.kdeplot(new_df2.iloc[:,3],legend=True)\n",
    "a = sns.kdeplot(new_df2.iloc[:,4],legend=True)\n",
    "\n",
    "# a.legend(fontsize = 15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3685192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(new_df2.iloc[:,0],legend=True)\n",
    "plt.legend(handles=)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "248bdd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "date = pd.date_range(\"2017-03\", freq=\"M\", periods=15)\n",
    "count = np.random.rand(15,4)\n",
    "df1 = pd.DataFrame({\"date\":date, \"count\" : new_df2.iloc[:,0]})\n",
    "df2 = pd.DataFrame({\"date\":date, \"count\" : new_df2.iloc[:,1]})\n",
    "df3 = pd.DataFrame({\"date\":date, \"count\" : new_df2.iloc[:,2]})\n",
    "\n",
    "f, ax = plt.subplots(1, 1)\n",
    "x_col='date'\n",
    "y_col = 'count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5a4c84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='O', ylabel='Count'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=new_df, x=\"O\", hue=\"Gender_Male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dbd20d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='O', ylabel='Count'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWF0lEQVR4nO3de5CddZ3n8ffXJJ1wV66adJNONggkMcOlOw4QGQ1IGMDorGBAwAgoOAssgsuss1Z2YS2rhIFdFSwgxSXMjALKRUF3GFAMFgjB5iISgiISSBMGOkxxGaiQC9/94xyaTtKdPknO0+fk6fer6lSf5znP8/t9+1T3p3/9O88lMhNJUvm8r9EFSJKKYcBLUkkZ8JJUUga8JJWUAS9JJTWy0QX0teuuu2Z7e3ujy5CkrcbDDz+8IjN36++1pgr49vZ2urq6Gl2GJG01IuK5gV5zikaSSsqAl6SSMuAlqaSaag6+P6tXr6a7u5uVK1c2upSmNGbMGFpbWxk1alSjS5HUZJo+4Lu7u9lhhx1ob28nIhpdTlPJTF555RW6u7uZMGFCo8uR1GSafopm5cqV7LLLLoZ7PyKCXXbZxf9uJPWr0ICPiPdHxM0R8VRELImIgzaznXqXVhq+N5IGUvQUzXeBOzPz2IhoAbYtuD9JUlVhAR8ROwKHAl8EyMxVwKqi+pMkravIKZqJQA9wXUQ8GhFXR8R2628UEadHRFdEdPX09NTU8EsvvcTnP/95Jk6cyIEHHshBBx3EbbfdtsUFL1y4kGOOOWaL21m6dCkRwbx583rXrVixglGjRnHWWWdtdN8FCxYMuo2kxmlvG0dE1PXR3jaukFqLnKIZCRwAnJ2ZiyLiu8DXgXl9N8rM+cB8gI6OjkFvL5WZfOYzn2Hu3Ln88Ic/BOC5557j9ttvr3f9g1qzZg0jR/b/Fk6cOJGf/exnfPOb3wTgxz/+MVOmTBnK8iQV4Lnu5eR1R9e1zTjl53Vt711FjuC7ge7MXFRdvplK4G+Re+65h5aWFr7yla/0rhs/fjxnn302a9eu5fzzz6ezs5Np06Zx1VVXAZWR+cc//nGOPfZY9tlnH0488UTevVXhnXfeyT777MOMGTO49dZbe9t88803OfXUU+ns7GT//ffnpz/9KVAZYR933HF86lOf4ogjjhiwzm222YZ9992399o6N910E5/73Od6X7/jjjv46Ec/yv7778/hhx/OSy+9tEEbPT09fPazn6Wzs5POzk7uv//+LXjnJA03hY3gM/PfImJZROydmX8ADgOe3NJ2Fy9ezAEH9P934pprrmGnnXbit7/9LW+//TaHHHJIbwg/+uijLF68mLFjx3LIIYdw//3309HRwZe//GXuueceJk2axJw5c3rb+ta3vsXMmTO59tprefXVV5k+fTqHH344AA888ACPP/44O++880ZrPf7447nxxhv54Ac/yIgRIxg7dizLly8HYMaMGTz44INEBFdffTUXX3wxl1566Tr7n3POOZx77rnMmDGD559/nlmzZrFkyZLNfu8kDS9FH0VzNvCD6hE0fwZOqXcHZ555Jvfddx8tLS2MHz+exx9/nJtvvhmA1157jaeffpqWlhamT59Oa2srAPvttx9Lly5l++23Z8KECey1114AnHTSScyfPx+Au+66i9tvv51LLrkEqByP//zzzwPwyU9+ctBwBzjyyCOZN28ee+yxxzp/PKByAtecOXN48cUXWbVqVb8nKv3iF7/gySff+5v4+uuv88Ybb7DDDjts6tskaRgqNOAz8zGgo55tTpkyhVtuuaV3+fvf/z4rVqygo6ODPffck8suu4xZs2ats8/ChQsZPXp07/KIESNYs2YNMPBx5JnJLbfcwt57773O+kWLFrHddht8VtyvlpYWDjzwQC699FIWL17MHXfc0fva2WefzXnnncfs2bNZuHAhF1xwwQb7v/POOzzwwANss802NfUnSX01/Zms65s5cyYrV67kiiuu6F331ltvATBr1iyuuOIKVq9eDcAf//hH3nzzzQHb2meffXj22Wd55plnALjhhht6X5s1axaXXXZZ71z9o48+uln1fu1rX+Oiiy5il112WWf9a6+9xrhxlU/Or7/++n73PeKII7j88st7lx977LHNqkHS8LTVBXxE8JOf/IR7772XCRMmMH36dObOnctFF13El770JSZPnswBBxzA1KlTOeOMM3pH6v0ZM2YM8+fP5+ijj2bGjBmMHz++97V58+axevVqpk2bxtSpU9c55HFTTJkyhblz526w/oILLuC4447jYx/7GLvuumu/+37ve9+jq6uLadOmMXnyZK688srNqkHS8BTvjlCbQUdHR65/R6clS5aw7777NqiirYPvkTR0IqKQwyQ3N4sj4uHM7HcqfKsbwUuSatP0lwtuZr///e85+eST11k3evRoFi1aNMAekjR0DPgt8JGPfMQPPiU1LadoJKmkDHhJKikDXpJKalgF/Li2Pet6ic9xbXvW1O+dd97J3nvvzaRJk/j2t79d8HcpSRXD6kPW5d3LmHPVb+rW3k1nHDzoNmvXruXMM8/k7rvvprW1lc7OTmbPns3kyZPrVock9WdYjeAb4aGHHmLSpElMnDiRlpYWjj/++N5LD0tSkQz4gr3wwgu0tbX1Lre2tvLCCy80sCJJw4UBX7D+Tj8e6AqWklRPBnzBWltbWbZsWe9yd3c3Y8eObWBFkoYLA75gnZ2dPP300zz77LOsWrWKG2+8kdmzZze6LEnDwLA6imZsa1tNR75sSnuDGTlyJJdffjmzZs1i7dq1nHrqqd58W9KQGFYB/8Ky5xvS71FHHcVRRx3VkL4lDV9O0UhSSRnwklRSBrwklZQBL0klZcBLUkkZ8JJUUsMq4NvbxtX1csHtbeMG7fPUU09l9913Z+rUqUPwHUrSewo9Dj4ilgJvAGuBNZnZUWR/g3muezl53dF1ay9O+fmg23zxi1/krLPO4gtf+ELd+pWkWgzFiU6fyMwVQ9BPUzr00ENZunRpo8uQNAwNqykaSRpOig74BO6KiIcj4vT+NoiI0yOiKyK6enp6Ci5Hqp963wIyIhjZMrrubdbyWZHKqegpmkMyc3lE7A7cHRFPZeav+26QmfOB+QAdHR0bXjxdalL1vgUkVG4DWc/PiaC2z4pUToWO4DNzefXry8BtwPQi+5MkvaewEXxEbAe8LzPfqD4/AvjfRfVXi/GtY+s6mhnfOviNO0444QQWLlzIihUraG1t5cILL+S0006rWw2SNJAip2j2AG6r3p5uJPDDzLyzwP4GtXTZ0N8L9YYbbhjyPiUJCgz4zPwz8BdFtS9J2jgPk5SkktoqAj7Tg2sG4nsjaSBNH/BjxozhlVdeMcj6kZm88sorjBkzptGlSGpCTX9P1tbWVrq7u/EkqP6NGTOG1tbWRpchqQk1fcCPGjWKCRMmNLoMSdrqNP0UjSRp8xjwklRSBrwklZQBL0klZcBLUkkZ8JJUUga8JJWUAS9JJWXAS1JJGfCSVFIGvCSVlAEvSSVlwEtSSRnwklRSBrwklZQBL0klZcBLUkkZ8JJUUga8JJWUAS9JJWXAS1JJFR7wETEiIh6NiJ8V3Zck6T1DMYI/B1gyBP1IkvooNOAjohU4Gri6yH4kSRsqegT/HeDvgHcG2iAiTo+Irojo6unpKbgcSRszrm1PIqKuj5Eto+veZnvbuEa/VVuFkUU1HBHHAC9n5sMR8fGBtsvM+cB8gI6OjiyqHkmDW969jDlX/aaubd50xsHkdUfXtc045ed1ba+sihzBHwLMjoilwI3AzIj45wL7kyT1UVjAZ+bfZ2ZrZrYDxwP3ZOZJRfUnSVqXx8FLUkkVNgffV2YuBBYORV+SpApH8JJUUga8JJWUAS9JJWXAS1JJGfCSVFIGvCSVlAEvSSVlwEtSSRnwklRSBrwklZQBL0klVVPAR8QhtayTJDWPWkfwl9W4TpLUJDZ6NcmIOAg4GNgtIs7r89KOwIgiC5MkbZnBLhfcAmxf3W6HPutfB44tqihJ0pbbaMBn5r3AvRGxIDOfG6KaJEl1UOsNP0ZHxHygve8+mTmziKIkSVuu1oD/MXAlcDWwtrhyJEn1UmvAr8nMKwqtRJJUV7UeJnlHRPyXiPhQROz87qPQyiRJW6TWEfzc6tfz+6xLYGJ9y5Ek1UtNAZ+ZE4ouRJJUXzUFfER8ob/1mfmP9S1HklQvtU7RdPZ5PgY4DHgEMOAlqUnVOkVzdt/liNgJ+KdCKpIk1cXmXi74LWCvjW0QEWMi4qGI+F1ELI6ICzezL0nSZqh1Dv4OKkfNQOUiY/sCPxpkt7eBmZn5HxExCrgvIv4lMx/c7GolSTWrdQ7+kj7P1wDPZWb3xnbIzAT+o7o4qvrIgfeQJNVTTVM01YuOPUXlipIfAFbVsl9EjIiIx4CXgbszc1E/25weEV0R0dXT01Nz4ZKkjav1jk6fAx4CjgM+ByyKiEEvF5yZazNzP6AVmB4RU/vZZn5mdmRmx2677bZJxUuSBlbrFM03gM7MfBkgInYDfgHcXMvOmflqRCwEjgSe2Iw6JUmbqNajaN73brhXvTLYvhGxW0S8v/p8G+BwKtM8kqQhUOsI/s6I+FfghuryHOD/DbLPh4DrI2IElT8GP8rMn21emZKkTTXYPVknAXtk5vkR8Z+BGUAADwA/2Ni+mfk4sH+9CpUkbZrBpmi+A7wBkJm3ZuZ5mXkuldH7d4otTZK0JQYL+PbqSHwdmdlF5fZ9kqQmNVjAj9nIa9vUsxBJUn0NFvC/jYgvr78yIk4DHi6mJElSPQx2FM1Xgdsi4kTeC/QOoAX4mwLrkiRtoY0GfGa+BBwcEZ8A3j0L9eeZeU/hlUmStkit14P/FfCrgmuRJNXR5l4PXpLU5Ax4SSopA16SSsqAl6SSMuAlqaQMeEkqKQNekkrKgJekkjLgJamkDHhJKikDXpJKyoCXpJIy4CWppAx4SSopA16SSsqAl6SSMuAlqaQMeEkqKQNekkqqsICPiLaI+FVELImIxRFxTlF9SZI2VNNNtzfTGuBrmflIROwAPBwRd2fmkwX2KUmqKmwEn5kvZuYj1edvAEuAcUX1J0la15DMwUdEO7A/sKif106PiK6I6Orp6RmKctQg49r2JCLq+hjXtmejvy01sSJ+5nhfkRMf9VV4pRGxPXAL8NXMfH391zNzPjAfoKOjI4uuR42zvHsZc676TV3bvOmMg+vanspluP/MFTqCj4hRVML9B5l5a5F9SZLWVeRRNAFcAyzJzP9TVD+SpP4VOYI/BDgZmBkRj1UfRxXYnySpj8Lm4DPzPiCKal+StHGeySpJJWXAS1JJGfCSVFIGvCSVlAEvSSVlwEtSSRnwklRSBrwklZQBL0klZcBLUkkZ8JJUUga8JJWUAS9JJWXAS1JJGfCSVFIGvCSVlAEvSSVlwEtSSRnwklRSBrwklZQBL0klZcBLUkkZ8JJUUga8JJWUAS9JJVVYwEfEtRHxckQ8UVQfkqSBFTmCXwAcWWD7kqSNKCzgM/PXwL8X1b4kaeMaPgcfEadHRFdEdPX09Gx2O+Pa9iQi6voY17ZnHb/T4f39FKne71N727hGf0tSXYxsdAGZOR+YD9DR0ZGb287y7mXMueo3dasL4KYzDq5re5uibN9PkfK6o+vaXpzy87q2JzVKw0fwkqRiGPCSVFJFHiZ5A/AAsHdEdEfEaUX1JUnaUGFz8Jl5QlFtS5IG5xSNJJWUAS9JJWXAS1JJGfCSVFIGvCSVlAEvSSVlwEtSSRnwklRSBrwklZQBL0klZcBLUkkZ8JJUUga8JJWUAS9JJWXAS1JJGfCSVFIGvCSVlAEvSSVlwEtSSRnwklRSBrwklZQBL0klZcBLUkkZ8JJUUga8JJWUAS9JJVVowEfEkRHxh4j4U0R8vci+JEnrKizgI2IE8H3gr4HJwAkRMbmo/iRJ6ypyBD8d+FNm/jkzVwE3Ap8usD9JUh+RmcU0HHEscGRmfqm6fDLw0cw8a73tTgdOry7uDfyhkII23a7AikYXsYmseWhY89Cw5tqMz8zd+nthZIGdRj/rNvhrkpnzgfkF1rFZIqIrMzsaXcemsOahYc1Dw5q3XJFTNN1AW5/lVmB5gf1JkvooMuB/C+wVERMiogU4Hri9wP4kSX0UNkWTmWsi4izgX4ERwLWZubio/grQdNNGNbDmoWHNQ8Oat1BhH7JKkhrLM1klqaQMeEkqKQO+HxHx/oi4OSKeioglEXFQo2vamIg4NyIWR8QTEXFDRIxpdE39iYhrI+LliHiiz7qdI+LuiHi6+vUDjaxxfQPU/A/Vn43HI+K2iHh/A0vcQH8193ntv0VERsSujahtIAPVHBFnVy93sjgiLm5Uff0Z4Gdjv4h4MCIei4iuiJjeyBoN+P59F7gzM/cB/gJY0uB6BhQR44D/CnRk5lQqH2gf39iqBrQAOHK9dV8HfpmZewG/rC43kwVsWPPdwNTMnAb8Efj7oS5qEAvYsGYiog34JPD8UBdUgwWsV3NEfILK2e/TMnMKcEkD6tqYBWz4Pl8MXJiZ+wH/s7rcMAb8eiJiR+BQ4BqAzFyVma82tKjBjQS2iYiRwLY06fkGmflr4N/XW/1p4Prq8+uBzwxlTYPpr+bMvCsz11QXH6RyjkfTGOB9Bvi/wN/RzwmHjTZAzX8LfDsz365u8/KQF7YRA9ScwI7V5zvR4N9FA35DE4Ee4LqIeDQiro6I7Rpd1EAy8wUqI5vngReB1zLzrsZWtUn2yMwXAapfd29wPZvqVOBfGl3EYCJiNvBCZv6u0bVsgg8DH4uIRRFxb0R0NrqgGnwV+IeIWEbl97Kh/90Z8BsaCRwAXJGZ+wNv0nzTBr2qc9afBiYAY4HtIuKkxlY1PETEN4A1wA8aXcvGRMS2wDeoTBlsTUYCHwD+Ejgf+FFE9HcJlGbyt8C5mdkGnEt1JqBRDPgNdQPdmbmounwzlcBvVocDz2ZmT2auBm4FDm5wTZvipYj4EED1a1P9Gz6QiJgLHAOcmM1/Msl/ojIA+F1ELKUypfRIRHywoVUNrhu4NSseAt6hcjGvZjaXyu8gwI+pXFW3YQz49WTmvwHLImLv6qrDgCcbWNJgngf+MiK2rY5uDqOJPxTux+1Ufimofv1pA2upSUQcCfx3YHZmvtXoegaTmb/PzN0zsz0z26kE5wHVn/Vm9hNgJkBEfBhoofmvLrkc+Kvq85nA0w2sBTLTx3oPYD+gC3icyg/ZBxpd0yD1Xgg8BTwB/BMwutE1DVDnDVQ+J1hNJWROA3ahcvTM09WvOze6zhpq/hOwDHis+riy0XUOVvN6ry8Fdm10nTW8zy3AP1d/rh8BZja6zhpqngE8DPwOWAQc2MgavVSBJJWUUzSSVFIGvCSVlAEvSSVlwEtSSRnwklRSBry0ERHRGhE/rV7t8pmI+G71FpRS0zPgpQFUTxy7FfhJVq52+WFge+BbDS1MqpHHwUsDiIjDgP+VmYf2Wbcj8CzQllvBWawa3hzBSwObQuWsxF6Z+TqVy0NMakhF0iYw4KWBBf1fO32g9VJTMeClgS0GOvquqE7RtAHPNKQiaRMY8NLAfglsGxFfAIiIEcClwALn37U1MOClAWTlCIS/AY6LiKep3H91JfA/GlqYVCOPopGkknIEL0klZcBLUkkZ8JJUUga8JJWUAS9JJWXAS1JJGfCSVFL/HzMDawxG2oOwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=new_df, x=\"O\", hue=\"Gender_Male\", multiple=\"dodge\", shrink=.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b2e6a82",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `y` for parameter `hue`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e4bd4b33f42a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultiple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"dodge\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshrink\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\distributions.py\u001b[0m in \u001b[0;36mhistplot\u001b[1;34m(data, x, y, hue, weights, stat, bins, binwidth, binrange, discrete, cumulative, common_bins, common_norm, multiple, element, fill, shrink, kde, kde_kws, line_kws, thresh, pthresh, pmax, cbar, cbar_ax, cbar_kws, palette, hue_order, hue_norm, color, log_scale, legend, ax, **kwargs)\u001b[0m\n\u001b[0;32m   1389\u001b[0m ):\n\u001b[0;32m   1390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1391\u001b[1;33m     p = _DistributionPlotter(\n\u001b[0m\u001b[0;32m   1392\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1393\u001b[0m         \u001b[0mvariables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_DistributionPlotter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_semantics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\distributions.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    107\u001b[0m     ):\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\_core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    602\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 604\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_semantic_mappings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\_core.py\u001b[0m in \u001b[0;36massign_variables\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    665\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"long\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m             plot_data, variables = self._assign_variables_longform(\n\u001b[0m\u001b[0;32m    668\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m             )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\_core.py\u001b[0m in \u001b[0;36m_assign_variables_longform\u001b[1;34m(self, data, **kwargs)\u001b[0m\n\u001b[0;32m    900\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m                 \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"Could not interpret value `{val}` for parameter `{key}`\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 902\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret value `y` for parameter `hue`"
     ]
    }
   ],
   "source": [
    "sns.histplot(data=new_df, x=\"C\", hue=\"y\", multiple=\"dodge\", shrink=.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42414711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a05d53a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "audio_models.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
